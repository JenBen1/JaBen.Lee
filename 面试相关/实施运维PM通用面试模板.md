# （一）简单聊项目

## 01自我介绍

面试官您好，我叫XXX，毕业于福建XX大学XX工程专业。我在互联网+政务领域有5年的工作经验，
曾在XXX集团负责跨境业务并与XXXX部门协作，目前在XXXX公司主导XXXX项目，与XXXX局保持沟通。
今天想面试实施的岗位，基于以下理由：
1-专业技能：计算机专业背景，参与过多个大型项目，熟悉项目流程。
2-知识储备：已通过PMP认证，对项目管理有深入理解。
3-性格特质：乐于挑战，执行力强，相信自己能胜任此岗位。
期待在接下来的面试中展示我的能力，并希望能与贵公司共同成长，谢谢。

## 02项目经历

1、背景：为解决医保信息系统标准不统一和数据不互认问题，实现业务编码、数据规范和经办服务的统一，以及数据互联互通和信息共享，启动国家医疗保障信息平台项目。

2、目标：确保在2021年底前全国完成国家信息平台的上线工作。
3、解决方案：

前期准备： a. 进行各地市需求调研，涵盖当地医保政策、征缴政策和零报业务。b. 撰写需求规格说明书，明确项目需求和目标。c. 参与项目启动会议，了解项目目标和计划。

中期实施：a. 制定详细的内外部培训计划，提升项目团队和客户的能力。 b. 使用Postman和JMeter工具进行接口联调测试，确保系统接口正常工作。 c. 安排客户现场测试验证，获取反馈并及时调整。 d. 进行产品功能介绍和用户培训，确保用户能够有效使用新平台。

后期运维：a.逐步推出各地市上线方案 b. 制定项目验收计划，确认系统满足预定要求。 c. 规划后期的运维方案，包括数据运维和数据库运维，确保系统长期稳定运行。

4、成果：成功在广东11个地市（清远、云浮、茂名等）及青海、西藏、甘肃、江西、重庆等7个省份部署国家医疗保障信息平台。

5、复盘：项目上线后，进行项目复盘，推出暖阳行动，采用传帮带模式，由开发和部门负责人负责培训成员及客户，分享经验，促进知识传递和团队学习。
这就是整体的项目情况。谢谢。

## 03应对客户提出的需求变更？

应对客户提出的需求变更，可以遵循以下步骤：
确认变更内容：明确客户具体要变更哪些需求。
评估影响：分析变更对项目进度、成本和质量的潜在影响。
沟通与协商：与客户沟通变更的影响，并讨论可能的解决方案。
调整计划：更新项目计划、时间表和资源分配以适应变更。
获取确认：确保客户理解变更的后果，并获得书面确认。
实施变更：按照更新后的计划执行，并监控变更实施情况。
记录变更：详细记录所有变更及其实施过程，保持项目文档的透明性和完整性。

## 04需求调研的方法？

访谈：与利益相关者进行一对一或小组讨论，收集需求信息。
问卷调查：发放问卷，通过预设问题获取用户反馈。
观察：直接观察用户操作流程，了解实际使用情况。
头脑风暴：组织研讨会，共同探讨和定义需求。
文档分析：审查现有文档，理解历史数据和业务流程。
原型测试：使用初步原型获取用户反馈，进一步细化需求。

## 05需求发生变更时如何控制？

提交变更请求：正式记录变更。
评估影响：分析变更对项目的影响。
审批：相关权限人审批变更。
更新计划：修改项目文档和计划。
实施和跟踪：执行变更并监控结果。
沟通：向团队和利益相关者通报变更。
保持过程简洁和透明，确保项目各方都能及时了解变更情况。

## 06应对需求蔓延措施

1. 明确目标：确保项目或工作任务的目标清晰明确，避免因为目标不明确导致需求蔓延。

2. 优先级排序：对需求进行优先级排序，确保关键需求得到优先满足，非关键需求可以适当延后或缩减。

3. 制定计划：根据目标和优先级制定详细的工作计划，包括时间表、资源分配等，确保项目按计划进行。

4. 沟通协调：与相关方保持良好的沟通，确保需求的变化得到及时反馈和处理，避免需求蔓延。

5. 控制变更：对于需求变更，要进行严格的变更控制，确保变更的合理性和必要性。

6. 定期评估：定期对项目进展进行评估，发现问题及时调整，避免需求蔓延导致项目失控。

## 07你的优缺点

优点：
1-执行力强：坚决完成任务，完成KPI考核。
2-PMP认证：熟悉项目管理流程。
3-适应力强：能快速适应加班和出差。
缺点：
1-缺乏深度思考：有时候埋头工作，更多关注行动，需提高从高层次视角审视工作能力。
2-经验积累中：需要进一步学习和积累行业经验。

## 08如何控制项目中的风险？

首先要规划项目中可能遇到的风险，例如：需求蔓延、人员变动、技术难点、项目延期等；
其次要制定风险应对措施和流程，如何应对这些风险，谁来应对，谁来负责等，定期跟进风险列表；
再次要做好风险预警，发现有预警的苗头要及时控制，采取应对措施；
最后是风险出现之后要按照流程解决风险，并且将风险的情况及时汇报给相关干系人。

## 09辞职的理由

追求职业突破：希望在新平台上挑战自我，实现更大进步。

拓展专业领域：想拓展自己的知识面，进行更深的学习和实践。

## 10五年职业规划

1. **入职初期（第1年）**：基础学习
   - 熟悉工作环境，熟悉团队，掌握核心业务和工作流程。
   - 设定并完成短期目标，如完成特定项目、获得必要的技能认证。
   - 积极寻求反馈，提升工作表现。

2. **中期（第2-4年）**：技能提升承担责任
   - 承担更多责任，接手挑战性项目。
   - 通过跨部门合作，提升决策和规划能力。
   - 寻求导师指导，请教同事，为未来的管理角色做准备。

3. **后期（第5年及以后）**：成为领导者
   - 成为领域专家，具备多方面能力。
   - 保持专业知识前沿性。
   - 成为团队领导者，培养新一代人才。

## 11做项目管理什么最重要

1. 理解能力：深入理解公司方向、领导意图和客户深层需求，以及准确应对干系人反馈。
2. 沟通能力：具备清晰的逻辑和分析能力，以有效沟通和判断。
3. 风险控制能力：及时预判项目风险并采取适当措施，向领导层反馈。

## 12最能概括自己的三个词

1. 学习力：
   - 我具备强烈的学习动力和持续的学习意愿，这使我能够不断更新知识和技能。
   - 我注重学习方法，技术我会阅读专业书籍、通过github等多种途径来获取知识。
   - 在实践中，我会将新学的知识应用到工作中去。
2. 心态：
   - 我面对挑战时保持积极乐观的心态，不轻易被困难和挫折所动摇。
   - 我总是努力保持冷静和理性，以便更好地分析问题和寻找解决方案。
   - 在压力和不确定性面前，我能不断地调整策略，以实现目标。
3. 执行力：
   - 对于上级分配的任务，我总是能够迅速行动，并确保按时按质完成。
   - 我明白执行力不仅仅是完成任务，还包括主动沟通进度、及时反馈问题并提出改进建议，以确保项目的顺利进行。

## 13最近项目中出现的问题，如何避免，以及成长和收获

问题描述：

在进行医院接口验收时，出现了与医院意见不一致的情况。尽管我已经将所需的测试案例和政策案例提供给了测试群，但由于可能的通知不到位，医院方面声称完全没有收到相关信息。这导致了验收进度缓慢，严重拖慢了项目的整体进度。

为了避免类似问题的发生，并确保项目能够顺利进行，我采取了以下三个方法：

1. 加强沟通：
   - 我主动与医院负责人建立了更紧密的沟通渠道，确保信息的及时传递和理解。通过电话沟通及时确认，我确保医院方面对项目进展有清晰的了解，并且能够及时提出意见和建议。

2. 测试用例准备充分：
   - 我重新审视了测试用例的准备过程，确保它们是全面且详尽的。我将这些测试用例整理成文档，确保它们能够准确无误地送达医院负责人手中。同时，我还提供了简要的使用说明，以便医院方面能够更好地理解和应用这些测试用例。

3. 及时跟进验收进度：
   - 为了确保项目进展顺利，我制定了一个详细的跟进计划。我会定期与医院负责人进行沟通，了解验收进度，并及时解决可能出现的问题。如果发现进度滞后或存在其他障碍，我会立即采取措施进行调整，以确保项目能够按计划进行。

成长和收获：

通过以上措施的实施，我成功地解决了与医院验收相关的问题，并确保了项目的顺利进行。这个经历让我学到了很多，特别是在沟通、测试用例准备和进度跟进方面的技巧。我意识到，及时的沟通和准确的信息传递是项目成功的关键。此外，我也学会了如何更好地准备测试用例，并确保它们能够被正确地理解和应用。最后，我认识到了及时跟进项目进展的重要性，以便能够迅速解决问题并保持项目的顺利进行。

总的来说，这个项目经历使我在项目管理和沟通方面有了显著的成长和收获。我学到了如何更好地与不同利益相关方进行合作，并确保项目的顺利进行。这些经验和技巧将对我未来的工作产生积极的影响。

## 14简述项目流程

1.项目立项
2.需求评审会
3.产品原型设计
4.ui 效果图设计
5.前后端工程师把业务逻辑实现
6.提测
7.上线

## 15对我们公司有什么想了解的

1试用期，公司的考核指标是怎么安排的？
2目前公司的团队组成和组织架构是怎样的？
3公司核心部门为哪些业务负责？
4贵公司对新入公司的员工有没有什么培训项目，我可以参加吗？
5贵公司的晋升机制是什么样的？

## 16故障具体怎么处理的  怎么回答

处理紧急故障的具体方法会因故障的性质和严重程度而异，但一般包括以下步骤：

1. 故障接收：首先，我们需要接收到故障报告，这可能来自内部监控系统或用户反馈。

2. 故障定位：一旦接收到故障报告，我们的技术团队会立即进行故障定位，确定问题的具体位置和原因。

3. 制定解决方案：在确定故障原因后，我们会制定相应的解决方案。这可能包括更换硬件、修复软件、调整配置等。

4. 执行解决方案：然后，我们会尽快执行解决方案，以恢复系统的正常运行。

5. 验证和监控：最后，我们会验证解决方案是否有效，并通过监控系统持续监控，以确保问题已经完全解决。

## 17你在项目管理过程中从事什么工作

在整个项目管理过程中， 先进行需求调研； 再制定项目规划； 后续在开发阶段对进度的一个把控，以及在这个过程中不断和干系人沟通，了解各个干系人的满意度； 最后是交付和收尾。 

## 18如何持续提升项目团队梯队建设

第一步树立项目目标，将整个目标贯彻到所有团队成员，使团队有共同的努力方向；
第二步能够和每个员工独处，了解团队成员每个人的详细情况，技术、优点、缺点，擅长领域，针对每个人的情况进行任务分解，角色划分；
第三步建立团队学习、分享机制，扬长避短，使每个人在这个项目中都能够得到提升。
第四步联合职能部门定期考核，奖罚分明；
第五步在成本范围内不定时举行各种团建。

## 19工作成长总结/自己最大的变化

#### 1）专业知识提升

- **数据库技术**：SQL查询优化，事务管理等，掌握实战技巧。
- **Linux系统管理**：基础的命令行操作到高级的系统配置、服务管理、部署应用等，我在Linux环境中的工作技能得到了全面提升。

#### 2）解决问题能力增强

- **问题识别**：基于对业务流程的深入理解，快速定位问题核心。
- **问题分析与求解**：深入剖析，持续学习，遇到新问题时，能够快速查阅资料、请教他人，探索前沿技术，以找到最佳解决方案。

#### 3）工作习惯优化

- **时间管理**：合理规划，平衡工作休息。
- **协作沟通**：清晰表达，有效倾听。尊重他人意见，促进了信息的准确传递与理解。
- **持续学习与反思**：总结经验，建立知识库。将工作中遇到的问题及其解决方案记录下来，便于日后查阅与分享。

#### 4）处事心态成熟

- **应对压力**：将其视为成长的机会而非负担，积极面对挑战。
- **处理人际关系**：换位思考，理解和尊重他人的立场与需求，跟同事友好相处。
- **面对失败与挫折**：我能够坦然接受失败，从中汲取经验，持续改进，展现出更强的抗压能力和韧性。

## 20在实施项目时，您如何处理变更管理？

在实施项目时，我会遵循公司的变更管理流程。

首先，我会与项目团队和利益相关者讨论变更的必要性和影响。

然后，我会创建详细的变更请求文档，包括变更的描述、影响评估、风险评估和实施计划。

在获得批准后，我会按照计划实施变更，并确保所有相关人员都了解变更的内容和影响。

## 21如何处理客户的投诉和不满？

面对客户的投诉和不满，首先要保持冷静和专业的态度，认真倾听客户的问题和需求。

然后，我会尽快地确认问题的细节，并提供清晰的沟通，让客户知道我们正在积极解决问题。

接下来，我会与团队合作，找出问题的根源，并制定解决方案。

在问题解决后，我会及时向客户反馈，并采取措施防止类似问题再次发生。

最后，我会跟进客户，确保他们对解决方案满意。

## 22在软件实施过程中，如何确保项目按时按质完成？

为确保项目按时按质完成，我会在项目开始时与项目团队和客户共同制定一个详细的项目计划，包括明确的里程碑和交付日期。

在项目实施过程中，我会定期监控项目进度，并与团队成员进行沟通，确保每个人都清楚自己的任务和责任。

如果遇到任何潜在的风险或延误，我会及时与客户沟通，并寻求解决方案。

此外，我还会确保质量控制流程得到遵守，通过定期的代码审查和测试来保证软件质量。

## 23如何在项目实施过程中与非技术背景的客户沟通？

在与非技术背景的客户沟通时，我会使用清晰、简洁的语言来解释技术问题和概念。

我会避免使用过多的技术术语，并尽可能用类比或实例来说明问题。

此外，我会确保提供足够的上下文信息，帮助客户理解项目的重要性和影响。

我还会定期更新客户项目进展情况，并邀请他们提供反馈和建议。

## 24描述一次你在项目中如何领导团队解决复杂问题的经历。

在一个涉及多个部门的系统集成项目中，我们遇到了数据同步的问题。我首先组织了一个跨部门会议，明确了问题的性质和影响。
然后，我组织团队成员负责调查不同的潜在原因，并定期汇报进展。
通过团队的协作和努力，我们发现并解决了数据同步的问题，在同步系统中定时任务挂了，并进行了修复。
在整个过程中，我确保团队成员之间的沟通顺畅，并提供必要的支持和资源。

## 25常见的项目管理工具

项目管理工具是用来辅助项目管理者计划、组织、监控和控制项目进程的软件应用程序，旨在提高工作效率，确保项目按照预定预算、时间和质量目标顺利完成。以下是一些常见的项目管理工具列表：

1. **在线项目管理工具**：
   - Trello：看板式的项目管理工具，适用于任务分配与追踪。
   - Asana：强大的项目和任务管理工具，支持多任务视图和项目规划。
   - Monday.com：可视化的项目管理工具，可自定义工作流。
   - Wrike：提供多功能项目管理，包括Gantt图表、时间表和实时协作。
   - Basecamp：一体化的项目协作工具，包括文件共享、任务分配和讨论功能。
   - Microsoft Project：Microsoft出品的专业级项目管理工具，含甘特图和资源管理功能。
   - Smartsheet：结合了表格和项目管理功能，提供丰富的报表和自动化选项。

2. **敏捷开发工具**：
   - Jira：Atlassian公司的产品，专为软件团队设计，支持敏捷开发流程。
   - Azure DevOps：Microsoft提供的集成工具套件，包括敏捷规划、源代码管理、持续集成/部署等功能。
   - GitLab：除了版本控制系统外，也提供了敏捷项目管理模块。
   - Kink code（应为“PingCode”）：根据之前的信息，这款工具在国内针对软件研发项目管理有着良好的口碑和市场表现。

3. **云端项目管理工具**：
   - Worktile：国内知名的项目管理软件，支持多种类型的项目管理需求。
   - Slack：虽然主要作为通讯工具，但也具备项目管理和协同工作的能力。
   - ClickUp：综合性的项目管理平台，支持多种项目视图和团队协作。

4. **传统项目管理工具**：
   - Microsoft Project（MS Project）：经典的项目管理软件，主要用于创建项目计划、跟踪项目进度等。
   - Primavera P6：专业级项目计划和控制软件，常用于大型工程项目管理。

5. **开源项目管理工具**：
   - Redmine：开源的项目管理和缺陷追踪工具。
   - OpenProject：开源的项目管理软件，提供多种项目管理特性。
   - GanttProject：免费开源的项目计划软件，支持甘特图和资源管理。

6. **其他工具**：
   - Teamwork：提供项目管理、任务分配和时间跟踪等功能。
   - Airtable：兼具数据库和项目管理功能，灵活性高。
   - Notion：一体化工作空间，可以用于项目管理、知识库管理等多种场景。

上述列举的工具仅仅是众多项目管理工具的一部分，每种工具都有其独特的功能特点和适用场景，选择时需考虑团队规模、行业特点、项目性质和预算等因素。随着技术的发展，越来越多的项目管理工具不断涌现和完善，因此最新的工具排行和功能可能会有所变化。

## 26当遇到无法满足客户特定需求的情况时，应该怎么答

有效的沟通至关重要，以下是一个通用的沟通框架和步骤，以具体实例来说明：

**实例场景**：
假设客户要求开发一个具有复杂实时视频处理功能的移动应用，但经过技术评估后发现，现有的团队技术和资源限制无法在规定时间内实现这种高度定制化的功能。

**沟通步骤和策略**：

1. **准备充分**：
   - 收集详尽的技术评估报告，明确指出无法实现的原因，比如现有技术瓶颈、时间限制、预算不足等。
   - 找到替代解决方案或折衷方案，例如推荐市场上已有的成熟视频处理服务集成，或是计划在未来某个阶段逐步完善相关功能。

2. **主动沟通**：
   - 首先，表达对客户需求的理解和尊重：“我们非常重视您提出的要求，关于实时视频处理的功能，我们完全明白其对您业务的重要性。”

3. **坦诚说明**：
   - 诚实地解释现状：“经过我们内部的技术评估，我们发现按照当前的技术条件和项目进度安排，短期内直接开发这样复杂的实时视频处理功能存在一定的困难。”

4. **提供依据**：
   - 分析原因：“主要挑战在于所需的算法复杂度、硬件性能要求以及我们的开发周期限制，这些因素综合起来超出了我们现阶段能够迅速应对的能力范围。”

5. **提出替代方案**：
   - 提供替代建议：“不过，我们已经考虑了一个替代方案，我们可以整合市面上先进的第三方视频处理API服务，这样可以在短时间内为您的应用提供类似的功能，虽然可能并非完全定制化，但能够在满足基本需求的同时降低开发风险和成本。”

6. **寻求共识**：
   - 征求客户意见：“我们希望听取您的想法，是否愿意考虑这个临时性的解决方案，同时我们将继续研究和规划长期的定制开发计划，以便在未来迭代中逐步完善这项功能。”

7. **后续跟进**：
   - 如果客户接受替代方案，则约定实施细节和下一步行动计划；如果不接受，讨论是否有其他可行的调整方案，或探讨延长开发周期、增加投入的可能性。

通过这种方式，既保证了与客户的透明沟通，又展示了积极解决问题的态度，有助于维护良好的客户关系，并在实际操作中寻找最佳平衡点。

# 项目管理相关：

1．根据领导要求按计划实施项目, 做好项目实施中的沟通协调及实施过程反馈；

## 1-请描述一下您在以往的项目中是如何按照领导的要求制定并执行项目计划的？

在以往的项目中，我遵循了以下步骤来制定并执行项目计划：

1. **明确项目要求**：与领导进行深入讨论，确保对项目目标、预期成果、时间节点和资源需求有清晰的理解。
2. **制定项目计划**：细化任务分解、时间规划、责任分配，并制定风险应对策略。
3. **执行与监控**：通过定期会议和项目管理工具跟踪进度，确保团队对项目状态有实时了解。
4. **沟通与协调**：积极与相关部门和团队成员沟通，解决执行中的问题，确保项目顺利进行。
5. **风险管理**：对潜在偏差和风险进行预警，及时提出并执行调整方案，并向领导汇报。
6. **持续优化**：建立反馈机制，收集意见，不断改进项目执行效果。

通过这一系列有条理的步骤，我能够有效地按照领导的要求执行项目计划，确保项目目标的顺利实现。

## 2-假设你在执行项目时遇到了跨部门协作难题，你是如何进行有效沟通和协调的？

面对跨部门协作难题，我采取以下措施进行有效沟通和协调：

1. **理解需求**：深入了解各部门的需求和挑战，寻求共同点。
2. **组织会议**：召开多方会议，明确项目目标和各自的责任，强调团队合作的重要性。
3. **开放交流**：鼓励坦诚对话，共同识别问题并协商解决方案。
4. **明确分工**：确定责任分工和时间节点，必要时形成书面协议。
5. **建立沟通机制**：设立定期的进度同步和问题解决小组，确保信息流通和快速响应。

通过这些策略，我能够有效地促进跨部门合作，解决协作难题，推动项目顺利进行。

## 3-请分享一次你在项目实施过程中，如何处理突发问题并向上级领导反馈的经历。

在项目实施中遇到的突发问题是供应商延迟交付关键部件。我迅速采取以下措施：

1. **启动应急预案**：立刻联系备选供应商，同时调整内部工作流程和时间安排。
2. **汇报上级**：整理情况报告，包括应对措施和对项目进度的影响，及时向上级反馈。
3. **提出建议**：提供解决方案和风险缓解措施，寻求领导的指导和批准。
4. **执行调整**：在获得批准后，迅速切换供应商，并加强内部工作以减少延误。

通过这些迅速而有效的应对策略，项目最终能够按计划进行，同时也增强了团队的应急处理能力。

## 4-在项目实施过程中，你如何确保项目计划得到有效执行并得到及时反馈？

为确保项目计划的有效执行和及时反馈，我实施以下策略：

1. **明确执行计划**：制定详尽的任务分配和时间表，利用项目管理工具进行跟踪监控。
2. **定期项目会议**：安排固定会议讨论进展和挑战，提供反馈和团队协作机会。
3. **设置检查点**：确立关键里程碑，对工作成果进行评审，及时调整偏离计划的任务。
4. **敏捷和滚动规划**：采用灵活的规划方法以适应变化，实现迭代改进。
5. **建立沟通机制**：鼓励团队成员主动反馈，同时向上级汇报，确保项目顺利进行。

通过这些措施，我能够有效地保障项目按计划执行，并确保问题和建议得到及时处理。

## 5-在你的项目管理经验中，你是如何处理团队内部及与其他部门间的冲突，确保项目顺利进行的？

在处理团队内部及跨部门冲突时，我采取以下策略：

1. **公平倾听**：给予各方表达意见的机会，公正地听取并分析冲突原因。
2. **促进沟通**：通过会议或工作坊等活动，增进理解，引导团队关注共同目标。
3. **提出解决方案**：制定并实施解决策略，如调整计划、资源重配，或建立联合工作组。
4. **高层介入**：在需要时寻求上级领导的支持，以助于冲突的解决。
5. **持续关注与改进**：冲突解决后，持续监督效果并总结经验，优化项目管理和团队协作机制。

通过这些方法，我确保了项目能够在冲突得到妥善处理后，继续顺利进行。

----------------

# 需求测试相关：

2．收集用户需求，协助进行需求分析、软件升级测试，解决实施过程中出现的问题；

## 1-请分享一次你在实际工作中收集用户需求的具体经历，并说明你是如何确保需求收集准确且全面的？

在负责企业级应用系统改版升级的项目中，我通过以下步骤确保用户需求收集的准确性和全面性：

1. **多渠道调研**：结合一对一访谈、问卷调查和焦点小组讨论等方法，广泛接触用户群体。
2. **设计问题**：制定结构化和开放式问题，覆盖用户痛点、功能期望和创新需求。
3. **观察与记录**：访谈中观察用户操作，记录反馈，引导描述应用场景和需求背景。
4. **需求整理**：归类整理需求，通过数据分析剔除无效或重复项，进行优先级排序。
5. **持续反馈**：建立需求反馈渠道，允许用户在项目周期内更新需求或提出意见。

通过这些策略，我确保了需求收集工作的高效性和质量，为产品设计和优化打下了坚实基础。

##  2-在进行需求分析时，你是如何处理用户需求之间可能存在冲突的情况？

面对用户需求冲突，我采取以下措施进行处理：

1. **识别冲突**：明确并列出冲突的需求，分析其业务场景和价值。
2. **优先级排序**：根据战略目标、用户需求、成本和技术可行性对需求进行排序。
3. **研讨解决方案**：组织相关人员讨论，探索可能的设计或技术方案以平衡或兼容冲突需求。
4. **决策与沟通**：若需求无法同时满足，列出方案的优缺点，提供专业建议并提交决策层。决策后，及时通知用户并解释原因，争取理解与认同。

通过这种方法，我能够有效地解决需求冲突，确保项目顺利进行。

## 3-在软件升级测试阶段，你通常会采用哪些测试方法来确保新功能的稳定性和兼容性？

在软件升级测试阶段，我采用以下关键测试方法确保新功能稳定性和兼容性：

1. **功能测试**：编写测试用例，验证所有新旧功能是否符合需求规格。
2. **兼容性测试**：在不同操作系统、浏览器和设备上测试，确保软件的广泛兼容性。
3. **性能测试**：评估软件在高负载和长时间运行下的性能表现，识别性能瓶颈。
4. **回归测试**：全面检查现有功能，确保新功能添加未引起问题。
5. **安全性测试**：检查安全防护措施，防止潜在的数据泄露和非法访问。
6. **用户接受度测试**：邀请目标用户试用新功能，收集反馈进行最终优化。

通过这些综合测试方法，我确保新功能的质量，为软件的稳定发布打下坚实基础。



## 4-当在实施过程中发现严重问题时，你会如何进行问题定位和解决？

面对实施过程中的严重问题，我的处理流程如下：

1. **问题记录**：详细记录问题现象、复现步骤、影响范围和初步判断。
2. **问题定位**：与开发团队合作，通过日志分析、代码审查和调试工具定位问题。
3. **解决方案**：评估修复难度和时间，确定并执行解决方案。
4. **沟通协调**：对于复杂问题，制定临时措施并及时通报给所有相关干系人。
5. **根本原因分析**：反思问题原因，采取措施预防未来问题，如优化流程、提升代码质量等。

通过这种方法，我能够有效地定位和解决问题，同时采取措施减少未来类似问题的发生。

## 5-在收集用户需求的过程中，如何平衡用户需求与企业战略、技术可行性和经济效益之间的关系？

在收集用户需求的过程中，我通过以下方式平衡用户需求与企业战略、技术可行性和经济效益：

1. **战略一致性**：确保需求与企业战略相符，优先考虑对战略目标有贡献的需求。
2. **技术评估**：与技术团队合作，评估需求的技术实现可能性，避免追求技术上难以实现或成本过高的解决方案。
3. **经济效益分析**：对需求进行量化评估，考虑其重要性、紧迫性以及预期的开发成本和收益，合理排序需求的优先级。
4. **通用性和扩展性**：选择具有通用性和良好扩展性的需求，以满足当前用户需求的同时，支持产品的长期发展。

通过这种综合性的平衡策略，我能够确保用户需求的收集既符合企业的长期利益，又具有实际的技术可操作性和经济效益。



# 财务接口相关：

负责对产品财务数据接口进行校验、反馈、治理，完成产品上线交付； 

## 1-请描述一下你曾经负责过的财务数据接口校验工作流程，以及如何确保数据准确无误？

在负责财务数据接口校验的工作中，我遵循以下流程确保数据的准确性：

1. **深入了解数据规范**：首先熟悉接口数据格式、字段定义和业务规则，确保对数据要求有全面理解。
2. **制定校验规则**：基于数据规范，制定详细的数据校验规则，涵盖字段完整性、数值范围和逻辑一致性等关键点。
3. **自动化校验**：编写脚本或程序，自动化执行数据校验，对比实际数据与预期标准，确保数据格式和内容无误。
4. **逻辑校验**：对于复杂的业务逻辑，如交易流水和金额匹配，设置专项逻辑校验确保业务正确性。
5. **异常处理**：对校验中发现的异常数据进行记录和反馈，与相关部门协作排查并解决问题。
6. **持续改进**：定期编制数据质量报告，分析错误趋势，提出并实施改进措施，不断提升数据质量。

通过这一严谨的工作流程，我确保了财务数据接口的准确性和数据质量，为公司提供了可靠的数据支持。

## 2-假如在产品上线前，你发现财务数据接口存在数据缺失或错误的情况，应该如何处理？

面对产品上线前财务数据接口的数据缺失或错误问题，我的处理策略如下：

1. **问题确认**：迅速核实数据问题的具体内容、影响范围和潜在原因。
2. **跨部门协作**：立即与财务和IT团队沟通，共同定位问题源头。
3. **解决方案制定**：根据问题类型，采取补充数据、纠正错误或优化接口逻辑等措施。
4. **重新校验**：问题解决后，再次进行彻底的数据校验，确保数据的完整性和准确性。
5. **上线计划调整**：如需调整上线时间，与项目组协商并确定新的上线计划，及时通知所有相关方。
6. **回顾总结**：问题解决后，进行过程回顾，改进监控和校验机制，防止问题重现。

通过这一系列有序的措施，我能够确保数据问题得到及时有效的解决，保障产品顺利上线。

## 3-在财务数据接口治理方面，你认为有哪些重要的原则和策略？

在财务数据接口治理方面，我认为以下原则和策略是关键：

1. **数据质量优先**：确保数据的准确性、完整性和一致性，作为治理的核心。
2. **统一标准**：实施统一的数据格式和规范，简化接口设计，提高数据处理效率。
3. **动态监控**：建立实时监控系统，快速识别并响应数据异常，保持数据质量。
4. **风险管理**：识别潜在风险，实施严格的数据安全和隐私保护措施，防止数据泄露。
5. **全周期管理**：对数据的整个生命周期进行闭环管理，确保问题可追溯和及时解决。
6. **跨部门协作**：促进不同部门和团队之间的合作，共同推进数据接口的维护和优化。

通过遵循这些原则和策略，可以有效地提升财务数据接口的治理水平，确保数据的安全性和可靠性。

## 4-请简述你如何对产品上线前的财务数据接口进行压力测试，以确保其在高负载情况下仍能正常工作？

为确保财务数据接口在高负载下正常工作，我采取以下压力测试措施：

1. **设计测试场景**：模拟实际高流量数据请求，设定合理的压力测试环境。
2. **执行压力测试**：利用压力测试工具模拟并发请求，逐步提升负载，监测接口性能。
3. **资源监控**：实时监控系统资源使用情况，识别性能瓶颈。
4. **性能优化**：根据测试反馈，调整性能策略如数据库优化、缓存机制或负载均衡。
5. **持续迭代**：重复测试至接口能在预期负载下稳定运行，满足业务性能要求。

通过这一流程，我确保财务数据接口能够承受高负载压力，保障产品上线后的稳定性和可靠性。

## 5-在进行财务数据接口治理时，如何处理历史遗留数据与新接口数据的衔接过渡？

处理历史遗留数据与新接口数据衔接的过渡，我会采取以下策略：

1. **详细分析**：对比历史数据与新接口数据模型，明确差异和需求。
2. **制定迁移方案**：规划数据清洗、转换和适配流程，确保数据兼容性。
3. **开发迁移工具**：创建数据迁移脚本或工具，并在测试环境中验证其准确性。
4. **执行迁移**：选择适当时机进行数据迁移，同时监控系统状态，确保服务不受影响。
5. **核验数据**：完成迁移后，验证数据的完整性和正确性，保障数据的平滑过渡。
6. **逐步切换**：确保所有业务迁移至新接口后，逐步淘汰旧接口。

通过这些有序的步骤，我能够确保历史数据与新接口的顺利衔接，同时最小化对现有业务的影响。

# 用户培训相关：

## 1-请描述一下您在编写产品操作手册时的主要步骤和注意事项是什么？

编写产品操作手册的主要步骤和注意事项如下：

**主要步骤：**

1. **需求分析**：深入了解产品功能和目标用户，确定手册内容和重点。
2. **内容规划**：制定手册结构，涵盖产品概述、安装、功能、操作步骤和常见问题等。
3. **撰写内容**：用简洁明了的语言撰写，配合图示和步骤列表，清晰展示操作流程。
4. **审阅修订**：与团队合作审阅手册，确保内容准确，符合用户理解。
5. **用户测试**：让目标用户试读手册并收集反馈，根据反馈进行调整优化。

**注意事项：**
1. **易懂语言**：使用用户友好的语言，避免行业术语，确保易读性。
2. **持续更新**：随着产品更新，及时修订手册，保持信息的时效性。
3. **全面覆盖**：内容要适应不同水平的用户，从基础到高级，满足不同需求。

通过这些步骤和注意事项，可以确保操作手册的有效性，帮助用户更好地理解和使用产品。

## 2-请谈谈您在为客户进行产品培训时的具体做法和培训效果如何衡量？

为客户进行产品培训时，我遵循以下步骤并衡量培训效果：

1. **定制培训内容**：根据客户需求准备培训资料，涵盖基础操作和高级功能。
2. **互动讲解**：采用现场演示和讲解相结合的方式，鼓励客户提问和参与。
3. **实战演练**：组织客户进行分组练习，通过实际操作巩固学习成果。
4. **收集反馈**：培训后通过问卷或讨论收集客户反馈，评估培训质量。

**衡量培训效果的方法：**

1. **满意度调查**：通过调查问卷收集客户对培训的满意度评价。
2. **技能考核**：通过测试或考核验证客户对产品操作的掌握情况。
3. **长期跟踪**：在培训后一段时间内跟踪客户的产品使用情况和问题解决能力。

通过这些方法，我确保培训内容的有效传达，并持续改进培训质量，以提高客户满意度和产品使用效率。

## 3-请描述一下您如何收集和跟进客户对产品的使用反馈意见，并转化为产品改进的建议？

收集和跟进客户反馈以及转化为产品改进建议的过程如下：

1. **建立反馈通道**：确保客户可以通过多种途径（问卷、热线、邮件、社交媒体等）提供反馈。
2. **组织反馈**：对收集到的反馈进行分类和记录，分为功能、体验、故障等类别。
3. **分析需求**：与团队合作深入分析每条反馈，挖掘客户需求和产品不足之处。
4. **制定改进措施**：将有价值的反馈转化为产品优化建议，与产品团队讨论并纳入改进计划。
5. **沟通结果**：向客户提供反馈采纳和改进结果，增强客户的参与感和满意度。

通过这一流程，我能够有效地将客户的使用反馈转化为产品改进的动力，不断提升产品质量和客户满意度。

## 4-您如何看待产品操作手册对于客户体验的重要性？如何确保手册内容易于理解和记忆？

产品操作手册对客户体验至关重要，因为它直接影响用户对产品的初步理解和长期依赖。为了确保手册内容易于理解和记忆，我会采取以下措施：

1. **清晰的结构**：合理组织手册内容，使其逻辑性强，便于用户查找和学习。
2. **明确的步骤**：用简洁的语言和清晰的图表展示操作流程，便于用户跟随。
3. **突出关键点**：强调重要的操作提示和注意事项，使用高亮或列表等形式吸引用户注意。
4. **互动元素**：加入互动环节，如小测试或实操练习，帮助用户通过实践加深记忆。
5. **持续更新**：随着产品的发展，定期更新手册内容，确保信息的准确性和时效性。

通过这些方法，我能够确保操作手册成为提升客户体验的有效工具，帮助用户更好地掌握和使用产品。

## 5-在培训客户使用产品时，遇到过什么棘手的问题，您是如何解决的？

在培训客户使用产品时，我遇到过客户对某复杂功能理解不足的挑战。为了解决这个问题，我采取了以下措施：

1. **使用比喻**：尝试用更贴近客户生活和工作场景的比喻来解释功能，但发现效果有限。
2. **实操案例**：设计了一个具体的业务流程案例，让客户通过模拟操作来实际体验该功能。
3. **动画教程**：制作了一个动画视频教程，详细展示功能的操作流程和逻辑，帮助客户更直观地理解。

通过结合实际操作和视觉辅助，客户对该功能的理解得到了显著提高，成功克服了学习障碍。这经历也强化了我对于采用多样化教学方法以适应不同客户需求的认识。



# 售后服务相关：

4．负责所承担项目上线后的售后服务和技术支持工作。 

## 1-请您描述一下，在项目上线后，作为售后服务和技术支持人员，您是如何进行客户问题响应和处理的？

作为售后服务和技术支持人员，在项目上线后，我通过以下步骤高效响应和处理客户问题：

1. **建立接收渠道**：确保客户能通过多种方式（服务热线、邮箱、在线聊天等）随时反馈问题。
2. **迅速反馈**：收到问题后，快速确认详情，判断问题紧急性，并及时给予客户回应或临时解决方案。
3. **深入诊断**：通过远程协助、日志分析等手段，准确找出问题根源。
4. **制定解决策略**：根据问题类型，提供技术修复、操作指导或重新培训等解决方案。
5. **持续跟进**：解决问题后，及时与客户沟通结果，并持续监控确保问题完全解决，防止复发。
6. **知识库建设**：将问题及解决方案归档，丰富内部知识库，提升未来问题处理的效率。

通过这一流程，我确保了客户能够得到及时有效的支持，同时不断优化服务质量，提升客户满意度。

## 2-当面临客户提出的复杂技术支持请求时，您如何协调内部资源以保证高效服务？

面对客户提出的复杂技术支持请求，我通过以下步骤高效协调内部资源：

1. **问题评估**：深入了解技术问题，准确评估所需资源和支持的部门。
2. **团队协作**：与相关部门快速沟通，组建专家团队或专项小组，明确各自职责。
3. **资源分配**：根据问题紧迫性设定优先级，合理分配资源以确保关键问题得到快速响应。
4. **进度跟踪**：持续监控问题解决进度，定期向客户报告，保持沟通的透明度。
5. **经验反馈**：问题解决后，进行内部复盘，总结经验并优化流程，防止问题重现。

通过这样的流程，我确保了对客户技术支持请求的高效响应和服务质量，同时不断优化内部协作机制。



## 3-您如何确保在售后服务和技术支持阶段保持与客户良好的沟通，并提高客户满意度？

为确保售后服务和技术支持阶段与客户的顺畅沟通及提升客户满意度，我采取以下措施：

1. **主动跟进**：定期与客户沟通，了解他们的使用体验和需求，预防潜在问题。
2. **倾听与理解**：耐心倾听客户反馈，展现同理心，确保客户感到被尊重和理解。
3. **简洁明了**：用易懂的语言解释技术问题，避免行业术语，提高沟通效率。
4. **迅速行动**：快速响应客户需求，及时解决问题，减少客户等待和不便。
5. **服务改进**：利用客户反馈进行服务流程的持续优化，通过满意度调查等手段收集意见。

通过这些方法，我能够有效维护与客户的沟通，提升服务质量，从而提高客户满意度。

## 4-您能否举个例子说明，在过去的工作中，您是如何成功解决一个重大售后问题，并且通过这次经历获得了哪些启示？

在之前的工作中，我成功解决了一次系统升级后出现的严重功能故障。面对这一挑战，我采取了以下措施：

1. **迅速响应**：立即组建应急小组，稳定系统状态，防止问题扩散。
2. **问题定位**：通过日志分析快速找到问题源头，与开发团队合作制定解决方案。
3. **及时修复**：迅速部署修复方案，恢复系统正常运行。
4. **透明沟通**：与客户保持实时沟通，通报问题处理进展，维护信任关系。
5. **总结改进**：问题解决后，进行复盘分析，优化发布流程和应急预案，强化测试工作。

这次经历让我意识到，优秀的售后服务不仅要迅速解决问题，更要注重预防措施和从经验中学习，以此提升产品和服务质量。

## 5-在长期的售后服务和技术支持工作中，您如何平衡日常维护与突发问题处理的关系？

在长期的售后服务和技术支持中，平衡日常维护与突发问题处理，我采取以下策略：

1. **预防性维护**：实施定期监控和维护计划，减少突发问题发生。
2. **优先级划分**：为不同任务设定优先级，确保日常维护有序进行，同时对突发事件给予足够关注。
3. **团队分工**：明确团队职责，一部分人负责日常维护，另一部分人准备应对紧急情况。
4. **准备应急预案**：制定突发问题处理预案，储备必要资源，确保快速响应。
5. **灵活调整**：根据业务需求和实际情况，动态调整维护和应急策略，保持服务质量和效率。

通过这些方法，我能够有效地平衡日常工作与紧急问题处理，确保售后服务的连续性和高效性。

# 相关技能面试题：

根据实施工程师职位要求，以下是可能的面试题以及相应的回答：

## 1-请描述您在软件项目实施过程中扮演的角色以及您的具体职责。

**回答**: 在我之前的软件项目中，我主要负责后端开发。我的职责包括编写和维护Java代码，参与需求分析，以及与团队合作确保项目按时交付。我还参与了项目的测试和部署阶段，确保软件的质量和性能符合预期。

## 2-您如何管理和跟踪软件项目的进度？

**回答**: 我使用敏捷开发方法和项目管理工具（如JIRA）来管理和跟踪项目进度。我会定期与团队成员进行站立会议，更新任务状态，并及时解决任何潜在的瓶颈。

## 3-描述一次您解决复杂网络通讯编程问题的经历。

**回答**: 在一个项目中，我遇到了一个棘手的网络延迟问题。通过分析网络日志和调试代码，我发现是由于一个第三方库的不当使用导致的。我重构了相关代码，并优化了网络请求，最终显著提高了系统性能。

## 4-您在Windows和Linux操作系统中通常使用哪些命令来排查问题？

**回答**: 在Windows中，我常用`ipconfig`、`netstat`和`tasklist`等命令。在Linux中，我常用`ps`、`top`、`lsof`和`netstat`等命令来监控系统状态和网络连接。

## 5-请举例说明您如何优化数据库性能。

**回答**: 我通过分析查询执行计划来识别慢查询，并对其进行优化。此外，我会定期进行索引重建和更新统计信息，以确保查询性能。

## 6-编写一个SQL脚本，用于查询一个月内销售总额。

**回答**: 这取决于具体的数据库结构，但一个基本的SQL查询可能如下所示：

```sql
SELECT SUM(sales_amount) AS total_sales
FROM sales
WHERE sale_date >= '2024-04-01' AND sale_date < '2024-05-01';
```

## 7-描述一次您解决IT软件系统问题的经历。

**回答**: 在一个项目中，客户报告了一个关于数据处理的错误。我通过日志分析发现是数据格式不一致导致的。我编写了一个脚本来标准化数据格式，并更新了数据处理流程，从而解决了问题。

## 8-您如何保持对新技术的了解和学习？

**回答**: 我通过阅读技术博客、参加在线课程、参与开源项目以及参加行业会议来保持对新技术的了解。

## 9-您是否有医疗信息化行业的经验？如果有，请分享一些细节。

**回答**: 是的，我曾在一个医疗信息系统项目中工作，负责开发患者管理系统。我熟悉医疗数据的隐私和安全要求，并在项目中实现了符合HIPAA标准的数据处理流程。

## 10-您在团队合作中通常扮演什么角色？

**回答**: 我在团队中通常扮演技术专家和协调者的角色。我乐于分享知识，并帮助团队成员解决技术难题。

## 11-描述一次您接受短期出差的经历，以及您如何准备和适应的。

**回答**: 我曾被派往客户现场进行系统部署。我通过提前了解客户的需求和现场环境，准备了必要的文档和工具。在出差期间，我保持灵活性，快速适应了不同的工作环境。

## 12-您如何处理与非技术人员的沟通？

**回答**: 我通过使用非技术性的语言和类比来解释技术问题，确保非技术人员能够理解。同时，我也会倾听他们的需求和反馈，确保沟通的有效性。 

## 13-您在项目中是如何处理变更请求的？

**回答**: 我首先评估变更请求的影响，然后与项目团队和利益相关者讨论。如果变更可行，我会更新项目计划，并确保所有相关方都了解变更的影响。

## 14-您如何确保代码的质量和可维护性？

**回答**: 我遵循编码最佳实践，如编写清晰的注释、使用版本控制和进行代码审查。我还定期进行代码重构，以保持代码的整洁和高效。

## 15-您是否有使用过持续集成和持续部署（CI/CD）的经验？

**回答**: 是的，我在之前的项目中使用了Jenkins进行CI/CD。我配置了自动化构建、测试和部署流程，以提高开发效率和软件质量。

# （二）技术面试

## 1- linux相关

### 1）在Linux系统中，可以使用以下命令来监控CPU、内存、磁盘使用情况和网络流量：

1. **CPU使用情况**：

  - `top`：显示当前系统中占用CPU资源最多的进程信息。
  - `vmstat`：报告关于系统内存、交换分区、IO、CPU活动等虚拟内存统计信息。
  - `mpstat`：显示每个可用CPU的利用率及统计信息。

2. **内存使用情况**：

  - `free`：显示当前系统的空闲和已用内存量，以及被内核使用的缓冲区。
  - `cat /proc/meminfo`：查看详细的内存使用情况，包括物理内存、交换空间等信息。

3. **磁盘使用情况**：

  - `df`：显示磁盘空间的使用情况。
  - `iostat`：用于监测和报告每个磁盘的I/O统计信息。

4. **网络流量**：

  - `ifstat`：用来监视网络接口的数据传输状态。
  - `netstat`：显示网络连接、路由表、接口统计等信息。

-------------------------------------------

### 2）Linux系统中的**系统监控与维护涉及多种命令**，具体如下：

1. **进程监控**：

  - **top**：实时显示系统中各进程的资源占用状况及总体状况，是系统管理员常用的性能监控工具。
  - **ps**：显示当前进程的快照，可以用来查看哪些进程在运行以及它们的状态。
  - **htop**：相比top命令，htop提供了一个彩色的界面和更多的功能选项，使得进程监控更加直观和方便。

2. **内存使用情况**：

  - **free**：显示系统的空闲、已用物理内存及swap内存的使用情况，是监控内存的常用命令。
  - **vmstat**：提供虚拟内存、内核线程、磁盘、系统进程等信息，但需要先安装sysstat包才能使用。

3. **CPU信息**：

  - **cat /proc/cpuinfo**：查看CPU的详细信息，包括物理CPU个数、每个CPU的核心数以及逻辑CPU的数量。
  - **mpstat**：报告CPU的利用率和统计信息，通常与top命令一起使用来分析系统的整体性能。

4. **磁盘I/O监控**：

  - **iostat**：用于监控系统输入输出设备和CPU的使用情况，可以观察磁盘的读写速度和负载情况。
  - **df**：显示磁盘空间的使用情况，帮助管理员了解各个文件系统的容量和使用率。

5. **网络流量监控**：

  - **ifconfig**：查看和配置网络接口的参数，包括IP地址、子网掩码等。
  - **netstat**：显示网络连接、路由表、接口统计等信息，用于诊断网络问题。

6. **系统资源监控**：

  - **uptime**：显示系统已经运行了多长时间，当前有多少用户登录以及系统的负载情况。
  - **sar**：收集、报告或保存系统活动信息，常用于历史性能数据分析。

------------------------------------------------------

ping：测试网络连接的可达性。
`netstat -ntlp` 是一个用于显示网络连接、路由表和网络接口统计的命令。具体来说：

- **`-n`**：表示以数字形式显示地址和端口号，而不尝试查找它们的名称。

- **`-t`**：仅显示TCP连接。

- **`-l`**：仅显示监听套接字（即正在等待连接的服务器程序）。

- **`-p`**：显示与每个套接字/端口关联的进程ID和程序名称，有助于识别哪个程序正在使用特定的端口。

  -----------------

  

awk '{print $2}' file.log   列出log文件内容的第二列

------------

nc（netcat）/telnet 测试端口是否通畅
[root@iZ7xve0g1gz4tte7oyrzgiZ logs]# nc -vz 8.138.26.188 3306
Ncat: Version 7.91 ( https://nmap.org/ncat )
Ncat: Connected to 8.138.26.188:3306.
Ncat: 0 bytes sent, 0 bytes received in 0.01 seconds.

------------------



### 3）网络抓包：



[root@iZ7xve0g1gz4tte7oyrzgiZ logs]# sudo ngrep -q -d any 'GET' port 8090
interface: any
filter: ( port 8090 ) and (ip || ip6)
match: GET

抓包操作：
在Linux系统中进行服务器抓包通常涉及使用**tcpdump命令、tshark命令和ngrep命令**。

1. **tcpdump命令**：这是一个强大的命令行抓包工具，可以用于捕获网络数据包并对其进行显示或保存。例如，要抓取所有网络接口上的HTTP流量，可以使用`sudo tcpdump -i any port 80`。
2. **tshark命令**：这是Wireshark的文本版本，可以在不启动图形界面的情况下进行抓包，它提供了与Wireshark类似的功能。例如，要抓取特定IP地址的数据包，可以使用`sudo tshark -i any host 192.168.0.1`。
3. **ngrep命令**：这个工具类似于grep，专门用于网络数据包的抓取和过滤。它可以根据正则表达式匹配抓取的数据包。例如，要抓取所有包含"GET"的HTTP请求，可以使用`sudo ngrep -q -d any 'GET' port 80`。

这些工具都支持丰富的过滤选项，使得你可以根据需要定制要捕获的数据包类型。使用抓包工具时，建议采用合适的过滤条件来减少无关流量的干扰，以便更有效地分析目标数据。
1-
tcpdump是一个用于捕获网络数据包的命令行工具。以下是一个简单的tcpdump命令示例：

```bash
tcpdump -i eth0 -w output.pcap
```

这个命令将捕获网卡eth0上的所有数据包，并将它们保存到名为output.pcap的文件中。

2-
tshark是一个用于分析网络数据包的命令行工具，它是Wireshark的终端版本。以下是一个简单的tshark命令示例：

```bash
tshark -i eth0 -w output.pcap
```

这个命令将捕获网卡eth0上的所有数据包，并将它们保存到名为output.pcap的文件中。

3-
ngrep是一个用于搜索网络数据包中特定模式的命令行工具。以下是一个简单的ngrep命令示例：

```bash
ngrep -d 'en0' 'GET /index.html'
```

这个命令将在名为en0的网络接口上捕获所有包含"GET /index.html"模式的数据包，并将它们输出到终端。

### 4）常用命令：

#### awk命令的使用

`awk` 是一个强大的文本处理工具，它在Linux和Unix环境中广泛用于对文本数据进行分析、处理和格式化。`awk` 基于模式匹配和动作执行的机制，能够方便地进行行级和列级的数据处理。以下是一些`awk`命令的基本使用方法、示例和常见功能：

##### **基本语法**

```bash
awk [选项] '模式 {动作}' 文件
awk 'BEGIN {初始化动作} 模式 {动作} END {结束动作}' 文件
```

- `[选项]`：可选的命令行参数，例如 `-F` 用于指定字段分隔符。
- `'模式 {动作}'`：模式匹配部分，其中模式是正则表达式或条件判断，动作是当模式匹配时执行的命令序列。
- `BEGIN` 和 `END`：可选的块，分别在处理文件之前（初始化）和之后（清理或汇总）执行。在这些块中定义的动作不会与文件内容关联。
- `文件`：要处理的文本文件，可以是单个文件名、多个文件名（以空格分隔）或`-`表示标准输入。

##### **模式与动作**

**模式**：可以是正则表达式（如 `/pattern/`），用于匹配行中的文本；也可以是条件表达式（如 `$1 > 10`），用于测试某个字段的值。当模式匹配时，相应的动作会被执行。

**动作**：一组由分号分隔的命令，如 `print`、`printf`、`if`、`for`、`while`、`next`、`exit` 等。动作通常用于处理匹配行中的数据，如打印、计算、格式化输出等。

##### 示例：

以下列举几个`awk`实用的使用操作示例，涵盖数据筛选、格式化输出、统计计算和字段操作等方面：

1. **筛选特定列的特定值**：

   ```bash
   awk '$3 == "value" {print}' input.txt
   ```

   在`input.txt`中，仅打印出第三列（`$3`）值为`value`的行。

2. **打印文件的具体列**：

   ```bash
   awk '{print $6}' abc.txt
   ```

   打印abc.txt内容的第6列的信息。

3. **统计文件行数**：

   ```bash
   awk 'END {print NR}' file.txt
   ```

   输出`file.txt`的总行数。`END`块在处理完所有行后执行，`NR`是当前处理到的行数。

4. **计算某一列的总和**：

   ```bash
   awk '{sum+=$2} END {print "Total:", sum}' numbers.txt
   ```

   计算`numbers.txt`中每一行的第二列（`$2`）数值之和，并在处理完所有行后输出结果。

5. **格式化输出日期和时间**：

   ```bash
   date +%Y-%m-%d:%H:%M:%S | awk '{printf "%s\t%s\n", $1, strftime("%A, %B %d, %Y", mktime($1))}'
   ```

   获取当前日期和时间，然后使用`awk`的`strftime`函数将其格式化为更易读的形式（如`Monday, April .png 06, 2024`），并保持原始时间戳。

6. **按列对数据排序**：

   ```bash
   sort -t',' -k2,2 input.csv | awk -F',' '{print $0}' OFS=',' > sorted_output.csv
   ```

   先使用`sort`命令按第二列（`-k2,2`）对`input.csv`按逗号分隔排序，然后使用`awk`保留排序后的格式（设置`OFS=','`），将结果保存到`sorted_output.csv`。

7. **合并相同字段值的行**：

   ```bash
   awk '{a[$1]=a[$1]?a[$1] FS $2:$2} END{for(i in a) print i,a[i]}' input.txt
   ```

   对`input.txt`中第一列相同的行，将其第二列值合并，以空格分隔。

8. **计算文件字符数**：

   ```bash
   awk '{c+=length()} END{print "Total characters:", c}' file.txt
   ```

   计算`file.txt`中所有字符的总数，包括换行符。

9. **提取IP地址**：

   ```bash
   ifconfig | awk '/inet / {print $2}'
   ```

   从`ifconfig`命令的输出中，提取出以`inet`开头的行的第二个字段（通常是IP地址）。

10. **统计单词出现次数**：

    ```bash
    cat file.txt | awk '{for(i=1;i<=NF;i++) word[$i]++} END {for(w in word) print w, word[w]}'
    ```

    统计`file.txt`中每个单词（以空格分隔）的出现次数，并在处理完所有行后输出结果。

以上示例展示了`awk`在实际使用中的多种应用场景，包括筛选、格式化、统计、排序、合并、提取特定信息等，展现了其强大的文本处理能力。根据实际需求，可以灵活组合这些操作或编写更复杂的`awk`脚本来处理数据。

- `awk` 命令中单引号 `' '` 用于包围模式和动作，防止shell对其中的内容进行扩展。
- `awk` 的默认行为是逐行处理输入数据，但可以通过改变`RS`变量处理多行记录。
- `awk` 的动作部分支持完整的编程结构，如条件判断、循环、函数定义等。
- 在处理大量数据时，`awk` 效率较高，因为它一次处理一行，无需一次性加载整个文件到内存。

通过熟练掌握 `awk` 的模式匹配、变量使用、内置函数和动作编写，可以高效地处理各种文本数据任务，如筛选、排序、统计、格式转换等。结合实际情况，灵活运用上述示例和内置功能，可以满足大多数文本处理需求。

#### touch 指令

touch 指令创建空文件
基本语法: touch 文件名称

#### cp 指令

cp 指令拷贝文件到指定目录
基本语法: cp[选项] source dest

常用选项
-r:递归复制整个文件

应用案例:
案例1:将/home/hello.txt拷贝到/home/bbb目录下

cp hello.txt /home/bbb

案例2:递归复制整个文件夹，举例，比如将/home/bbb整个目录，拷贝到 /opt

cp -r /home/bbb/opt

使用细节
强制覆盖不提示的方法：\cp ,\cp -r /home/bbb/opt

#### rm 指令

说明：rm 指令移除文件或目录

基本语法: rm [选项] 要删除的文件或目录

常用选项
-r :递归删除整个文件夹

-f: 强制删除不提示

应用案例
案例1：将/home/hello.txt删除， rm /home/hello.txt

案例2: 递归删除整个文件夹 /home/bbb, rm -rf /home/bbb[删除整个文件夹，不提示]

使用细节: 强制删除不提示的方法，带上 -f 参数即可

#### mv 指令

说明: mv 移动文件与目录或重命名

基本语法: mv oldNameFile newNameFile (功能描述:重命名)

mv /temp/movefile/targetFolder (功能描述:移动文件)

应用实例:
案例1:将/home/cat.txt文件重新命名为pig.txt

mv /home/cat.txt pig.txt

案例2:将/home/pig.txt文件移动到/root目录下

mv /home/pig.txt /root

案例3:移动整个目录，比如将/opt/bbb移动到/home 下

mv /opt/bbb /home/

#### cat 指令

说明:cat 查看文件内容

基本语法:cat [选项] 要查看的文件

常用选项:
-n: 显示行号

应用案例
案例: /etc/profile 文件内容，并显示行号

cat -n /etc/profile

使用细节
cat只能浏览文件，而不能修改文件，为了浏览方便，一般会带上管道命令|more
cat -n/etc/profile | more「进行交互]

#### tail 指令

说明:tail用于输出文件中尾部的内容，默认情况下tail指令显示文件的后10行内容

基本语法:tail 文件 (功能描述:查看文件尾10行内容)

tail -n 5 (功能描述:查看文件尾5行内容，5可以是任意行数)

tail -f 文件 (功能描述:实时追踪该文档的所有更新)

#### find 指令

说明:find指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件或者目录显示在终端。

基本语法: find [搜索范围] [选项]

find -name file.txt

#### systemctl 设置服务的自启动状态

systemctl list-unit-files [ | grep 服务名] (查看服务开机启动状态, grep可以进行过滤)

systemctl enable 服务名 (设置服务开机启动)

systemctl disable 服务名 (关闭服务开机启动)

systemctl is-enabled 服务名(查询某个服务是否是自启动的)

应用案例
查看当前防火墙的状况，关闭防火墙和重启防火墙。

systemctl status firewalld

systemctl stop firewalld

systemctl start firewalld

#### firewall 指令

打开端口:firewall-cmd --permanent --add-port=端口号/协议(查看协议指令 :netstat -anp | more)
关闭端口:firewall-cmd --permanent --remove-port=端口号/协议号
打开或关闭重新载入，才能生效:firewall-cmd --reload
查询端口是否开发:firewall-cmd --query-port=端口/协议
应用案例
启用防火墙，测试111端口是否能telnet

开放111 端口

(1) firewall-cmd --permanent --add-port=111/tcp

(2)需要firewall-cmd --reload

关闭111端口

(1) firewall-cmd --permanent --remove-port=111/tcp

(2)需要firewall-cmd --reload

#### nmap指令  端口占用

查看端口占用情况

[root@JaBen ~]# nmap 8.138.26.188
Starting Nmap 7.91 ( https://nmap.org ) at 2024-04-02 23:33 CST
Nmap scan report for 8.138.26.188
Host is up (0.00050s latency).
Not shown: 992 filtered ports
PORT     STATE  SERVICE
22/tcp   open   ssh
80/tcp   open   http
3306/tcp open   mysql
8080/tcp closed http-proxy
8090/tcp open   opsmessaging
9090/tcp closed zeus-admin
9200/tcp closed wap-wsp
9876/tcp closed sd

Nmap done: 1 IP address (1 host up) scanned in 4.46 seconds

#### netstat命令，查看指定端口的占用情况

语法：netstat -anp | grep 端口号，安装netstat：yum -y install net-tools

命令：

```bash
netstat -anp | grep 15672
```

**命令功能**：
该命令用于在Linux环境下检查网络连接状态，并筛选出与特定端口号（本例中为15672）相关的活动信息。具体解释如下：

- `netstat`: 是一个网络工具，用于显示网络连接、路由表、网络接口统计等网络相关信息。它是Linux系统中常用的网络诊断命令之一。

- `-anp`:
  - `-a`：显示所有活动的TCP连接和监听（LISTEN）状态的TCP和UDP端口，不仅限于与Internet连接的那些。
  - `-n`：以数字形式显示地址和端口号，而非尝试解析为主机名和端口服务名。这使得输出更快，且避免了DNS解析失败导致的延迟或错误。
  - `-p`：显示每个连接对应的进程ID（PID）和进程名称（program name）。这有助于识别哪个进程正在使用特定端口。

- `|`: 管道符号，用于将前一个命令（`netstat -anp`）的输出作为输入传递给后一个命令（`grep 15672`）。

- `grep 15672`: `grep` 是一个文本搜索工具，用于在输入流中查找包含指定模式的行。这里指定的模式是 `15672`，即要查找包含该端口号的行。因此，它将过滤出`netstat -anp`输出中所有包含端口号 `15672` 的网络连接信息。

**命令执行效果**：
执行此命令后，终端将显示当前系统中所有与端口 `15672` 相关的网络连接状态信息。对于RabbitMQ来说，端口 `15672` 是其管理插件的默认Web界面端口。因此，执行该命令的结果可能包括以下信息：

- 如果RabbitMQ管理插件正在运行并监听在端口 `15672` 上，输出将显示一个或多个条目，表示有一个或多个进程（以其PID和进程名称标识）正在监听（`LISTEN`状态）或已建立（`ESTABLISHED`状态）与该端口相关的TCP连接。
- 如果没有任何进程与端口 `15672` 相关联，则命令输出为空，表示当前系统中没有进程在使用或监听该端口。

通过执行此命令，管理员可以快速验证RabbitMQ管理插件是否正在运行、是否在预期的端口上监听，或者是否有其他进程意外地占用该端口。这对于RabbitMQ的部署、故障排查和日常维护都非常有用。

#### rz、sz命令

rz上传对应目录

sz下载到桌面

#### tar 命令压缩/解压

压缩：

tar的常用组合为：tar -cvf test.tar 1.txt 2.txt 3.txt将1.txt 2.txt 3.txt 压缩到test.tar文件内

tar -zcvf test.tar.gz 1.txt 2.txt 3.txt将1.txt 2.txt 3.txt 压缩到test.tar.gz文件内，使用gzip模式

注意：-z选项如果使用的话，一般处于选项位第一个-f选项，必须在选项位最后一个

tar zcvf backup.tar.gz /home/ljb

1. 使用`tar`命令创建一个新的档案文件。
2. 采用gzip压缩算法对生成的档案文件进行压缩，生成名为`backup.tar.gz`的文件。
3. 在详细模式下运行，显示备份过程的详细信息。
4. 将` /home/ljb`目录及其所有内容（包括子目录和文件）打包到压缩后的档案文件`backup.tar.gz`中。

执行此命令后，您将在当前工作目录下得到一个名为`backup.tar.gz`的文件，其中包含了指定目录的完整备份，且已使用gzip进行了压缩。您可以将此文件保存到安全的位置以备恢复之用

解压：

常用的tar解压组合有tar -xvf test.tar解压test.tar，将文件解压至当前目录

tar -xvf test.tar -C /home/itheima解压test.tar，将文件解压至指定目录（/home/itheima）

tar -zxvf test.tar.gz -C /home/itheima以Gzip模式解压test.tar.gz，将文件解压至指定目录（/home/itheima）

#### zip压缩文件

压缩：

可以使用zip命令，压缩文件为zip压缩包语法：-r，被压缩的包含文件夹的时候，需要使用-r选项，和rm、cp等命令的-r效果一致

示例：

zip test.zip a.txt b.txt c.txt将a.txt b.txt c.txt 压缩到test.zip文件内

zip -r test.zip test itheima a.txt将test、itheima两个文件夹和a.txt文件，压缩到test.zip文件内

#### unzip 命令解压文件

使用unzip命令，可以方便的解压zip压缩包语法：-d，指定要解压去的位置，同tar的-C选项参数，被解压的zip压缩包文件

示例：

unzip test.zip，将test.zip解压到当前目录

unzip test.zip -d /home/itheima，将test.zip解压到指定文件夹内（/home/itheima）

#### getent命令

使用getent命令，可以查看当前系统中有哪些用户  语法： getent passwd

使用getent命令，同样可以查看当前系统中有哪些用户组  语法：getent group

#### set-hostname命令，修改主机名

hostnamectl set-hostname 主机名，修改主机名（需root）



#### scp命令 

频繁的在多台服务器之间相互传输数据。

为了更加方面的互相传输，我们补充一个命令：scp

scp命令是cp命令的升级版，即：ssh cp，通过SSH协议完成文件的复制。

其主要的功能就是：在不同的Linux服务器之间，通过`SSH`协议互相传输文件。

只要知晓服务器的账户和密码（或密钥），即可通过SCP互传文件。

语法：

scp [-r] 参数1 参数2

- -r选项用于复制文件夹使用，如果复制文件夹，必须使用-r
- 参数1：本机路径 或 远程目标路径
- 参数2：远程目标路径 或 本机路径

如：
scp -r /export/server/jdk root@node2:/export/server/
将本机上的jdk文件夹， 以root的身份复制到node2的/export/server/内
同SSH登陆一样，账户名可以省略（使用本机当前的同名账户登陆）

如：
scp -r node2:/export/server/jdk /export/server/
将远程node2的jdk文件夹，复制到本机的/export/server/内


##### scp命令的高级用法

cd /export/server
scp -r jdk node2:`pwd`/    # 将本机当前路径的jdk文件夹，复制到node2服务器的同名路径下
scp -r jdk node2:$PWD      # 将本机当前路径的jdk文件夹，复制到node2服务器的同名路径下

#### chmod命令

我们可以使用chmod命令，修改文件、文件夹的权限信息。注意，只有文件、文件夹的所属用户或root用户可以修改。

语法：chmod -R  权限 文件或文件夹

选项：-R，对文件夹内的全部内容应用同样的操作示例：chmod u=rwx,g=rx,o=x hello.txt ，将文件权限修改为：rwxr-x--x其中：u表示user所属用户权限，g表示group组权限，o表示other其它用户权限chmod -R u=rwx,g=rx,o=x test，将文件夹test以及文件夹内全部内容权限设置为：rwxr-x--x除此之外，还有快捷写法：chmod 751 hello.txt

权限可以用3位数字来代表，第一位数字表示用户权限，第二位表示用户组权限，第三位表示其它用户权限。数字的细节如下：r记为4，w记为2，x记为1，可以有：0：无任何权限，	即 ---1：仅有x权限，	即 --x2：仅有w权限	即 -w-3：有w和x权限	即 -wx4：仅有r权限	即 r--5：有r和x权限	即 r-x6：有r和w权限	即 rw-7：有全部权限	即 rwx

所以751表示： rwx(7) r-x(5) --x(1)

#### chown命令

使用chown命令，可以修改文件、文件夹的所属用户和用户组

普通用户无法修改所属为其它用户或组，所以此命令只适用于root用户执行

语法：chown 【-R】【用户】：【用户组】 文件或文件夹

选项，-R，同chmod，对文件夹内全部内容应用相同规则选项，用户，修改所属用户选项，用户组，修改所属用户组:用于分隔用户和用户组

chown root hello.txt，将hello.txt所属用户修改为root

chown :root hello.txt，将hello.txt所属用户组修改为root

chown root:itheima hello.txt，将hello.txt所属用户修改为root，用户组修改为itheima

chown -R root test，将文件夹test的所属用户修改为root并对文件夹内全部内容应用同样规则

### 5）请解释在Linux系统中，如何使用Shell脚本自动化日常任务？

Shell脚本是Linux系统中用于自动化任务的强大工具。

通过编写Shell脚本，我可以将一系列命令封装到一个可执行的脚本文件中。

例如，我可以使用脚本来自动化备份过程、系统监控、日志分析等任务。

Shell脚本可以使用条件语句、循环、函数等编程结构来实现复杂的逻辑。

通过在cron中设置定时任务，脚本可以定期自动执行，从而提高工作效率。

### 6）在Linux系统中，如何实现自动化的软件部署和更新？

在Linux系统中，实现自动化的软件部署和更新可以通过多种方法，包括使用包管理器、编写脚本、使用配置管理工具和持续集成/持续部署(CI/CD)系统。以下是一些具体步骤：

#### 1. 使用包管理器

Linux发行版通常都有自己的包管理器，如`apt`（Debian/Ubuntu）、`yum`（CentOS/RedHat）、`dnf`（Fedora/RHEL 8+）、`zypper`（openSUSE）等。

- **更新软件包索引**：

  ```bash
  sudo apt update  # Debian/Ubuntu
  sudo yum check-update  # CentOS/RedHat
  sudo dnf check-update  # Fedora/RHEL 8+
  sudo zypper refresh  # openSUSE
  ```

- **安装或更新软件包**：

  ```bash
  sudo apt upgrade  # Debian/Ubuntu
  sudo yum update  # CentOS/RedHat
  sudo dnf upgrade  # Fedora/RHEL 8+
  sudo zypper update  # openSUSE
  ```

#### 2. 编写自动化脚本

可以编写Shell脚本或使用其他自动化工具来执行安装、更新和配置软件的步骤。

- **编写脚本**：
  - 定义安装和更新软件所需的命令。
  - 包括错误检查和异常处理。
  - 使脚本可执行：`chmod +x script.sh`。

- **执行脚本**：
  - 手动运行脚本：`./script.sh`。
  - 使用`cron`定时任务自动运行脚本。

#### 3. 使用配置管理工具

如Ansible、Puppet、Chef等，它们可以帮助管理和自动化部署过程。

- **安装配置管理工具**：
  - 根据所选工具的文档进行安装和配置。

- **编写配置管理代码**（例如Ansible Playbook）：
  - 描述软件部署和配置的步骤。
  - 包括变量、任务和模块。

- **运行配置管理任务**：
  - 执行Playbook或其他配置任务以部署和更新软件。

#### 4. 持续集成/持续部署 (CI/CD)

使用Jenkins、GitLab CI/CD、Travis CI等CI/CD工具可以实现自动化测试和部署。

- **设置版本控制系统**（如Git）：
  - 将代码托管在远程仓库。

- **配置CI/CD流水线**：
  - 编写`.gitlab-ci.yml`、`Jenkinsfile`或`.travis.yml`等配置文件。
  - 定义作业和阶段，包括代码检出、构建、测试和部署步骤。

- **触发构建和部署**：
  - 推送代码变更以触发CI/CD流水线。
  - 或者设置Webhook自动响应代码变更事件。

#### 5. 监控和日志

为了确保自动化部署和更新的可靠性，需要监控系统和应用程序的状态，并收集相关日志。

- **设置监控系统**：
  - 使用Nagios、Zabbix、Prometheus等监控工具监控系统和服务状态。

- **配置日志收集**：
  - 使用rsyslog、Logstash、Fluentd等工具收集和分析日志。

- **设置报警通知**：
  - 配置邮件、Slack或其他即时通讯工具的报警通知。

通过上述步骤，可以实现Linux系统中软件部署和更新的自动化。这不仅可以提高效率，还可以减少人为错误，确保软件质量和系统稳定性。



## 2 -SQL相关

### 1）GROUP BY

`GROUP BY`语句用于将数据表中的数据按照指定的列进行分组，以便对每个分组执行聚合函数，如求和、平均值、计数等。

eg:按产品ID分组，计算每个产品的销售总量

SELECT product_id, SUM(quantity) as total_quantity
FROM orders
GROUP BY product_id;

### 2）InnoDB引擎与MyISAM引擎的区别 ?

①. InnoDB引擎, 支持事务, 而MyISAM不支持。

②. InnoDB引擎, 支持行锁和表锁, 而MyISAM仅支持表锁, 不支持行锁。

③. InnoDB引擎, 支持外键, 而MyISAM是不支持的。

![image-20240331130119463](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240331130119463.png)

### 3）左连接（LEFT JOIN）和右连接（RIGHT JOIN）

左连接（LEFT JOIN）是SQL中的一种连接方式，用于从两个表中返回匹配的行。当在左表中找到匹配的行时，它会返回右表中的匹配行，如果没有找到匹配的行，则返回NULL值。左侧的表会完全显示。

示例：

假设有两个表，一个是员工表（employees），另一个是部门表（departments）。通过department_id、id关联。

employees表：

| id   | name1 | department_id |
| ---- | ----- | ------------- |
| 1    | 张三  | 1             |
| 2    | 李四  | 2             |
| 3    | 王五  | 3             |
| 4    | 赵六  | 4             |

CREATE TABLE employees(id INT,name1 VARCHAR(32),department_id INT);

INSERT INTO employees VALUES(1,'张三',1),(2,'李四',2),(3,'王五',3),(4,'赵六',4);

SELECT * FROM employees;

departments表：

| id   | name2  |
| ---- | ------ |
| 1    | 人事部 |
| 2    | 财务部 |
| 3    | 技术部 |
| 5    | 实施部 |

CREATE TABLE departments(id INT,name2 VARCHAR(32));

INSERT INTO departments VALUES(1,'人事部'),(2,'财务部'),(3,'技术部'),(5,'实施部');

SELECT * FROM departments;

现在我们想要查询每个员工所在的部门名称，可以使用左连接实现：

```sql
SELECT employees.id,employees.name1, departments.name2
FROM employees
LEFT JOIN departments ON employees.department_id = departments.id;
```

查询结果：

| id   | name1 | name2  |
| ---- | ----- | ------ |
| 1    | 张三  | 人事部 |
| 2    | 李四  | 财务部 |
| 3    | 王五  | 技术部 |
| 4    | 赵六  | NULL   |

--------------------------



右连接(RIGHT JOIN):当在右表中找到匹配的行时，它会返回左表中的匹配行，如果没有找到匹配的行，则返回NULL值。右侧的表会完全显示。



SELECT
	departments.id,
	employees.name1,
	departments.name2 
FROM
	employees
	RIGHT JOIN departments ON employees.department_id = departments.id;



| id   | name1 | name2  |
| ---- | ----- | ------ |
| 1    | 张三  | 人事部 |
| 2    | 李四  | 财务部 |
| 3    | 王五  | 技术部 |
| 5    | NULL  | 实施部 |

### 4)存储过程

dilimiter用法：

您可能是指在MySQL中使用`DELIMITER`命令来设置SQL语句的结束符。在MySQL的命令行客户端或脚本中，通常使用分号 (`;`) 作为一条SQL语句的结束标志。然而，在编写存储过程、触发器、事件等复合SQL语句时，由于这些结构内部可能包含多条SQL语句，且各语句之间也用分号分隔，直接使用分号作为结束符会导致客户端在遇到第一个分号时就尝试执行语句，而非等待整个复合语句结束。为解决这个问题，可以使用`DELIMITER`命令临时更改SQL语句的结束符。

**如何使用`DELIMITER`设置结束符**：

1. **更改结束符**：
   使用`DELIMITER`命令，后跟您希望设置的新结束符。例如，将结束符更改为两个反斜杠 (`\\`)：

   ```sql
   DELIMITER \\
   ```

2. **编写复合语句**：
   在更改结束符后，您可以编写包含内部分号的复合语句，如存储过程。复合语句以您设定的新结束符结尾：

   ```sql
   CREATE PROCEDURE my_procedure()
   BEGIN
     SELECT * FROM users;
     INSERT INTO logs (message) VALUES ('Procedure executed');
   END \\
   ```

3. **恢复默认结束符**：
   在复合语句定义完毕后，恢复SQL语句的默认分号结束符：

   ```sql
   DELIMITER ;
   ```

**示例说明**：

假设您要创建一个简单的存储过程，其中包含两条SQL语句：

```sql
DELIMITER \\
CREATE PROCEDURE my_procedure()
BEGIN
  SELECT * FROM users;
  INSERT INTO logs (message) VALUES ('Procedure executed');
END \\
DELIMITER ;
```

在这个示例中：

- 首先使用`DELIMITER \\`命令将结束符更改为两个反斜杠。
- 接着定义存储过程`my_procedure`，其中包含两条用分号分隔的SQL语句：一条是查询`users`表，另一条是向`logs`表插入一条记录。
- 存储过程定义以两个反斜杠结束。
- 最后使用`DELIMITER ;`命令恢复SQL语句的默认分号结束符。

通过设置和恢复`DELIMITER`，您可以确保复合语句在MySQL客户端中正确解析和执行，而不被内部的分号提前截断。这样，当您执行`CALL my_procedure();`时，整个存储过程会作为一个单元被调用。





-----------------



MySQL的存储过程（Stored Procedure）是一种在数据库服务器端预先定义、存储和编译好的一组SQL语句集合，它具有特定的名称，可以接收输入参数，执行一系列数据操作，并可返回结果或输出参数。存储过程旨在封装复杂的业务逻辑，提高代码复用性，简化客户端应用程序的开发，同时有助于增强数据安全性、提升性能和降低网络开销。

理解MySQL存储过程的关键点包括：

1. **封装与复用**：存储过程将一组相关的SQL语句打包在一起，形成一个可重复调用的单元。应用程序只需通过调用存储过程的名称和传递参数，即可执行一系列复杂的数据库操作，无需每次都编写和发送完整的SQL代码。

2. **局部变量与条件控制**：存储过程内部可以声明并使用局部变量，支持流程控制语句（如`IF...THEN...ELSE`、`CASE`、`LOOP`、`WHILE`等），使得存储过程能够处理复杂的逻辑分支和循环操作。

3. **事务管理**：存储过程内部可以包含事务处理语句（如`START TRANSACTION`、`COMMIT`、`ROLLBACK`），方便对一系列操作进行原子性的管理，确保数据的一致性。

4. **安全性与权限控制**：通过授予对存储过程的特定权限，可以限制用户仅能执行特定的操作，而无需直接访问底层表，增强了数据安全性。同时，存储过程在服务器端执行，减少了敏感数据在网络中传输的风险。

**示例：**

以下是一个简单的MySQL存储过程示例，该存储过程用于给指定用户账户增加一定金额：

```sql
DELIMITER //
CREATE PROCEDURE add_funds_to_account (
    IN p_account_id INT,    -- 输入参数：账户ID
    IN p_amount DECIMAL(10, 2)  -- 输入参数：要增加的金额
)
BEGIN
    DECLARE v_current_balance DECIMAL(10, 2);  -- 声明局部变量：当前余额

    -- 查询当前账户余额
    SELECT balance INTO v_current_balance FROM accounts WHERE account_id = p_account_id;

    -- 检查账户是否存在
    IF v_current_balance IS NOT NULL THEN
        -- 更新账户余额（增加金额）
        UPDATE accounts SET balance = v_current_balance + p_amount WHERE account_id = p_account_id;
        
        -- 提交事务
        COMMIT;
        
        SELECT CONCAT('成功为账户', p_account_id, '增加金额', p_amount, '，当前余额为', v_current_balance + p_amount) AS message;
    ELSE
        SELECT '账户不存在' AS message;
    END IF;
END //
DELIMITER ;
```

在这个示例中：

- 创建了一个名为`add_funds_to_account`的存储过程，它接收两个输入参数：`p_account_id`（账户ID）和`p_amount`（要增加的金额）。

- 在存储过程内部，声明了一个局部变量`v_current_balance`用于存储查询到的账户当前余额。

- 使用`SELECT ... INTO`语句查询指定账户的当前余额，并将结果存储到`v_current_balance`变量中。

- 使用`IF`语句检查账户是否存在（即`v_current_balance`是否为非NULL）。如果存在，执行更新操作，增加账户余额，并通过`COMMIT`提交事务。

- 存储过程在成功执行更新后，返回一条包含操作结果的消息。如果账户不存在，则返回相应的错误消息。

应用程序调用这个存储过程时，只需传递账户ID和要增加的金额，如：

```sql
CALL add_funds_to_account(123, 100.00);
```

通过这个示例，可以看到MySQL存储过程如何封装复杂的业务逻辑（查询、更新、条件判断、事务管理），并以一种易于调用的方式提供给客户端应用程序使用。这样，不仅简化了客户端代码，还实现了数据库操作的集中管理，有利于维护和优化。



------------------------------

#### a.涉及变量

在MySQL中变量分为三种类型: 系统变量、用户定义变量、局部变量。

##### 1-系统变量

系统变量 是MySQL服务器提供，不是用户定义的，属于服务器层面。分为全局变量（`GLOBAL`）、会话变量（`SESSION`）。

查看系统变量：

```
show session variables
show variables like 'auto%';
select @@global.autocommit;
```

设置系统变量：

```
set session autocommit :=1;
set @@autocommit :=1;
```

注意:

如果没有指定`SESSION/GLOBAL`，默认是`SESSION`，会话变量。

mysql服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在 `/etc/my.cnf`中配置。

- 全局变量(GLOBAL): 全局变量针对于所有的会话。
- 会话变量(SESSION): 会话变量针对于单个会话，在另外一个会话窗口就不生效了。

##### 2-用户自定义变量：

用户定义变量 是用户根据需要自己定义的变量，用户变量不用提前声明，在用的时候直接用 "@变量名" 使用就可以。其作用域为当前连接

赋值，使用：

```
select @my_name:='ljb',@my_hobby:='mysql',@my_age:=20;
set @my_course：='math';
select count(*) into @my_count from employees;
select @my_age,@my_count,@my_course,@my_hobby,@my_name;
```

##### 3-局部变量：

局部变量是根据需要定义的在局部生效的变量，访问之前，需要`DECLARE`声明。可用作存储过程内的局部变量和输入参数，局部变量的范围是在其内声明的BEGIN ... END块。

```
create procedure p3()
begin
    declare emp_count1 int;
    select count(*) into emp_count1 from employees;
    select emp_count1;
end;

call p3();
```

#### b.IF判断：

```
IF 条件1 THEN
    .....
ELSEIF 条件2 THEN     -- 可选
    .....
ELSE              -- 可选
    .....
END IF;

根据定义的分数score变量，判定当前分数对应的分数等级。

score >= 85分，等级为优秀。
score >= 60分 且 score < 85分，等级为及格。
score < 60分，等级为不及格。

create procedure p4()
begin
    declare score int default 60;
    declare result varchar(20);
    if score>=85 then
        set result:='优秀';
        elseif score>=60 then
        set result:='及格';
        else
        set result:='不及格';
    end if;
    select result;
end;

call p4();
```



以上的需求我们虽然已经实现了，但是也存在一些问题，比如：score 分数我们是在存储过程中定义死的，而且最终计算出来的分数等级，我们也仅仅是最终查询展示出来而已。

那么我们能不能，把score分数动态的传递进来，计算出来的分数等级是否可以作为返回值返回呢？答案是肯定的，我们可以通过接下来所学习的 参数 来解决上述的问题。

#### c.存储过程的参数：

1、介绍：
参数的类型，主要分为以下三种：IN、OUT、INOUT。 具体的含义如下：

| 类型  | 含义                                         | 备注 |
| ----- | -------------------------------------------- | ---- |
| IN    | 该类参数作为输入，也就是需要调用时传入值     | 默认 |
| OUT   | 该类参数作为输出，也就是该参数可以作为返回值 |      |
| INOUT | 既可以作为输入参数，也可以作为输出参数       |      |



```sql
CREATE PROCEDURE 存储过程名称 ([ IN/OUT/INOUT 参数名 参数类型 ])
BEGIN
	-- SQL语句
END ;

```

案例一

根据传入参数score，判定当前分数对应的分数等级，并返回。

- score >= 85分，等级为优秀。
- score >= 60分 且 score < 85分，等级为及格。
- score < 60分，等级为不及格。

```
create procedure p5(in score int,out result varchar(20))
begin
        if score>=85 then
        set result:='优秀';
    elseif score>=60 then
        set result='及格';
    else
        set result:='不及格';
    end if;

end;

call p5(100,@result);
select @result;
```

案例二

将**传入**的200分制的分数，进行换算，换算成百分制，然后**返回**。

```
create procedure p6(inout score double)
begin
    set score:=score*0.5;
end;

set @score:=500;
call p6(@score);
select @score;
```

#### d.case语法：

1. 语法

case结构及作用，和我们在基础篇中所讲解的流程控制函数很类似。有两种语法格式：

```sql
-- 含义： 当条件search_condition1成立时，执行statement_list1，当条件search_condition2成立时，执行statement_list2， 否则就执行 statement_list
CASE
	WHEN search_condition1 THEN statement_list1
	[WHEN search_condition2 THEN statement_list2] ...
	[ELSE statement_list]
END CASE;
```

```
案例：
根据传入的月份，判定月份所属的季节（要求采用case结构）。

1-3月份，为第一季度
4-6月份，为第二季度
7-9月份，为第三季度
10-12月份，为第四季度

create procedure p8(in month int)
begin
    declare result varchar(20);
    case
        when month>=1 and month<=3 then
        set result:='第一季度';
        when month>=4 and month<=6 then
            set result:='第二季度';
        when month>=7 and month<=9 then
            set result:='第三季度';
        when month>=10 and month<=12 then
            set result:='第四季度';
        else
            set result:='非法参数';
    end case;
    select concat('您输入的月份是：',month,'所属的季度是：',result);
end;

call p8(1);
```



```
if语句实现：

create procedure p12(in month int,out result varchar(20))
begin

   if month>=1 and month<=3 then
            set result:='第一季度';
        elseif month>=4 and month<=6 then
            set result:='第二季度';
        elseif month>=7 and month<=9 then
            set result:='第三季度';
        elseif month>=10 and month<=12 then
            set result:='第四季度';
        else
            set result:='非法参数';
        end if;
    end;
call p12(7,@result);
select concat ('所属季度为：',@result);
```

提示

注意：如果判定条件有多个，多个条件之间，可以使用 and 或 or 进行连接。

--------------------



### 5）事务

#### a.两种方式：

##### 1、修改事务的提交方式

set @@autocommit=0

commit; -- 提交

rollback;--回滚

##### 2、开启事务

start transaction;

--提交

commit;

--回滚

rollback;

#### b.并发事务的问题

##### 1-脏读：一个事务读到另一个事务还没有提交的数据

![image-20240401235539625](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240401235539625.png)

##### 2-不可重复读：一个事务先后读取同一条记录，但两次读取的数据不同

![image-20240401235819927](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240401235819927.png)

##### 3-幻读：一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了“幻影”

![image-20240402000209272](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240402000209272.png)

#### c.事务的隔离级别

![image-20240402000705408](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240402000705408.png)

说明：√可能出现 ×不会出现

##### 四种：

###### 1）读未提交

###### 2）读已提交

###### 3）可重复读

###### 4）串行化

#### d.查看隔离级别：

```
select @@transaction_isolation;
```

#### e.设置隔离级别：

set session/global transaction isolation lever read uncommitted;

![image-20240402003337731](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240402003337731.png)



### 6）索引

#### a、概述：

index,有序的数据结构，高效获取数据

优缺点：

优点：提高查询效率，降低排序成本

缺点：占用磁盘空间，降低更新表的速度

#### b、索引结构：

![image-20240402161439964](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240402161439964.png)

在存储引擎层实现的，不同的存储引擎有不同的结构

##### B+Tree：重点

![image-20240402164411985](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240402164411985.png)

以最大度数为5的为例（每个节点最多存储4个KEY,5个指针）

树的度数指的是一个节点的子节点个数。

![image-20240402162450424](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240402162450424.png)

相对于B-Tree：

1-所有的数据都会出现在叶子节点

2-叶子节点形成一个单向链表

##### Hash索引：

精确匹配  不支持范围查询，但查询效率高

![image-20240402165202695](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240402165202695.png)



Hash索引是一种特殊的数据库索引类型，它利用哈希算法（如MD5、SHA等）将数据表中的特定列（索引列）的值快速映射到一个固定大小的、通常是连续的内存空间中，这个空间通常被组织成哈希表的形式。哈希表由多个“桶”（bucket）组成，每个桶内存储一组具有相同哈希值或经过冲突解决后落入同一桶的数据行指针。

理解Hash索引的关键在于理解其基于哈希函数的工作原理以及如何利用这种机制快速定位数据。以下通过一个具体的例子来说明：

假设我们有一个学生信息表 `students`，其中包含 `id`（主键）、`name` 和 `age` 列，现在我们要在 `name` 列上创建一个Hash索引来加速对学生的姓名进行等值查询。

**创建Hash索引**

首先，数据库系统会选择一个合适的哈希函数，比如 `hash_fn()`。当在 `name` 列上创建Hash索引时，会对表中的每一个学生的姓名应用此哈希函数：

```
hash_value = hash_fn(student.name)
```

计算出的 `hash_value` 是一个固定长度的数值，通常远小于原始姓名的字节长度。这个数值将被用来确定哈希表中的桶位置。

**哈希表结构**

哈希表由若干个桶组成，假设总共有 `N` 个桶。为了将 `hash_value` 映射到桶的位置，通常会使用取模运算：

```
bucket_index = hash_value % N
```

这样，每个学生的姓名经过哈希函数计算后，都会被分配到哈希表中特定的一个桶里。如果不同的姓名计算出来的 `hash_value` 恰好除以 `N` 后余数相同，就会发生哈希冲突，这些冲突的姓名将被存储在同一桶内，通常通过链表或其他冲突解决策略来管理。

**查询示例**

现在假设我们要执行以下查询：

```sql
SELECT * FROM students WHERE name = '张三';
```

使用Hash索引的查询过程如下：

1. **计算哈希值**：对查询条件 `'张三'` 应用相同的哈希函数 `hash_fn()`，得到 `hash_value`。

2. **定位桶**：使用 `hash_value` 计算桶的索引 `bucket_index`，即 `bucket_index = hash_value % N`。

3. **查找数据**：直接访问哈希表中索引为 `bucket_index` 的桶。如果桶内只有一个元素且其哈希值与计算出的 `hash_value` 相同，说明找到了匹配的记录，直接返回该记录。如果有多个元素（发生哈希冲突），则需要按照链表顺序逐个比较姓名，直到找到与 `'张三'` 完全相同的记录。

通过这样的过程，Hash索引能够在大多数情况下仅通过一次哈希计算和一次内存访问即可找到目标数据，从而极大地提高了查询效率，尤其适用于等值查询场景。

需要注意的是，Hash索引并不适合所有的查询场景，其主要限制包括：

- **仅支持等值查询**：由于其基于哈希值的特性，不支持范围查询、排序、最左前缀匹配等操作。
- **哈希冲突**：虽然可以通过链表等方式缓解，但在大量冲突的情况下可能会影响查询性能。
- **无法利用部分索引列**：必须使用索引列的全部内容计算哈希值，不能像B树索引那样仅使用索引列的一部分进行查询。
- **不存储原始值**：有些Hash索引仅存储哈希值和数据行指针，不存储字段值本身，这可能导致额外的行数据读取。

综上所述，Hash索引是一种针对特定查询模式（主要是等值查询）设计的高效索引结构，通过哈希函数将数据快速映射到内存中的特定位置，从而实现近乎瞬间的查找能力。但其适用范围有限，对于复杂查询或需要排序的情况可能需要配合其他类型的索引来实现最佳性能。

##### 思考：

为什么InnoDB存储引擎选择使用B+tree索引结构?

1-相对于二叉树,层级更少,搜索效率高;
2-对于B-tree,无论是叶子节点还是非叶子节点,都会保存数据,这样导致一页中存储的键值减少,指针跟着减少,要同样保存大量数据,只能增加树的高度,导致性能降低;
3-相对Hash索引,B+tree支持范围匹配及排序操作;

#### c、索引的分类：

主键索引、唯一索引、常规索引、全文索引

在 InnoDB 存储引擎中，根据索引的存储形式，又可以分为以下两种：

聚集索引(Clustered Index)：只会有一个

二级索引(Secondary Index)

- 聚集索引的叶子节点下挂的是这一行的数据 。
- 二级索引的叶子节点下挂的是该字段值对应的主键值。

**回表查询**： 这种先到二级索引中查找数据，找到主键值，然后再到聚集索引中根据主键值，获取 数据的方式，就称之为回表查询。

##### 思考题：

- 以下两条SQL语句，那个执行效率高? 为什么?

  A. select * from user where id = 10 ;

  B. select * from user where name = 'Arm' ;

  备注: id为主键，name字段创建的有索引；

解答：

- A 语句的执行性能要高于B 语句。
- 因为A语句直接走聚集索引，直接返回数据。 而B语句需要先查询name字段的二级索引，然后再查询聚集索引，也就是需要进行回表查询。

##### 思考题：

- InnoDB主键索引的B+tree高度为多高呢?

#### d、索引语法：

创建：

CREAT [UNIQUE | FULLTEXT ] INDEX  index_name on table_name (字段名)



查看索引：

SHOW INDEX FROM table_name;

删除索引：

drop index index_name on table_name;

#### e.索引的设计原则

1）数据量大，查询频繁的表建立索引。

2）作为查询条件where 排序 order by 分组 group by  后面的字段建立索引

3）区分度高，尽量建立唯一索引

4）字段长度较长，建立前缀索引

5）使用联合索引

6）控制索引的数量

7)列不能存储NULL值，使用NOT NULL约束。

#### f、SQL性能分析

##### 1）执行频次

show global status like "Com_______"

##### 2）慢查询日志

show variables like 'slow_query_log';

慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有 SQL语句的日志。

MySQL的慢查询日志默认没有开启，我们可以查看一下系统变量 slow_query_log。

show variables like 'slow_query_log';

如果要开启慢查询日志，需要在MySQL的配置文件（/etc/my.cnf）中配置如下信息：

#开启MySQL慢日志查询开关

slow_query_log=1

#设置慢日志的时间为5秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志

long_query_time=5

1. 检查慢查询日志 ：

最终我们发现，在慢查询日志中，只会记录执行时间超多我们预设时间（5s）的SQL，执行较快的SQL是不会记录的。

那这样，通过慢查询日志，就可以定位出执行效率比较低的SQL，从而有针对性的进行优化

##### 3）profile详情

show profiles 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。通过have_profiling参数，能够看到当前MySQL是否支持profile操作：

select @@have_profiling;

可以看到，当前MySQL是支持 profile操作的，但是开关是关闭的。可以通过set语句在session/global级别开启profiling：

SET profiling = 1;

执行一系列的业务SQL的操作，然后通过如下指令查看指令的执行耗时：

-- 查看每一条SQL的耗时基本情况
show profiles;

-- 查看指定query_id的SQL语句各个阶段的耗时情况
show profile for query query_id;

SHOW PROFILE FOR QUERY 19;

-- 查看指定query_id的SQL语句CPU的使用情况
show profile cpu for query query_id;

SHOW PROFILE cpu FOR QUERY 11;

##### 4)explain执行计划

EXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序。

-- 直接在select语句之前加上关键字 explain / desc
EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件 ;

Explain 执行计划中各个字段的含义:

| 字段          | 含义                                                         |
| ------------- | ------------------------------------------------------------ |
| id            | 查询的序号，包含一组数字，表示查询中执行select子句或操作表的顺序 **两种情况** id相同，执行顺序从上往下 id不同，id值越大，优先级越高，越先执行 |
| select_type   | 查询类型，主要用于区别普通查询，联合查询，子查询等的复杂查询 1、simple ——简单的select查询，查询中不包含子查询或者UNION 2、primary ——查询中若包含任何复杂的子部分，最外层查询被标记 3、subquery——在select或where列表中包含了子查询 4、derived——在from列表中包含的子查询被标记为derived（衍生），MySQL会递归执行这些子查询，把结果放到临时表中 5、union——如果第二个select出现在UNION之后，则被标记为UNION，如果union包含在from子句的子查询中，外层select被标记为derived 6、union result:UNION 的结果 |
| table         | 输出的行所引用的表                                           |
| type          | 显示联结类型，显示查询使用了何种类型，按照从最佳到最坏类型排序 1、system：表中仅有一行（=系统表）这是const联结类型的一个特例。 2、const：表示通过索引一次就找到，const用于比较primary key或者unique索引。因为只匹配一行数据，所以如果将主键置于where列表中，mysql能将该查询转换为一个常量。 3、eq_ref:唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于唯一索引或者主键扫描。 4、ref:非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有匹配某个单独值的行，可能会找多个符合条件的行，属于查找和扫描的混合体。 5、range:只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引，一般就是where语句中出现了between,in等范围的查询。这种范围扫描索引扫描比全表扫描要好，因为它开始于索引的某一个点，而结束另一个点，不用全表扫描。 6、index:index 与all区别为index类型只遍历索引树。通常比all快，因为索引文件比数据文件小很多。 7、all：遍历全表以找到匹配的行。 注意:一般保证查询至少达到range级别，最好能达到ref。 |
| possible_keys | 指出MySQL能使用哪个索引在该表中找到行                        |
| key           | 显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL。查询中如果使用覆盖索引，则该索引和查询的select字段重叠。 |
| key_len       | 表示索引中使用的字节数，该列计算查询中使用的索引的长度在不损失精度的情况下，长度越短越好。如果键是NULL,则长度为NULL。该字段显示为索引字段的最大可能长度，并非实际使用长度。 |
| ref           | 显示索引的哪一列被使用了，如果有可能是一个常数，哪些列或常量被用于查询索引列上的值 |
| rows          | 根据表统计信息以及索引选用情况，大致估算出找到所需的记录所需要读取的行数 |
| Extra         | 包含不适合在其他列中显示，但是十分重要的额外信息 1、Using filesort：说明mysql会对数据适用一个外部的索引排序。而不是按照表内的索引顺序进行读取。MySQL中无法利用索引完成排序操作称为“文件排序” 2、Using temporary:使用了临时表保存中间结果，mysql在查询结果排序时使用临时表。常见于排序order by和分组查询group by。 3、Using index:表示相应的select操作用使用覆盖索引，避免访问了表的数据行。如果同时出现using where，表名索引被用来执行索引键值的查找；如果没有同时出现using where，表名索引用来读取数据而非执行查询动作。 4、Using where :表明使用where过滤 5、using join buffer:使用了连接缓存 6、impossible where:where子句的值总是false，不能用来获取任何元组 7、select tables optimized away：在没有group by子句的情况下，基于索引优化Min、max操作或者对于MyISAM存储引擎优化count（*），不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 8、distinct：优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。 |

#### g、最左前缀法则

如果索引关联了多列（联合索引），要遵守最左前缀法则，最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。如果跳跃某一列，索引将部分失效（后面的字段索引失效）。要是第一列的字段没有出现在查询语句，索引失效

思考题:

当执行SQL语句: explain select * from tb_user where age = 31 and status = '0' and profession = '软件工程'； 时，是否满足最左前缀法则，走不走上述的联合索引，索引长度？

mysql> explain select * from tb_user where age = 31 and status = '0' and profession = '软件工程';

![image-20240405160523564](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240405160523564.png)

可以看到，是完全满足最左前缀法则的，索引长度54，联合索引是生效的。

注意 ： 最左前缀法则中指的最左边的列，是指在查询时，联合索引的最左边的字段(即是第一个字段)必须存在，与我们编写SQL时，条件编写的先后顺序无关

MySQL索引的最左前缀法则强调了在使用复合索引时，查询条件必须从索引最左侧列开始，并保持连续，才能有效利用索引来提升查询性能。

##### 1）范围查询

```
explain select * from tb_user where profession = '软件工程' and age > 30 and status = '0';
```

联合索引中，出现范围查询(>,<)，范围查询右侧的列索引失效。

![image-20240405161206272](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240405161206272.png)

当范围查询使用> 或 < 时，走联合索引了，但是索引的长度为49，就说明范围查询右边的status字段是没有走索引的

```sql
explain select * from tb_user where profession = '软件工程' and age >= 30 and status = '0';
```

![image-20240405161337933](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240405161337933.png)

当范围查询使用>= 或 <= 时，走联合索引了，但是索引的长度为54，就说明所有的字段都是走索引的。

所以，在业务允许的情况下，尽可能的使用类似于 >= 或 <= 这类的范围查询，而避免使用 > 或 <

## 3 -SQL面试题汇总

### 1） 汇总统计分组分析 

表：sales，字段：product_id, category_id, quantity_sold, date_sold 问题描述：按产品类别分组，计算每个月的总销售量（quantity_sold）。

SELECT category_id, DATE_FORMAT(date_sold, '%Y-%m') as month, SUM(quantity_sold) as total_quantity_sold
FROM sales
GROUP BY category_id, month;

### 2 ）查询每个班学生数 

表：stu_table，字段：id, class_id 问题描述：编写SQL查询，统计每个班级的学生人数。

SELECT class_id, COUNT(*) as student_count
FROM stu_table
GROUP BY class_id;

### 3 ）复杂查询 

表：employees, departments, salaries 问题描述：找出每个部门年薪最高的员工的姓名、部门名称及年薪

SELECT e.name, d.department_name, s.salary
FROM employees e
JOIN departments d ON e.department_id = d.department_id
JOIN salaries s ON e.employee_id = s.employee_id
WHERE (e.department_id, s.salary) IN (
    SELECT department_id, MAX(salary)
    FROM employees e
    JOIN salaries s ON e.employee_id = s.employee_id
    GROUP BY department_id
);

### 4 ）多表查询 

表：orders, customers, products 问题描述：给出订单表、客户表和产品表的结构，编写查询以显示每个客户的最近一次订单的订单号、产品名称、购买日期。

SELECT o.order_id, p.product_name, o.purchase_date
FROM orders o
JOIN customers c ON o.customer_id = c.customer_id
JOIN products p ON o.product_id = p.product_id
WHERE (c.customer_id, o.purchase_date) IN (
    SELECT customer_id, MAX(purchase_date)
    FROM orders
    GROUP BY customer_id
);

这个查询首先通过连接三个表来获取所需的数据。然后，使用子查询来找到每个客户的最新购买日期。最后，将结果与原始表进行连接，以获取相应的订单号和产品名称。

### 5 ）Top N问题 

表：user_activity，字段：user_id, activity_type, activity_count 问题描述：为每个用户找出其最常进行的前3种活动类型及其对应活动次数。

解析： 这个问题可以通过使用SQL的窗口函数来解决。首先，我们需要对每个用户的活动类型进行分组，并计算每种活动的总次数。然后，我们可以使用ROW_NUMBER()窗口函数来为每种活动分配一个行号，这个行号是基于活动次数的降序排列的。最后，我们只需要选择行号在前3的活动即可。

WITH activity_rank AS (
    SELECT 
        user_id, 
        activity_type, 
        activity_count,
        ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY activity_count DESC) as rank
    FROM 
        user_activity
)
SELECT 
    user_id, 
    activity_type, 
    activity_count
FROM 
    activity_rank
WHERE 
    rank <= 3;

### 6） 窗口函数应用 

表：employee_performance，字段：employee_id, quarter, performance_score 问题描述：计算每位员工在每个季度相对于其所在部门同季度员工的绩效排名。 

解析： 这个问题可以通过使用SQL的窗口函数来解决。首先，我们需要对每个季度和部门进行分组，并计算每位员工的绩效得分。然后，我们可以使用RANK()窗口函数来为每位员工分配一个排名，这个排名是基于绩效得分的降序排列的。最后，我们只需要选择每个季度和部门的排名即可。

WITH performance_rank AS (
    SELECT 
        employee_id, 
        quarter, 
        performance_score,
        RANK() OVER(PARTITION BY quarter, department_id ORDER BY performance_score DESC) as rank
    FROM 
        employee_performance
)
SELECT 
    employee_id, 
    quarter, 
    rank
FROM 
    performance_rank;

这段代码首先创建了一个名为performance_rank的临时表，其中包含了每个季度和部门的所有员工的绩效得分以及基于绩效得分的排名。然后，我们从这个临时表中选择了每个季度和部门的排名，即每位员工在每个季度相对于其所在部门同季度员工的绩效排名。

### 7 ）慢查询优化 

问题描述：针对给定的SQL查询（例如，一个复杂的联接查询），请指出可能导致性能瓶颈的因素，并提出优化建议。

慢查询优化是一个复杂的过程，需要根据具体的SQL查询进行分析。但是，以下是一些常见的可能导致性能瓶颈的因素和优化建议：

1. 索引不足或不合理：如果查询中涉及到的列没有建立索引或者索引设置不合理，那么查询效率会很低。建议根据查询中的条件和排序字段，合理地创建索引。

2. 数据量过大：如果表中的数据量非常大，那么查询效率也会受到影响。建议对表进行分区、分表等操作，将数据分散到多个表中，提高查询效率。

3. 复杂的联接查询：如果查询中涉及到多个表的联接操作，那么查询效率也会受到影响。建议使用合适的联接方式（如HASH JOIN、MERGE JOIN、NEST LOOP JOIN等），并尽量减少联接操作的次数。

4. 子查询过多：如果查询中包含过多的子查询，那么查询效率也会受到影响。建议将子查询转换为连接查询或者使用临时表等方式，减少子查询的使用。

5. SQL语句编写不规范：如果SQL语句编写不规范，例如使用了SELECT *、没有使用LIMIT等，那么查询效率也会受到影响。建议遵循SQL编写规范，避免使用不必要的SELECT *、ORDER BY等操作。

6. 数据库配置不合理：如果数据库的配置不合理，例如缓存大小不足、连接数过多等，那么查询效率也会受到影响。建议根据实际需求调整数据库的配置参数。

### 8 ）子查询与连接查询的选择 

问题描述：描述何时应使用子查询，何时应使用连接查询，并举例说明。 

在执行数据库查询时，选择使用子查询还是连接查询取决于具体的查询需求和性能考虑。以下是子查询和连接查询的特点以及适用场景：

**子查询的特点**：

- **执行方式**：子查询是先执行内层的查询，再将结果应用于外层查询的条件中。
- **结果集**：子查询的结果通常用作外部查询的过滤条件，而不是直接展示所有数据。
- **灵活性**：子查询可以在SELECT、FROM、WHERE等多个地方使用，提供了较高的灵活性。
- **适用场景**：当需要对查询结果进行进一步的筛选或计算时，或者当查询逻辑较为复杂时，子查询是一个不错的选择。

**连接查询的特点**：

- **执行方式**：连接查询是一次性执行的，同时处理所有需要连接的表。
- **结果集**：连接查询的结果集直接包含了所有需要的数据，可以直接展示出来。
- **效率**：在效率上，连接查询通常高于子查询，因为它可以减少查询的层级和复杂性。
- **适用场景**：当需要从多个表中获取数据并将其合并到一个结果集中时，连接查询是更合适的选择。

**举例说明**：

- 如果需要查询所有销售额超过平均水平的销售人员，可以先使用子查询计算出平均销售额，然后再用这个结果作为外部查询的条件来筛选出符合条件的销售人员。
- 如果要列出所有客户及其订单详情，可以使用连接查询直接将客户表和订单表连接起来，一次性获取所有相关信息。

总的来说，在选择使用子查询还是连接查询时，应该根据查询的目的、数据的复杂度以及性能要求来决定。如果查询逻辑复杂或者需要逐步筛选数据，子查询可能更适合；而如果需要高效地合并多个表的数据，连接查询可能是更好的选择。

### 9） 索引设计 

问题描述：在一张包含大量数据的表中，如何设计合适的索引来加速常见查询？

在设计索引以加速常见查询时，需要考虑以下几个因素：

1. 查询模式：了解常见的查询模式是设计索引的第一步。如果大部分查询都是基于某个特定列进行的，那么为这个列创建索引可能会提高查询性能。

2. 选择性：选择性是指索引列中不同值的数量与表中行数的比率。选择性越高，索引的效果越好。例如，性别列的选择性较低（通常只有两个值），而ID列的选择性较高（每个值都是唯一的）。

3. 复合索引：如果查询经常同时使用多个列进行过滤，可以考虑创建复合索引。复合索引的顺序应该根据查询的模式来确定，最常用的列应该放在前面。

4. 覆盖索引：如果查询只需要返回索引列中的数据，而不需要访问表的其他数据，那么可以使用覆盖索引来加速查询。

5. 最左前缀原则：在使用复合索引时，查询条件必须使用到索引的最左侧列，才能充分利用索引。

6. 索引维护：索引虽然可以提高查询速度，但是也会降低写入速度，因为每次插入、更新或删除数据时，都需要更新索引。因此，需要根据实际需求来平衡查询速度和写入速度。

7. 使用短索引：如果索引列的长度很长，可以考虑使用短索引。短索引可以减小索引的大小，从而提高查询速度。

8. 避免过度索引：虽然索引可以提高查询速度，但是过多的索引会导致写入速度下降，同时也会增加存储空间的使用。因此，需要避免过度索引。

总的来说，设计索引是一个需要根据具体需求和查询模式来进行的过程，需要不断地测试和调整以达到最佳效果。

不要着急，一点一点来，理解至上

### 10 ）数据一致性保证 

问题描述：解释ACID属性，并阐述在事务处理中如何确保数据的一致性。

ACID属性是**数据库事务正确执行的四个基本要素，它们确保了数据的准确性和可靠性**。具体如下：

1. **原子性（Atomicity）**：原子性指的是一个事务要么全部完成，要么全部不执行，不会出现只执行了部分操作的情况。这保证了事务作为一个不可分割的工作单位。
2. **一致性（Consistency）**：一致性是指事务必须使数据库从一个一致性状态转变为另一个一致性状态。在事务开始之前和结束之后，数据库的完整性约束必须得到满足。
3. **隔离性（Isolation）**：隔离性要求每个事务都独立执行，不受其他事务的干扰。即使在多个事务并发执行的情况下，也要保证这一点。隔离性通过锁机制和不同的隔离级别来防止脏读、不可重复读和幻读等问题。
4. **持久性（Durability）**：持久性意味着一旦事务被提交，它对数据库的修改就是永久性的，即使发生系统故障也不会丢失这些修改。

为了确保数据的一致性，事务处理中采取了以下措施：

1. **使用锁定机制**：在事务处理期间对数据加锁，防止其他事务访问正在被修改的数据，从而避免不一致性的产生。
2. **设置检查点**：定期设置检查点，以确保在发生故障时能够恢复到一个已知的一致状态。
3. **日志记录**：记录事务的更改，以便在系统故障后能够重做或撤销事务，确保数据的持久性和一致性。
4. **两阶段提交**：在分布式系统中，采用两阶段提交协议来确保所有节点上的事务都能够成功提交或回滚，保持数据的全局一致性。
5. **隔离级别设置**：根据实际需求选择合适的事务隔离级别，平衡性能和一致性的需求。

通过上述措施，数据库管理系统（DBMS）能够在写入或更新资料的过程中保证事务的正确性和可靠性，从而确保数据的一致性。

### 11 ）存储过程

面试题示例： 题目：创建一个存储过程，接受两个参数：一个产品ID和一个折扣率。该存储过程应更新指定产品的价格，将其乘以给定的折扣率。同时，记录更新操作的时间和操作员（假设为当前登录用户）到一个审计表（如product_price_audit）中。 问题描述： 定义存储过程的输入参数、返回值（如有）。 编写SQL语句更新产品表中的价格。 使用系统函数获取当前时间与当前登录用户信息。 插入审计记录到product_price_audit表，包含产品ID、原价格、新价格、折扣率、操作时间、操作员等信息。MySQL的语法来编写存储过程。

解析：

首先，我们需要定义存储过程的输入参数和返回值。在这个例子中，输入参数是产品ID和折扣率，没有返回值。

然后，我们需要编写SQL语句来更新产品表中的价格。这可以通过将产品表中的价格乘以给定的折扣率来实现。

接着，我们需要使用系统函数获取当前时间和当前登录用户信息。在MySQL中，我们可以使用NOW()函数获取当前时间，使用CURRENT_USER()函数获取当前登录用户信息。

最后，我们需要插入审计记录到product_price_audit表。这需要包含产品ID、原价格、新价格、折扣率、操作时间、操作员等信息。

DELIMITER //
CREATE PROCEDURE UpdateProductPrice(IN product_id INT, IN discount DECIMAL(5,2))
BEGIN
  -- 获取原价格
  DECLARE original_price DECIMAL(10,2);
  SELECT price INTO original_price FROM products WHERE id = product_id;

  -- 计算新价格
  DECLARE new_price DECIMAL(10,2);
  SET new_price = original_price * discount;

  -- 更新产品价格
  UPDATE products SET price = new_price WHERE id = product_id;

  -- 获取当前时间和当前登录用户
  DECLARE current_time TIMESTAMP;
  DECLARE current_user VARCHAR(50);
  SET current_time = NOW();
  SET current_user = CURRENT_USER();

  -- 插入审计记录
  INSERT INTO product_price_audit(product_id, original_price, new_price, discount, operation_time, operator)
  VALUES (product_id, original_price, new_price, discount, current_time, current_user);
END //
DELIMITER ;

注意：这个存储过程假设你已经有一个名为products的产品表，其中有一个名为price的列，以及一个名为product_price_audit的审计表，其中包含product_id、original_price、new_price、discount、operation_time和operator列。

### 12）NOW();CURRENT_DATE();CURRENT_TIME();CURRENT_TIMESTAMP();区别

SELECT NOW();
2024-04-06 21:29:16
SELECT CURRENT_DATE();
2024-04-06
SELECT CURRENT_TIME();
21:29:17
SELECT CURRENT_TIMESTAMP();
2024-04-06 21:29:17

### 13）在MySQL中，可以使用 `CREATE` 语句创建以下对象：

1. **数据库（DATABASE）**：
   使用 `CREATE DATABASE` 语句创建新的数据库。可以指定数据库名称，并可选地指定字符集和校对规则。
2. **表（TABLE）**：
   使用 `CREATE TABLE` 语句创建新的数据表。可以定义表的结构，包括列名、数据类型、约束（如主键、外键、唯一键、检查约束等）、索引、默认值、注释等。
3. **视图（VIEW）**：
   使用 `CREATE VIEW` 语句创建虚拟表（视图），它基于一个或多个实际表的查询结果。视图提供了一种简化数据访问的方式，用户可以像操作普通表一样查询视图，但实际上视图不存储数据，而是动态生成结果。
4. **索引（INDEX）**：
   虽然在创建表时通常会直接定义索引，但也可以使用 `CREATE INDEX` 或者在 `ALTER TABLE` 语句中单独创建索引来增强已存在表的查询性能。索引可以基于一列或多列，并可以选择不同的索引类型，如B-tree、Full-text、Hash等。
5. **存储过程（PROCEDURE）**：
   使用 `CREATE PROCEDURE` 语句创建存储过程，这是一种预编译的SQL代码块，包含一系列SQL语句和控制流语句。存储过程可以接受参数，执行复杂逻辑，并返回结果。
6. **函数（FUNCTION）**：
   使用 `CREATE FUNCTION` 语句创建用户定义的函数，它可以接受参数并返回一个值。用户定义的函数可以是SQL函数，也可以是采用其他编程语言（如C或Java）编写的外部函数。
7. **触发器（TRIGGER）**：
   使用 `CREATE TRIGGER` 语句创建触发器，它是与特定表相关的事件驱动程序，当发生指定的数据库操作（如INSERT、UPDATE、DELETE）时自动执行。
8. **事件调度器（EVENT）**：
   使用 `CREATE EVENT` 语句创建定时任务，允许在特定时间点或按照预定的计划自动执行一组SQL语句。
9. **序列（SEQUENCE）**：
   在某些MySQL版本或特定插件（如MySQL 8.0及更高版本的原生序列支持，或者某些第三方提供的序列实现）中，可以使用 `CREATE SEQUENCE` 语句创建序列对象，用于生成连续的整数或递增/递减的数值，通常用作表中自动增长字段的替代或补充。



### 14）备份数据库：

###### 命令：mysqldump -u root -p Cloud_order > backup_order.sql

[root@JaBen ljb]# mysqldump -u root -p Cloud_order > backup_order.sql
Enter password: 
[root@JaBen ljb]# ll
total 148
-rw-r--r-- 1 root    root      2637 Apr  7 13:38 backup_order.sql
-rw-r--r-- 1 root    root      2810 Apr  3 00:05 ChatGPT.md
-rwxr-xr-x 1 root    root        10 Apr  2 09:26 ljb.sh
-rw-r--r-- 1 root    root    110341 Apr  6 23:46 ms0406.txt
-rw-r--r-- 1 tcpdump tcpdump  25245 Mar 26 16:24 output.pcap
[root@JaBen ljb]# mysqldump -u root -p Cloud_order | gzip > backup_order.sql.gz
Enter password: 
[root@JaBen ljb]# ll
total 152
-rw-r--r-- 1 root    root      2637 Apr  7 13:38 backup_order.sql
-rw-r--r-- 1 root    root      1203 Apr  7 13:41 backup_order.sql.gz
-rw-r--r-- 1 root    root      2810 Apr  3 00:05 ChatGPT.md
-rwxr-xr-x 1 root    root        10 Apr  2 09:26 ljb.sh
-rw-r--r-- 1 root    root    110341 Apr  6 23:46 ms0406.txt
-rw-r--r-- 1 tcpdump tcpdump  25245 Mar 26 16:24 output.pcap

[root@JaBen ljb]# gunzip backup_order.sql.gz
[root@JaBen ljb]# ll
total 152
-rw-r--r-- 1 root    root      2637 Apr  7 13:38 backup_order1.sql
-rw-r--r-- 1 root    root      2637 Apr  7 13:41 backup_order.sql
-rw-r--r-- 1 root    root      2810 Apr  3 00:05 ChatGPT.md
-rwxr-xr-x 1 root    root        10 Apr  2 09:26 ljb.sh
-rw-r--r-- 1 root    root    110341 Apr  6 23:46 ms0406.txt
-rw-r--r-- 1 tcpdump tcpdump  25245 Mar 26 16:24 output.pcap
[root@JaBen ljb]# 

### 15）备份某个库某张表的数据：

###### 命令：mysqldump -u root -p mysql employees > backup_mysql_employees.sql 

[root@JaBen ljb]# mysqldump -u root -p mysql employees > backup_mysql_employees.sql 
Enter password: 
[root@JaBen ljb]# ll
total 1436
-rw-r--r-- 1 root    root       2006 Apr  7 14:13 backup_mysql_employees.sql
-rw-r--r-- 1 root    root    1305335 Apr  7 14:05 backup_mysql.sql
-rw-r--r-- 1 root    root       2637 Apr  7 13:38 backup_order1.sql
-rw-r--r-- 1 root    root       2637 Apr  7 13:41 backup_order.sql
-rw-r--r-- 1 root    root       2373 Apr  7 14:00 backup_user.sql
-rw-r--r-- 1 root    root       2810 Apr  3 00:05 ChatGPT.md
-rwxr-xr-x 1 root    root         10 Apr  2 09:26 ljb.sh
-rw-r--r-- 1 root    root     110341 Apr  6 23:46 ms0406.txt
-rw-r--r-- 1 tcpdump tcpdump   25245 Mar 26 16:24 output.pcap

### 16）MySQL体系结构

连接层，服务层，引擎层，存储层

### 17）存储引擎

InnoDB:事务，行级锁，外键

重点介绍三种:MyISAM、InnoDB、MEMORY

1. MylSAM不支持事务、也不支持外键，但其访问速度快，对事务完整性没有要求。
2. InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是比起MylSAM存储引擎，InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。
3. MEMORY存储引擎使用存在内存中的内容来创建表。每个MEMORY表只实际对应-个磁盘文件。MEMORY类型的表访问非常得快，因为它的数据是放在内存中的，并且默认使用HASH索引。但是一旦MySQL服务关闭，表中的数据就会丢失掉,表的结构还在。

### 18）SQL优化

#### 1-insert into 优化：

大批量插入数据：如1000W条  可以使用load 指令优化

按格式罗列，如下命令操作：

-- 客户端连接服务端时，加上参数 -–local-infile
mysql –-local-infile -u root -p

-- 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关
set global local_infile = 1;

-- 执行load指令将准备好的数据，加载到表结构中
load data local infile '/root/sql1.log' into table tb_user fields terminated by ',' lines terminated by '\n' ;

#### 2-limit优化

覆盖索引、子查询

#### 3-group by 优化

在分组操作中，我们需要通过以下两点进行优化，以提升性能：

1. 在分组操作时，可以通过索引来提高效率。
2. 分组操作时，索引的使用也是满足最左前缀法则的。

## [#](https://frxcat.fun/database/MySQL/MYSQL_SQL_optimization/#limit-优化)limit 优化

### 19）DDL-表操作-查询

1-查询当前数据库所有表
SHOW TABLES;
2-查询表结构
DESC tb_user;
3-查询指定表的建表语句
SHOW CREATE TABLE tb_user;

CREATE TABLE `tb_user` (
  `id` int NOT NULL AUTO_INCREMENT COMMENT '主键',
  `name` varchar(50) NOT NULL COMMENT '用户名',
  `phone` varchar(11) NOT NULL COMMENT '手机号',
  `email` varchar(100) DEFAULT NULL COMMENT '邮箱',
  `profession` varchar(11) DEFAULT NULL COMMENT '专业',
  `age` tinyint unsigned DEFAULT NULL COMMENT '年龄',
  `gender` char(1) DEFAULT NULL COMMENT '性别 , 1: 男, 2: 女',
  `status` char(1) DEFAULT NULL COMMENT '状态',
  `createtime` datetime DEFAULT NULL COMMENT '创建时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_user_phone` (`phone`),
  KEY `idx_user_name` (`name`),
  KEY `idx_user_pro_age_sta` (`profession`,`age`,`status`),
  KEY `idx_user_email` (`email`)
) ENGINE=InnoDB AUTO_INCREMENT=25 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='系统用户表'

### 20）DDL-表操作-修改

修改表名
ALTER TABLE 表名 RENAME TO 新表名;
修改字段名，类型，删除（DROP）

### 21）DDL-表操作-删除

DROP TABLE [IF EXISTS] 表名;

### 22）DML-添加数据

1-给指定字段添加数据
INSERT INTO 表名（字段名1,字段名2,...）VALUES(值1,值2,...);
2-给全部字段添加数据
INSERT INTO 表名 VALUES(值1,值2,...);
3-批量添加数据
INSERT INTO 表名（字段名1,字段名2,...）VALUES(值1,值2,...),(值1,值2,...),(值1,值2,...);
INSERT INTO 表名 VALUES(值1,值2,...),(值1,值2,...),(值1,值2,...);

### 23）DML-修改数据

UPDATE 表名 SET 字段名1=值1,字段名2=值2，...[WHERE 条件];

### 24）DML-删除数据

DELETE FROM 表名 [WHERE 条件];

### 25）约束：

#### 1-概述、分类

![image-20240409122617750](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240409122617750.png)

### 26）锁：

全局锁：共享锁（读锁）、排他锁（写锁）

表级锁：意向锁（IS/IX）、元数据锁（MDL）

行级锁：间隙锁和临键锁

### 27）InnoDB存储引擎

1. 表空间

表空间是InnoDB存储引擎逻辑结构的最高层， 如果用户启用了参数 innodb_file_per_table(在8.0版本中默认开启) ，则每张表都会有一个表空间（xxx.ibd），一个mysql实例可以对应多个表空间，用于存储记录、索引等数据。

2.段

段，分为数据段（Leaf node segment）、索引段（Non-leaf node segment）、回滚段（Rollback segment），InnoDB是索引组织表，数据段就是B+树的叶子节点， 索引段即为B+树的非叶子节点。段用来管理多个Extent（区）。

3.区

区，表空间的单元结构，每个区的大小为1M。 默认情况下， InnoDB存储引擎页大小为16K， 即一个区中一共有64个连续的页。

4.页

页，是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。

5.行

行，InnoDB 存储引擎数据是按行进行存放的。

在行中，默认有两个隐藏字段：

- Trx_id：每次对某条记录进行改动时，都会把对应的事务id赋值给trx_id隐藏列。
- Roll_pointer：每次对某条引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。

### 28）索引失效的情况

#### 1.索引列运算

不要在索引列上进行运算操作， 索引将失效。

#### 2.字符串不加引号

字符串类型字段使用时，不加引号，索引将失效。

#### 3.模糊查询

如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。
在like模糊查询中，在关键字后面加%，索引可以生效。而如果在关键字前面加了%，索引将会失效。

#### 4.or连接条件

用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。

#### 5.数据分布影响

如果MySQL评估使用索引比全表更慢，则不使用索引。

就是因为MySQL在查询时，会评估使用索引的效率与走全表扫描的效率，如果走全表扫描更快，则放弃索引，走全表扫描。 因为索引是用来索引少量数据的，如果通过索引查询返回大批量的数据，则还不如走全表扫描来的快，此时索引就会失效。

### 29）**在MySQL中，如何优化查询性能？**

**答案：**优化MySQL查询性能的方法有很多，包括但不限于：使用索引来加速查询；优化SQL查询语句，避免使用SELECT *，而是指定需要的列；使用EXPLAIN命令来分析查询的执行计划；定期清理和优化表，如通过OPTIMIZE TABLE命令；调整MySQL的配置参数，如内存分配、缓存大小等，以适应不同的工作负载。

### 30）请描述您在配置MySQL数据库时，如何确保数据的安全性和完整性。

**答案：**在配置MySQL数据库时，我会采取多种措施来确保数据的安全性和完整性。这包括设置强密码策略，限制对数据库的访问权限，使用SSL加密数据库连接，定期进行数据备份，以及实施事务管理来确保数据的一致性。此外，我还会监控数据库的日志文件，以便及时发现和解决潜在的安全问题。

### 31）**在Linux系统中，如何查找并修复磁盘空间不足的问题？**

**答案：**首先，我会使用`df -h`命令来查看各个分区的磁盘使用情况。如果发现某个分区空间不足，我会使用`du -sh`命令来查找占用空间最多的文件和目录。对于不再需要的文件，我会及时清理。如果空间仍然不足，我可能会考虑删除不必要的文件或服务，或者移动一些数据到其他存储设备。在必要时，我还会考虑增加磁盘空间或重新分配分区大小。

### 32）请描述您在实施MySQL数据库时，如何处理并发访问的问题？

**答案：**在处理MySQL数据库的并发访问问题时，我会首先分析并发访问的模式和需求。我会使用`SHOW PROCESSLIST`命令来查看当前的进程和锁定情况。为了提高并发性能，我会优化数据库的索引策略，确保查询能够高效地使用索引。此外，我会调整MySQL的配置参数，如`innodb_thread_concurrency`和`max_connections`，来控制并发连接的数量。在必要时，我还会考虑使用读写分离、负载均衡等技术来分散数据库的压力。

## 4 -HSAF框架

1.1	分析hsaf架构
1.1.1 Hsaf框架的几个包
注意这里需要讲解一下几个包的作用，以及几个层级的调用关系。
以下内容是官方内容

1. hsa-api
   接口申明，包括DTO。如果微服务需要对其他提供接口，则需在该模块中添加代码
2. hsa-db
   mybatis的sql mapper文件。跟has-biz层的dao联合使用，完成数据库层操作。

3. hsa-biz
   业务逻辑，包括业务代码，公共功能引入，例如hsaf的core包，数据源配置xml。
   Controlle、Service、BO、Dao

4. hsa-main-generic
   开源云适配层，包括应用启动，适配层pom引入，配置相关xml，properties
   配置文件和spring注入（这里需要讲解一下appliaction这几个注解的意义在哪里以及spring注入的本质是什么）：

api：服务对外暴露的接口
biz：处理业务逻辑的代码部分
db：操作数据库的sql文件
ali、tencent、genneric，powercloud：
不同平台的启动类，每个启动类有不同的参数配置

## 5 -服务器的理解

服务器可以被理解为一个功能强大的计算机，它在网络上为其他电脑、手机、平板等设备提供服务。想象一下，你正在网上购物，当你点击购买按钮时，你的请求就被发送到了一个远程的服务器上。这个服务器处理你的请求，与你银行的服务器通信完成支付，然后告诉你商品已经购买成功。服务器通常需要高性能、高可靠性和安全性，因为它们要处理大量的数据和请求。比如，像淘宝、亚马逊这样的大型电商网站，他们的服务器必须能够同时处理成千上万甚至更多的在线交易。

总的来说，可以把服务器想象成一个工厂的车间，而你的电脑、手机就像是消费者。你在商店下单后，工厂就开始工作，生产出你需要的商品，然后通过物流送到你手上。在这个过程中，服务器就是那个日夜不停工作的车间。

## 6 -Nginx等负载均衡器的配置

### 1）轮询（Round Robin）：

是一种负载均衡算法，可以想象成一个老师正在给学生发课本。

假设有一堆新书和五个等待领书的学生，老师的任务是确保每个学生都得到一本书。老师采取一个简单的方法：
从第一排的第一个学生开始，逐个向后发书，当到达最后一排的最后一个学生后，又从头开始，如此循环往复。

在这个例子中：

- **老师**：代表负载均衡器（如Nginx）。
- **学生**：代表客户端，即等待接收服务的用户。
- **书**：代表服务资源，比如网页、图片或任何服务器上的资源。
- **发书的过程**：就是负载均衡器的分配过程，即如何将请求分配给后端服务器。

轮询算法的特点在于其简单和公平性。每个请求按照顺序被发送到不同的服务器，就像每个学生最终都会从老师那里领到一本书一样。
如果所有服务器的性能相似，这种策略可以很好地工作，因为它确保了请求在服务器之间平均分配。

在现实世界的服务器环境中，轮询算法通过负载均衡器实现。例如，Nginx会将客户端的请求依次发送到定义在upstream块中的不同后端服务器。
如果一个服务器处理请求并返回结果给用户后，下一个请求会被发送到列表中的下一台服务器，就像老师继续向下一个学生发书一样。

这种策略非常适合处理短时、无状态的请求，如静态网页的加载，但对于需要保持会话状态或有特定处理需求的请求，
可能需要更复杂的负载均衡策略来保证服务的质量和用户体验。

### 2）权重轮询：

权重轮询是指通过为服务器分配不同的权重值来调整每个服务器接收请求的比例。

举个简单例子理解：比如根据老师的专业程度和经验来分配教学任务。

假设一个学校有3个数学老师（A、B和C），他们分别有1年、2年、3年的教学经验。学校决定根据他们的工作经验来分配教学任务，使得经验丰富的老师可以教授更多的班级。因此，学校给每位老师分配了一个权重，分别是1、2、3。现在有6个班级需要安排数学课，学校决定按照老师的权重来轮流分配这些班级。这意味着A老师会教1个班级，B老师会教2个班级，C老师会教3个班级。当所有的班级都被分配完毕后，再从头开始，继续按权重分配新的班级。   在这个例子中：

- **学校**：代表负载均衡器（如Nginx）。
- **老师**：代表后端服务器（如Tomcat）。
- **教学任务（班级）**：代表客户端的请求。
- **工作经验（权重）**：代表服务器的处理能力或资源。

权重轮询确保了更强大的服务器（像有更多教学经验的老师）可以处理更多的请求，从而更充分地利用了服务器的资源，并提高了整体的处理效率。
在Nginx中实施权重轮询时，可以在upstream块中指定每台服务器及其对应的权重值。在Nginx.conf配置文件，如添加如下内容：

```nginx
upstream Nginx_server {
    server 8.138.26.188 weight=3;
    server 8.138.26.100;
}
```

在这个配置中，表示8.138.26.188这台机器将接收三倍于8.138.26.100这台机器的请求量。这种策略适用于服务器性能不同或某些服务器拥有更多资源的情况，使得负载均衡更加灵活和高效。

### 3）IP哈希：

IP哈希是一种基于客户端IP地址来决定后端服务器的负载均衡算法。这种方法的核心思想是将来自同一IP地址的请求始终发送到同一台服务器，
这有助于会话保持（session persistence），即维持客户端和服务器之间的持续交互状态。

想象一下你是一位大型活动的组织者，你需要为参加活动的人分配座位。
为了确保每个人都能找到自己的座位而不会引起混乱，你决定根据每个人的入场券号码来分配座位。
每个入场券号码都对应着一个特定的座位。当人们到达活动现场时，
他们只需查看自己的入场券号码，就能快速找到自己的座位。

在这个例子中：

- **组织者**：代表负载均衡器（如Nginx）。
- **入场券号码**：代表客户端的IP地址。
- **座位**：代表后端服务器。
- **查找座位的过程**：就是负载均衡器的分配过程，即如何根据IP地址将请求分配给后端服务器。

IP哈希算法通过计算客户端IP地址的哈希值来确定应该将请求发送到哪台服务器。由于同一个客户端的IP地址是不变的，
所以每次这个客户端发起的请求都会被发送到相同的后端服务器。这有助于保持客户端与服务器之间的会话状态，
例如在在线购物网站上保持用户的登录状态和购物车信息。

在Nginx中实施IP哈希时，您会在upstream块中指定后端服务器，而无需其他特殊配置。
Nginx会自动使用客户端的IP地址来进行哈希计算，并将请求发送到相应的服务器。例如：

```nginx
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    ip_hash;
}
```

在这个配置中，`ip_hash`指令告诉Nginx使用IP哈希算法来分配请求。这种策略适用于需要会话保持的应用，
如在线购物、用户认证等场景，因为它可以保证用户的连续操作被同一台服务器处理，从而避免会话信息的丢失或不一致。

### 4）最少连接（Least Connections）

是一种负载均衡算法，它根据后端服务器当前的活跃连接数来分配新的请求。
这种策略旨在将新请求分配给当前连接数最少的服务器，从而避免过载并提高响应速度。

想象一下

广州地铁3号线，你要去乘坐地铁，高峰期的时候，到地铁站，工作人员会做引流，会有不同的站台，当其中一个站台人数过多的时候，工作人员会引导你去人员相对较少的站台等待。这样，可以避免某一站台过于拥挤，而其他站台却空荡荡的情况。

在这个例子中：

- **工作人员**：代表负载均衡器（如Nginx）。
- **站台**：代表后端服务器。
- **等待登车的乘客**：代表客户端的请求。
- **引导乘客的过程**：就是负载均衡器的分配过程，即如何根据服务器的当前连接数将请求分配给后端服务器。

最少连接算法通过监控每台服务器的活跃连接数来工作。
当一个请求到达时，负载均衡器会检查所有后端服务器的当前连接数，
并将请求发送到连接数最少的那台服务器。
这有助于平衡服务器的负载，特别是当请求处理时间不一或服务器性能不同时。

在Nginx中实施最少连接时，您需要在upstream块中指定后端服务器，并使用`least_conn`指令。例如：

```nginx
upstream backend {
    least_conn;
    server backend1.example.com;
    server backend2.example.com;
}
```

在这个配置中，`least_conn`指令告诉Nginx使用最少连接算法来分配请求。这种策略适用于服务器处理能力不同或请求处理时间不一致的场景，
因为它可以确保每台服务器都能够有效地处理请求，避免了某些服务器因为过载而响应缓慢的问题。

## 7 -proxy_pass作用

`proxy_pass`指令是Nginx中用于反向代理的指令，它用于将客户端的请求转发到指定的后端服务器。

举个例子，假设我们有一个Nginx服务器，它的IP地址是192.168.1.100，端口号是80。
我们希望将所有以`/api`开头的请求转发到另一个服务器，该服务器的IP地址是192.168.1.200，端口号是8080。
我们可以在Nginx配置文件中使用`proxy_pass`指令来实现这个功能。

```nginx
http {
    server {
        listen 80;

        location /api {
            proxy_pass http://192.168.1.200:8080;
        }
    }
}
```

在这个例子中，当客户端发送一个以`/api`开头的请求到Nginx服务器时，Nginx会将请求转发到`http://192.168.1.200:8080`，即后端服务器。
这样，客户端无需知道后端服务器的存在，只需要与Nginx服务器进行通信即可。

## 8 -负载均衡的理解

负载均衡可以想象成一个大商场的导购服务。假设一个商场有多家卖衣服的店铺，当顾客（客户端）想要买衣服时，他们通常会先找商场的导购（负载均衡器），
而不是直接决定去哪家店。

- **没有负载均衡器的情况**：如果商场没有导购服务，顾客们可能会根据自己的喜好或经验直接选择一家店铺，这可能会导致某些热门店铺非常忙碌，而其他店铺却很闲。
- **有负载均衡器的情况**：有了导购服务后，当顾客来到商场，导购会根据各店铺的情况（比如哪一家不那么忙、哪一家的衣服正在打折等）来推荐店铺给顾客。
  这样，每家店铺都能比较平均地接待顾客，不会有的店铺过于繁忙而有的店铺很闲。

在技术世界中，负载均衡器的作用类似：

- 当有多个服务器（就像多家店铺）可以处理用户的请求时，负载均衡器会按照某种策略（就像导购根据店铺情况推荐）将请求分配给不同的服务器，
  确保每个服务器都不会过载，从而提高整体的服务效率和可靠性。

这个例子中，商场的导购服务就像是Nginx或其他负载均衡软件，它们帮助客户端的请求找到合适的服务器，使得所有的服务器资源得到均衡利用，
同时也提高了服务的可用性和响应速度。

## 9-实现Tomcat的负载均衡

可以采用Nginx作为反向代理服务器来分配请求到不同的Tomcat实例。以下是具体的实现步骤：

1. **环境准备**：

- 确保至少有两个Tomcat服务器部署成功并运行，以保证可以进行负载均衡。
- 安装并配置Nginx服务，确保它能够正常运作。

2. **配置Nginx**：

- 在Nginx的配置文件中定义一个`upstream`块，该块中指定了参与负载均衡的Tomcat服务器组。例如：

  ```nginx
  upstream backend {
      server backend1.example.com weight=5;
      server backend2.example.com;
      server backend3.example.com;
  }
  ```

  在这个例子中，`backend1.example.com`具有更高的权重，意味着它将接收更多的请求。

- 在`server`块中配置`location`，使用`proxy_pass`指令将请求转发到上面定义的`upstream`服务器组。例如：

  ```nginx
  server {
      location / {
          proxy_pass http://backend;
      }
  }
  ```

  这里的`http://backend`是之前定义的别名，指向`upstream`块中配置的服务器组。

3. **测试配置**：

- 保存Nginx配置文件后，重新加载或重启Nginx服务以应用更改。
- 进行测试以确保请求被正确地分发到不同的Tomcat服务器。

通过以上步骤，Nginx将会根据配置的权重和轮询机制将客户端的请求分发到不同的Tomcat服务器，从而实现负载均衡。此外，Nginx还可以提供静态资源的缓存和SSL终止等功能，进一步提升网站的性能和安全性。

## 10 -Redis相关

### 1）Redis高可用和分布式的解决方案

#### a.Redis主从复制：

在Redis.conf配置文件中设置主从复制的相关配置:

```
# 主节点的配置文件
bind 127.0.0.1
port 6379
daemonize yes
pidfile /var/run/redis_6379.pid
logfile /var/log/redis_6379.log
dir /var/lib/redis/6379
dbfilename dump_6379.rdb
appendonly yes

# 从节点的配置文件
bind 127.0.0.1
port 6380
daemonize yes
pidfile /var/run/redis_6380.pid
logfile /var/log/redis_6380.log
dir /var/lib/redis/6380
dbfilename dump_6380.rdb
appendonly yes
slaveof 127.0.0.1 6379
```

#### b. Redis哨兵模式：

原理：哨兵模式是Redis的一种高可用解决方案，它通过监控主从节点的状态，自动进行故障转移。当主节点出现故障时，哨兵会自动将从节点提升为主节点，保证服务的高可用性。

区别：哨兵模式主要用于实现主从节点的自动故障转移，提高系统的可用性。

实现方法：在Redis配置文件中设置哨兵模式的相关配置，例如：

```
# 哨兵节点的配置文件
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 10000
sentinel parallel-syncs mymaster 1
```

Redis哨兵模式是一种用于监控和管理Redis主从复制集群的机制。它的作用是确保在主节点出现故障时，能够自动进行故障转移，
将一个从节点提升为新的主节点，并通知其他从节点更新它们的主节点信息。

举个例子来说，假设你有一个Redis主从复制集群，其中有一个主节点和两个从节点。当主节点出现故障时，哨兵模式会自动检测到这个故障，
并选择一个从节点作为新的主节点。然后，它会通知其他从节点更新它们的主节点信息，以便它们可以开始复制新的主节点上的数据。
这样，整个集群就能够继续正常运行，而不需要手动干预。

简单来说，哨兵模式就是用来保证Redis集群的高可用性和自动故障转移的。

这是Redis哨兵模式的配置文件，用于配置哨兵节点的行为。下面是对每个配置项的解释：

1. `sentinel monitor mymaster 127.0.0.1 6379 2`：这行配置指定了要监控的主节点的名称（mymaster）、IP地址（127.0.0.1）和端口号（6379）。
   最后一个参数2表示至少需要2个哨兵节点同意主节点不可用才会触发故障转移。

2. `sentinel down-after-milliseconds mymaster 5000`：这行配置设置了主节点被标记为不可用的时间阈值，单位是毫秒。
   在这个例子中，如果主节点在5000毫秒内没有响应哨兵节点的心跳请求，那么该主节点将被标记为不可用。

3. `sentinel failover-timeout mymaster 10000`：这行配置设置了故障转移的超时时间，单位是毫秒。
   在这个例子中，如果在10000毫秒内无法完成故障转移，那么故障转移操作将失败。

4. `sentinel parallel-syncs mymaster 1`：这行配置设置了在故障转移过程中，从节点与新的主节点进行数据同步时的并行同步数量。
   在这个例子中，只有一个从节点可以与新的主节点进行同步。

#### c.Redis集群模式:

原理：集群模式是Redis的一种分布式解决方案，它将数据分布在多个节点上，每个节点负责一部分数据。
集群模式下，数据可以水平扩展，提高系统的存储容量和并发能力。

区别：集群模式主要用于实现数据的分布式存储和负载均衡，提高系统的存储容量和并发能力。

实现方法：使用Redis官方提供的集群管理工具`redis-trib`进行集群的创建和管理，例如：

```
# 创建集群
redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
```

总结：主从复制、哨兵模式和集群模式分别解决了Redis的高可用、分布式存储和负载均衡等问题。在实际生产环境中，可以根据业务需求选择合适的方案。


这是一个用于创建 Redis 集群的命令。下面是对命令的解释：

- `redis-trib.rb`: 这是 Redis 官方提供的一个工具，用于管理和操作 Redis 集群。
- `create`: 这个子命令用于创建一个新的 Redis 集群。
- `--replicas 1`: 这个选项指定了每个主节点的从节点数量为 1。这意味着每个主节点都会有一个对应的从节点。
- `127.0.0.1:7000`、`127.0.0.1:7001`、`127.0.0.1:7002`、`127.0.0.1:7003`、`127.0.0.1:7004`、`127.0.0.1:7005`:
  这些是 Redis 主节点的 IP 地址和端口号。在这个例子中，有 6 个主节点，分别监听在本地主机（IP 地址为 127.0.0.1）的 7000 到 7005 端口上。

通过执行这个命令，将会创建一个包含 6 个主节点和 6 个从节点的 Redis 集群。每个主节点都有一个对应的从节点，用于实现数据的复制和故障恢复。

## 11- Redis、Tomcat、Nginx和MySQL在Linux系统上启动、停止和重启的命令

**MySQL**:

- **启动**：`service mysqld start` 或 `/etc/init.d/mysqld start`
- **停止**：`service mysqld stop` 或 `/etc/init.d/mysqld stop`
- **重启**：`service mysqld restart` 或 `/etc/init.d/mysqld restart`

**Tomcat**:

- **启动**：在`tomcat/bin`目录下，执行`./startup.sh`
- **停止**：在`tomcat/bin`目录下，执行`./shutdown.sh`
- **重启**：先执行`./shutdown.sh`停止，再执行`./startup.sh`启动

**Nginx**:

- **启动**：`cd /usr/local/nginx/sbin/`然后执行`./nginx`
- **停止**：可以通过`./nginx -s stop`或`./nginx -s quit`来停止Nginx
- **重启**：先执行停止命令，再执行启动命令。另外，可以通过`./nginx -s reload`重新加载配置文件而无需重启服务

**Redis**:

- **启动**：直接执行`redis-server`，如果需要指定配置文件，可以使用`redis-server /path/to/redis.conf`
- **停止**：通过`redis-cli shutdown`命令关闭Redis服务
- **重启**：先执行停止命令，再执行启动命令

在使用这些命令时，请确保你具有相应的权限，并且路径根据你的实际安装目录进行适当调整。

## 12- ELK日志体系

ELK日志体系是一种流行的日志管理和分析解决方案，由Elasticsearch、Logstash和Kibana三个开源项目组成。这三个项目分别负责日志的收集、处理和展示，它们可以协同工作，
帮助用户实现实时的日志分析。

1. **Elasticsearch**：是一个基于Lucene的搜索引擎，提供了分布式多用户能力，具有HTTP Web接口和无模式JSON文档。在ELK体系中，它负责存储和索引日志数据。
2. **Logstash**：是一个灵活的数据采集、处理和传输工具。它可以从各种来源收集日志数据，进行过滤和解析，然后将处理后的数据发送到Elasticsearch中存储。
3. **Kibana**：是一个可视化平台，用于查看和分析Elasticsearch中存储的数据。它提供了丰富的图表和过滤器，使用户能够轻松地创建仪表板来展示和探索日志数据。

举个例子，假设你是一个电商网站的运维人员，你需要监控网站的访问情况和性能指标。你可以使用ELK体系来实现这个目标：

- 首先，你可以在网站的服务器上安装Filebeat（一个轻量级的日志收集器），用于收集Web服务器的访问日志。
- 然后，Filebeat将收集到的日志数据传输给Logstash，Logstash对这些日志进行解析和过滤，提取出有用的信息（如IP地址、请求时间、页面URL等）。
- 接下来，Logstash将处理后的日志数据发送到Elasticsearch集群中进行存储和索引。
- 最后，你可以通过Kibana来查询和分析这些日志数据。例如，你可以创建一个仪表板来展示网站的总访问量、每个页面的访问量、访问来源等信息。你还可以使用Kibana的过滤器功能来筛选特定的数据，如某个时间段内的访问情况或某个特定用户的访问记录。

通过ELK体系，你可以实现对网站日志的实时分析和监控，帮助你更好地了解网站的运行状况并及时发现问题。

## 13、Spring全家桶关系表

由于Spring框架及其相关项目数量较多，且随着技术发展不断有新的组件加入，这里以表格形式列举一些核心的、广为人知的Spring项目及其主要功能，以展现它们之间的关系：

| **项目名称**              | **主要功能**                                                 | **与Spring框架的关系**                                       |
| ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Spring Framework**      | 核心基础，提供IoC/DI、AOP、数据访问抽象、MVC等基础功能       | 基础框架，所有其他Spring项目依赖或扩展的基础                 |
| **Spring Boot**           | 简化Spring应用的初始搭建和开发过程，提供内嵌服务器、自动配置、starter依赖等 | 基于Spring Framework构建，用于快速构建生产级Spring应用       |
| **Spring MVC**            | Web应用开发框架，实现MVC模式，处理HTTP请求、路由、视图渲染等 | Spring Framework的一部分，专注于Web层开发                    |
| **Spring WebFlux**        | 响应式Web框架，基于Reactor，支持非阻塞、背压的异步数据流处理 | Spring Framework的一部分，为构建异步和反应式Web服务提供支持  |
| **Spring Data**           | 提供对各种数据存储（如JPA、MongoDB、Redis等）的统一API和模块 | 基于Spring Framework，简化数据访问层开发                     |
| **Spring Data JPA**       | Spring Data的一个子项目，对JPA的进一步封装，简化Java Persistence API的使用 | 基于Spring Data，专注与关系型数据库的ORM操作                 |
| **Spring Data MongoDB**   | Spring Data的一个子项目，提供与MongoDB的集成，简化NoSQL数据操作 | 基于Spring Data，专注与MongoDB的交互                         |
| **Spring Security**       | 安全框架，提供身份验证、授权、密码加密、会话管理等功能       | 基于Spring Framework，为Spring应用提供全面的安全防护         |
| **Spring Cloud**          | 微服务框架，提供服务发现、配置管理、熔断器、API网关、分布式追踪等组件 | 基于Spring Boot，为构建和协调微服务架构提供工具和模式        |
| **Spring Cloud Netflix**  | Spring Cloud的一个子项目，整合Netflix OSS组件（如Eureka、Zuul、Hystrix等） | 基于Spring Cloud，提供一套成熟的微服务解决方案               |
| **Spring Batch**          | 批处理框架，处理大批量数据的导入导出、清洗、转换等批量作业   | 基于Spring Framework，用于构建批处理应用                     |
| **Spring Integration**    | 企业集成框架，支持消息传递、适配器、路由、转化等企业集成模式 | 基于Spring Framework，实现企业级系统集成和消息处理           |
| **Spring Cloud Stream**   | 基于Spring Integration的事件驱动微服务框架，简化消息驱动应用开发 | 基于Spring Cloud和Spring Integration，实现微服务间的事件驱动通信 |
| **Spring Cloud Function** | 函数即服务（FaaS）支持，提供无服务器（Serverless）应用开发模型 | 基于Spring Cloud，简化函数式编程模型在云环境下的应用         |

注意，上述表格仅列举了一些核心的Spring项目，实际Spring生态中还有许多其他项目和组件，如Spring Session、Spring Cloud Config、Spring Cloud Gateway、Spring Cloud Stream Kafka Binder等，它们同样与Spring Framework有着紧密的关系，为特定场景或技术栈提供了针对性的支持。这些项目通常通过依赖Spring Framework的核心功能，并在其之上提供额外的抽象、简化配置和特定领域的解决方案。整个Spring家族项目共同构成了一个庞大且高度互操作的软件开发平台。

## 14-Servlet的工作流程

1. 通过请求头获知浏览器访问的是哪个主机
2. 再通过请求行获取访问的是哪个一个web应用
3. 再通过请求行中的请求路径获知访问的是哪个资源
4. 通过获取的资源路径在配置中匹配到真实的路径，
5. 服务器会创建servlet对象，（如果是第一次访问时，创建servlet实例，并调用init方法进行初始化 操作）
6. 调用service（request， response）方法来处理请求和响应的操作
7. 调用service完毕后返回服务器 由服务器讲response缓冲区的数据取出，以http响应的格式发送给 浏览器

## 15-Servlet的生命周期

1、当浏览器访问 Servlet 的时候，Tomcat 会查询当前 Servlet 的实例化对象是否存在，如果不存在， 则通过反射机制动态创建对象，如果存在，直接执行第 3 步。

2、调用 init 方法完成初始化操作。

3、调用 service 方法完成业务逻辑操作。HttpServlet 的 service()方法，会依据请求方式来调用 doGet()或者 doPost()方法。但是，这两个 do 方法默认情况下，会抛出异常，需要子类去 override。

4、关闭 Tomcat 时，会调用 destory 方法，释放当前对象所占用的资源。

 Servlet 的生命周期方法：无参构造函数、  init 、service 、destory

1 、无参构造函数只调用一次，创建对象。

2 、init 只调用一次，初始化对象。

3 、service 调用 N 次，执行业务方法。

4 、destory 只调用一次，卸载对象。

## 16- Tomcat 与 Servlet 是如何工作的

![image-20240406234210034](C:\Users\JB.Lee\AppData\Roaming\Typora\typora-user-images\image-20240406234210034.png)

1. Web Client 向 Servlet 容器（Tomcat）发出 Http 请求
2. Servlet 容器接收 Web Client 的请求
3. Servlet 容器创建一个 HttpServletRequest 对象，将 Web Client 请求的信息封装到这个对象中
4. Servlet 容器创建一个 HttpServletResponse 对象
5. Servlet 容器调HttpServlet 对象service 方法，把 Request 与 Response 作为参数，传给HttpServlet
6. HttpServlet 调用 HttpServletRequest 对象的有关方法，获取 Http 请求信息
7. HttpServlet 调用 HttpServletResponse 对象的有关方法，生成响应数据
8. Servlet 容器把 HttpServlet 的响应结果传给 Web Client

## 17-Nginx有什么用，具体举例说明

Nginx 是一款高性能的 Web 服务器和反向代理服务器，同时也支持 IMAP/POP3/SMTP 协议的代理服务器。它的名称发音为“engine-x”，由俄罗斯程序员 Igor Sysoev 开发，最初是为了应对 Rambler.ru 网站的高并发挑战而设计的。Nginx 以其轻量级、高性能、稳定性和低资源消耗的特点，在现代互联网基础设施中占据着重要位置。

### 1）Nginx 的主要用途包括：

1. **Web 服务器**：
   - 处理并响应HTTP(S)请求，分发静态内容，如 HTML、CSS、JavaScript 文件、图片和视频等。由于其高效的事件驱动架构，Nginx 能够快速地处理大量并发请求，特别适合高流量网站。

2. **反向代理服务器**：
   - 接收客户端请求，并将其转发到后端服务器（如应用服务器），然后将服务器的响应返回给客户端。这一特性常用于负载均衡，即根据预设策略（如轮询、最少连接、哈希等）将请求分配到不同的后端服务器，以达到优化资源使用和提升系统稳定性的目的。

3. **负载均衡器**：
   - 基于反向代理的功能，Nginx 可以智能地分发请求到多个应用服务器，实现负载均衡。这有助于避免单点故障，提高系统的伸缩性和可靠性。

4. **API 网关**：
   - 作为微服务架构中的 API 网关，Nginx 可以管理多个后端服务的接入，负责请求路由、协议转换、认证鉴权、限流熔断等任务，为客户端提供统一的接口访问层。

5. **SSL 终端**：
   - Nginx 能够处理 HTTPS 请求，终止 SSL/TLS 连接，从而为后端服务器卸载加密解密的负担，同时保证数据传输的安全性。

6. **HTTP 缓存**：
   - 通过配置，Nginx 可以缓存频繁访问的内容，减少对后端服务器的请求，加快响应速度，减轻服务器压力。

7. **动静分离**：
   - 在处理请求时，Nginx 可以区分静态资源和动态内容，将静态资源直接从 Nginx 服务器返回，而将动态请求转发到应用服务器处理，这种机制优化了资源的分发效率。

### 2）具体举例说明：

假设有一个电商网站，它使用 Nginx 实现以下功能：

- **前端资源分发**：网站的HTML、CSS、JavaScript文件和图片等静态资源存储在Nginx服务器上，Nginx快速响应用户请求，提供这些资源，提升页面加载速度。

- **反向代理和负载均衡**：用户提交订单时，请求被Nginx接收，它根据负载均衡策略将请求转发到合适的后端应用服务器集群中的某一台服务器处理。这样，即使在高流量时段，也能确保系统稳定运行，不会因某一服务器过载而崩溃。

- **SSL 加密**：Nginx 配置了 SSL 证书，为整个网站提供 HTTPS 安全连接，保护用户数据安全。

- **API 网关**：网站的移动APP和第三方开发者通过Nginx作为单一入口访问后端的各种微服务，Nginx负责身份验证、速率限制，并根据API路径将请求路由到正确的服务。

- **缓存热门商品详情页**：对于访问量大的商品详情页面，Nginx可以设置缓存策略，将频繁访问的页面内容暂存，直接从缓存中快速返回，减少数据库查询和服务器计算压力，提升用户体验。

通过这些例子，可以看出 Nginx 在现代网站架构中扮演着关键角色，它不仅提升了网站的性能和安全性，还为复杂的服务架构提供了灵活的解决方案。

## 18-Kafka是什么，有什么作用，具体举例

Apache Kafka 是一个开源的分布式事件流平台，由LinkedIn开发并随后贡献给了Apache软件基金会。Kafka设计之初是为了处理网站的实时日志处理和流数据，但其灵活性和强大性能使其在众多场景下得到广泛应用。Kafka的核心概念包括主题（Topics）、生产者（Producers）、消费者（Consumers）和代理（Brokers）。

### 1）Kafka的作用主要包括：

1. **高吞吐量消息队列**：Kafka能够以极高的速度处理消息的生产和消费，支持每秒数十万条消息的吞吐，非常适合需要大规模数据传输的应用场景，如实时日志处理、事件驱动架构、数据管道等。

2. **发布-订阅模型**：Kafka采用发布-订阅模式，生产者将消息发布到特定的主题，而消费者则可以根据兴趣订阅这些主题。这种模式支持一对多的消息分发，使得系统解耦，易于扩展。

3. **数据持久化与缓冲**：Kafka将消息持久化到磁盘，支持消息的长期存储，可以用来构建数据管道，用于数据的备份、归档或批处理分析（如ETL）。

4. **分布式与高可用性**：Kafka的分布式特性意味着它能够跨多个服务器节点复制数据，提供故障切换和数据冗余，保证了系统的高可用性和数据的持久性。

5. **流处理平台**：虽然本质上是消息系统，但Kafka与流处理框架（如Kafka Streams、Apache Flink、Spark Streaming）的集成，使其也能作为流处理平台，用于实时数据分析和处理。

### 2）具体举例：

假设一家电商平台需要实时处理用户行为数据，以便进行个性化推荐、实时库存更新和欺诈检测：

- **用户行为跟踪**：每当用户浏览商品、添加购物车或完成购买，前端应用会将这些事件作为消息发送到Kafka的一个主题（比如`user_behavior`）。这里，Kafka作为消息队列，收集并缓冲这些实时事件数据。

- **实时处理与分析**：后端系统包括多个消费者服务，分别订阅`user_behavior`主题。一个服务可能使用Apache Flink实时分析这些数据，识别用户行为模式，进行实时个性化推荐；另一个服务可能负责实时更新库存，确保库存数据的准确性；还有服务专门负责监控异常行为，及时发现潜在的欺诈交易。

- **数据仓库集成**：同时，Kafka还可以将这些数据流进一步导入大数据仓库，如Hadoop或Snowflake，用于离线的深度分析和报告生成。这通常通过另一个消费者服务来完成，该服务订阅相同主题，但以较慢的速度处理消息，进行批量导入。

- **容错与扩展性**：随着业务增长，Kafka的分布式特性可以轻松地添加更多代理节点，提升整体系统的处理能力和可靠性。即使个别节点发生故障，也不会导致数据丢失或处理中断。

通过上述例子，可以看到Kafka在构建高并发、实时处理和数据驱动的系统中发挥着核心作用，它不仅提高了数据处理的效率和可靠性，也促进了不同系统组件间的解耦和独立扩展。

## 19-作为消息缓冲队列的工具

市场上有许多成熟且广泛使用的解决方案，它们各自有独特的功能和优势，满足不同场景下的需求。下面是一些典型的消息队列工具及其功能点概述：

1. **Apache Kafka**
   - **特点**: 高吞吐量、分布式、实时处理能力强，支持发布/订阅和队列两种模式。
   - **功能点**: 持久化、分区、副本机制保证数据可靠性和高可用性；支持流处理，可直接与流处理框架集成；良好的水平扩展能力。

2. **RabbitMQ**
   - **特点**: 开源、基于AMQP（高级消息队列协议），支持多种编程语言。
   - **功能点**: 可靠的消息投递（包括发送确认和持久化）、灵活的路由策略（如直连、主题、扇出、扇入）、高可用集群配置、管理界面友好。

3. **Redis**
   - **特点**: 虽然Redis主要是一个键值存储系统，但其Pub/Sub（发布/订阅）功能常被用作轻量级消息队列。
   - **功能点**: 极高的读写速度、简单易用，适合轻量级消息传递，但不支持消息持久化和队列管理的高级特性。

4. **RocketMQ**
   - **特点**: 阿里巴巴开源，专为大规模分布式系统设计，支持高吞吐、低延迟。
   - **功能点**: 支持顺序消息、事务消息、延时消息、消息过滤、精确一次投递语义，以及丰富的运维管理工具。

5. **ActiveMQ**
   - **特点**: 成熟的开源消息中间件，支持多种协议，包括AMQP、STOMP、MQTT等。
   - **功能点**: 多种消息模式、持久化、高可用集群、JMS（Java消息服务）标准支持，以及图形化的管理和监控界面。

6. **NATS**
   - **特点**: 轻量级、高性能，专注于云原生环境的简单消息总线。
   - **功能点**: 简单的发布/订阅模型、支持多种语言客户端、自动发现和连接集群、易于部署和管理。

7. **Disruptor**
   - **特点**: 不是一个传统意义上的消息队列，而是一个高性能的内存队列框架。
   - **功能点**: 面向低延迟、高吞吐的场景，利用环形缓冲区优化并发性能，适用于单机内的高性能事件处理。

8. **Pulsar**
   - **特点**: Apache顶级项目，结合了Kafka的耐用性和Pub/Sub的灵活性。
   - **功能点**: 分层架构支持无限规模扩展、多租户、支持多种消息模式、持久化存储、低延迟和高吞吐。

9. **Amazon SQS (Simple Queue Service)**
   - **特点**: AWS提供的托管队列服务，无需维护基础设施。
   - **功能点**: 简单队列和FIFO队列、自动扩展、消息保留期设定、延迟队列、死信队列处理。

10. **Google Cloud Pub/Sub**
    - **特点**: Google Cloud提供的完全托管的实时消息传递服务。
    - **功能点**: 发布/订阅模型、自动扩展、全球范围内消息传递、与Google Cloud其他服务集成紧密。

以上只是部分常见消息队列工具的概览，选择合适的工具需根据实际应用场景、性能要求、成本预算、技术支持以及团队熟悉度等因素综合考虑。



## 20-实施工程师会用到的监控工具有哪些

实施工程师在项目实施过程中可能会用到多种监控工具，以确保项目的顺利进行、系统稳定运行以及及时发现并解决问题。以下是一些常见的监控工具，它们覆盖了网络、系统、应用等多个层面：

1. **网络监控工具:**
   - **Cacti**: 开源的、基于Web的网络监控和绘图工具，用于监视和图形化展示CPU负载、网络带宽利用率、网络流量等。
   - **Nagios**: 功能强大的开源网络监控软件，能够监控服务器及各种应用程序的状态，及时发现并通知问题。
   - **Microsoft Network Monitor**: 用于捕获、查看和分析网络流量，帮助诊断网络问题。
   - **BandwidthD**: 监控TCP/IP网络使用情况，提供数据使用统计图表，适用于流量分析。

2. **系统监控工具:**
   - **Zabbix**: 分布式监控系统，支持网络监控、服务器监控、云基础设施监控等，具备灵活的通知机制和可视化界面。
   - **Nagios**: 同样适用于系统性能监控，可以监测系统资源如CPU、内存、磁盘使用情况。
   - **top, htop, atop**: 命令行工具，实时显示系统进程状态，htop和atop提供了比top更友好的界面和额外功能，如排序、搜索和日志记录。

3. **应用性能监控（APM）工具:**
   - **大众点评 Cat 监控平台 (CAT)**: 实时应用监控平台，提供全面的监控服务和决策支持，特别适用于Java应用。
   - **Spring Cloud Sleuth**: 分布式链路追踪工具，与Spring Cloud生态系统集成，便于追踪微服务间调用关系。
   - **Zipkin**: 分布式跟踪系统，用于收集和分析微服务架构下的延迟问题，提供调用链路的可视化。

4. **项目管理与进度监控工具:**
   - **Project 软件**: 微软的项目管理软件，用于规划、监控项目进度，对比分析项目计划与实际情况。
   - **思维导图工具**: 如MindManager、XMind等，用于项目规划、思路整理和团队协作。

5. **基础设施与云监控工具:**
   - **SolarWinds Server & Application Monitor (SAM)**: 企业级监控解决方案，用于服务器和应用程序的监控、优化和诊断。
   - **Prometheus and Grafana**: Prometheus用于监控指标的收集和存储，Grafana用于数据的可视化展示，两者常组合使用，适用于云原生环境。

6. **Linux运维监控工具:**
   - **Ganglia**: 分布式监控系统，主要用于高性能计算系统和网格环境的监控。
   - **Collectd/Collectl**: 系统性能数据收集工具，可将数据发送至各类后端存储或图形界面展示。

实施工程师依据具体项目需求和环境，可能会选择其中一种或多种工具组合使用，以达到最佳的监控效果。

## 21-Zabbix 监控的指标有哪些？

是一个广泛使用的监控解决方案，它可以监控从基础硬件到应用程序级别的众多指标。以下是Zabbix监控的一些具体指标分类和示例：

1. **操作系统层面:**
   - CPU 使用率（用户、系统、空闲时间）
   - 内存使用（总内存、使用量、缓存、交换空间）
   - 磁盘使用情况（磁盘空间使用率、I/O读写速率、磁盘队列长度）
   - 网络接口（带宽使用、包错误率、丢包率）
   - 系统负载（Load Average）
   - 进程状态（数量、CPU使用、内存使用）
   - 文件系统inode使用情况
   - 操作系统日志监控

2. **网络设备监控:**
   - 设备在线状态
   - 端口状态（连通性、速度、双工模式）
   - 网络流量（入站、出站）
   - 路由表状态
   - SNMP陷阱接收

3. **数据库监控:**
   - 连接数
   - 查询响应时间
   - 缓冲池命中率
   - 表锁、行锁状态
   - 磁盘使用（数据文件、日志文件）
   - MySQL、Oracle、PostgreSQL等特定数据库的性能指标

4. **Web服务监控:**
   - HTTP响应时间
   - 网站证书有效期
   - 页面内容检查（关键字匹配）
   - SSL/TLS握手时间
   - 服务器状态码（200, 404, 500等）

5. **应用程序监控:**
   - Tomcat监控（JVM堆内存使用、垃圾回收频率、线程池状态）
   - Java应用程序JMX指标
   - Apache、Nginx服务器状态
   - 应用程序日志监控
   - 自定义脚本输出监控

6. **硬件监控:**
   - 服务器硬件健康状态（通过IPMI、SMART等）
   - 温度、电压、风扇转速
   - RAID阵列状态
   - UPS电池状态、负载、剩余时间

7. **虚拟化环境监控:**
   - VMware ESXi主机和虚拟机状态
   - KVM、Hyper-V资源使用
   - Docker容器资源使用情况

8. **云基础设施监控:**
   - AWS、Azure、Google Cloud Platform等云平台资源使用
   - 云服务API响应时间
   - 云存储使用情况

9. **自定义监控项:**
   - 通过脚本或插件自定义监控任何可度量的指标，如自定义日志解析、业务逻辑监控等。

这些只是Zabbix监控能力的一部分概览，实际监控指标可以根据需求通过配置自定义检查项来扩展。Zabbix通过其灵活的配置和模板系统，几乎可以对任何可以度量的系统或应用参数进行监控。

## 22-Redis分布式缓存的理解

Redis分布式缓存是一种利用Redis数据库的特性，将数据分布在网络中的多个节点上的缓存机制。它是应对单个节点性能瓶颈、提高系统可用性和扩展性的有效手段。以下是关于Redis分布式缓存的几点深入理解：

1. **集群模式实现**：
   Redis的分布式缓存功能主要通过集群模式实现。集群由多个节点组成，每个节点负责存储和处理一部分数据。数据自动被划分为多个槽（slot），每个槽由一个主节点管理，同时拥有一个或多个从节点作为副本，以提供高可用性。

2. **数据分片与自动发现**：
   集群中的节点通过Gossip协议进行通信，实现数据的自动分片和节点的自动发现。当新的节点加入或现有节点离开时，集群能自动重新平衡数据分布，保持系统的稳定性。

3. **键值哈希定位**：
   应用程序在访问缓存时，通过计算键的哈希值确定其所属的槽，进而找到存储该键值对的节点。这种方式确保了高效的数据定位。

4. **客户端支持**：
   使用如ioredis这样的Redis客户端库，可以简化分布式缓存的使用。这些客户端能够自动处理数据分布逻辑，让开发者像操作单个Redis实例一样操作整个集群。

5. **性能与可靠性提升**：
   分布式缓存通过将数据分散存储，减少了单个节点的压力，提高了系统的处理能力和响应速度。副本机制则保证了即使某个节点失效，数据仍然可以从其他副本中获得，增强了系统的可靠性。

6. **操作简便性**：
   Redis提供了简单易用的API，使得设置、获取缓存数据变得直接而高效。此外，Redis支持多种数据结构（如字符串、列表、集合、哈希表、有序集合等），使得它在处理复杂缓存场景时更加灵活。

7. **数据持久化与备份**：
   尽管Redis主要是内存数据库，但它支持RDB和AOF两种持久化方式，可以定期或实时将数据同步到磁盘，保障数据不丢失。在分布式环境中，各节点的持久化策略需要合理配置，以维持数据的一致性和完整性。

8. **监控与管理**：
   分布式缓存的运维需要有效的监控和管理工具，包括但不限于监控集群状态、节点健康状况、缓存命中率、网络延迟等，以确保缓存系统高效稳定运行。

9. **负载均衡与扩展性**：
   通过负载均衡策略，Redis集群可以高效分配请求，避免单点过载。随着需求的增长，可以轻松添加新节点以横向扩展集群，提升整体的处理能力。

综上所述，Redis分布式缓存通过其灵活的集群架构、高效的数据管理机制以及丰富的功能特性，成为现代高性能应用中不可或缺的组件，尤其在应对高并发、大数据量的场景下表现出色。

1. - 

## 23-你用哪几种数据库比较多？分别有什么区别

在面试实施工程师时，提及使用过的数据库种类以及它们之间的区别，可以通过以下表格进行概括性比较，以展现你对不同数据库的了解和应用经验：

| 数据库类型 | 主要应用场景                                | 特点                                                         | 区别                                                         |
| ---------- | ------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Oracle     | 企业级应用、金融、电信、大型数据库管理系统  | 1. 高性能、高可靠性。2. 支持大并发、大数据量。3. 强大的SQL支持，包括PL/SQL。4. 成熟的分区、备份恢复功能。5. 商业软件，支持全面，但许可费用较高。 | 与MySQL相比，Oracle更适合处理复杂事务和高并发访问，提供更全面的企业级功能，但成本更高。与SQL Server相比，Oracle在跨平台能力、大型系统处理上表现更优。 |
| MySQL      | 网站、Web应用、中小企业                     | 1. 开源、免费（社区版），成本低。2. 易于安装、使用和维护。3. 支持多种存储引擎，如InnoDB（事务安全）、MyISAM（非事务）。4. 广泛的社区支持，插件和工具丰富。 | 相比Oracle，MySQL在处理复杂事务和高并发方面可能稍逊，但成本优势明显。与SQL Server相比，MySQL在开源社区活跃度、跨平台能力上有优势。 |
| SQL Server | Windows环境下的企业应用、电子商务、数据仓库 | 1. 与Windows系统深度集成，管理方便。2. 提供强大的BI（商业智能）工具。3. 支持.NET框架，易于开发和集成。4. 企业级安全性、高可用性解决方案。 | 与Oracle相比，SQL Server更适合Windows环境，集成度更高，但在跨平台能力上不如Oracle和MySQL。与MySQL相比，SQL Server在企业级功能和集成开发环境上更完善，但仅限于Windows平台。 |
| PostgreSQL | 开源项目、科研、Web应用、地理信息系统       | 1. 完全开源，遵循BSD协议。2. 支持复杂的SQL查询、事务处理。3. 强大的数据类型支持，包括JSON、数组、GIS等。4. 高度可扩展，支持插件和自定义函数。 | PostgreSQL在开源数据库中以功能全面著称，特别是在复杂查询和数据类型支持上超过MySQL，与Oracle和SQL Server在某些高级功能上可媲美，但市场占有率相对较低。 |

| DB2 | 大型企业、银行、保险、政府机构 | 1. 高度安全、稳定。2. 支持多平台，包括大型机。3. 强大的OLAP和数据仓库功能。4. 支持XML、JSON等多种数据格式。 | DB2在大型企业环境中表现突出，特别是在安全性、稳定性以及对大型机的支持上，与Oracle类似，但更侧重于IBM生态系统。 |

在回答时，你可以根据自己的实际经验，具体说明在哪些项目中使用了这些数据库，以及如何根据项目需求选择合适的数据库，强调你在数据库选型、安装、配置、性能优化等方面的经验和能力。

## 21-MongoDB与MySQL的区别：

在面试实施工程师时，提到使用过的数据库并对比它们的特点，尤其是将MongoDB纳入讨论，可以按照以下表格进行对比：

| 数据库类型 | 数据模型 | 存储方式              | 查询语言                     | 适用场景                     | 特点                                                         |
| ---------- | -------- | --------------------- | ---------------------------- | ---------------------------- | ------------------------------------------------------------ |
| MySQL      | 关系型   | 表格形式，行列结构    | SQL                          | 企业应用、网站后台、事务处理 | 1. 结构化数据存储，严格的数据模式。2. 支持事务处理，ACID特性。3. 多种存储引擎（InnoDB, MyISAM等）。4. SQL查询，支持JOIN操作。5. 对硬件资源占用相对较小。 |
| MongoDB    | 面向文档 | BSON文档（JSON-like） | MongoDB Query Language (MQL) | 大数据、内容管理、实时分析   | 1. 非关系型，灵活的文档存储，易于扩展数据模型。2. 弱一致性，优先保证高吞吐量和低延迟。3. 自动分片和复制，易于水平扩展。4. 支持复杂查询，如地理空间查询。5. 内置GridFS，支持大文件存储。6. 不支持JOIN操作，但可以使用嵌套文档和聚合管道实现关联数据操作。 |

### 区别总结：

- **数据模型与存储方式**：MySQL基于表格和行列的结构化数据模型，适合高度结构化数据的存储；而MongoDB采用面向文档的存储方式，以BSON格式存储数据，更灵活适应变化的数据结构。
- **查询语言**：MySQL使用传统的SQL语言，适合复杂的关联查询；MongoDB使用MQL，更接近JavaScript语法，适合文档的查询和操作，特别是对嵌套文档的处理。
- **事务处理**：MySQL支持ACID事务，适合需要强一致性的场景；MongoDB在早期版本中事务支持较弱，但自4.0版本起支持多文档事务，虽然与传统关系型数据库的事务特性相比，MongoDB的事务在某些方面仍然存在差异。
- **扩展性与性能**：MySQL通常采用垂直扩展（更强的单机），或通过主从复制、分区等手段增强；MongoDB设计之初就支持水平扩展，通过自动分片和复制集实现高可用性和数据分布，更适合处理海量数据和高并发请求。
- **应用场景**：MySQL适用于需要严格数据模式和事务支持的传统应用；MongoDB则更适合处理非结构化数据、实时数据处理、内容管理等场景，特别是在需要快速迭代和灵活数据模型的现代应用中更为常见。

在面试中，你可以根据个人经验，举例说明在具体项目中如何根据业务需求选择使用MySQL或MongoDB，以及如何利用各自的优势解决实际问题，展现你对数据库选型和应用的深入理解。



--------------------------

# （三）业务面试



# 面试题：

## 1 请描述一下您如何制定有效的服务器备份策略？

- 答案：有效的服务器备份策略应该包括定期的全备份、增量备份和差异备份。全备份是基础，增量备份和差异备份可以减少备份所需的时间和存储空间。同时，备份应该在服务器负载较低的时段进行，以减少对正常业务的影响。备份数据应该存储在安全的位置，最好是物理位置和服务器分离，以防灾难恢复的需要。

## 2 在发生数据丢失的情况下，您将如何恢复数据？

- 答案：首先，我会检查备份日志，确定最近的备份点和丢失的数据范围。然后，我会从备份存储中恢复数据到一个临时环境进行验证。验证无误后，再将数据恢复到生产环境。在整个过程中，我会确保数据的完整性和一致性，并记录恢复过程以供未来参考。

## 3 在进行系统升级时，您会如何确保业务连续性？

- 答案：在系统升级前，我会进行详细的规划，包括升级的版本、所需时间、影响范围等。我会在业务低峰时段进行升级，并提前通知相关人员。同时，我会准备回滚计划，以防升级过程中出现问题。升级过程中，我会监控系统状态，确保升级顺利进行。

## 4 您如何进行服务器的日常维护？

- 答案：日常维护包括检查服务器的硬件状态、操作系统的日志、应用程序的错误日志、磁盘空间使用情况、内存使用情况等。我会定期运行系统优化工具，更新系统和应用程序的安全补丁，以及监控服务器的性能指标，确保服务器运行在最佳状态。

## 5 您如何监控服务器的性能和安全？

- 答案：我会使用监控工具（**Zabbix**、**Nagios**、**Prometheus**、**Grafana**、**Datadog**、**ManageIQ**）来实时监控服务器的CPU、内存、磁盘I/O、网络流量等关键性能指标。对于安全监控，我会配置防火墙规则、入侵检测系统（IDS）和安全信息和事件管理（SIEM）系统。我会定期检查安全日志，及时响应安全警报，并进行安全漏洞扫描和修补。

## 5 如果服务器发生严重故障，您如何执行灾难恢复计划？

- 答案：

  灾难恢复计划应包括数据恢复、系统恢复和业务恢复三个阶段。

  在数据恢复阶段，我会从最近的备份中恢复数据。

  在系统恢复阶段，我会重建或修复受损的系统环境。

  在业务恢复阶段，我会与业务团队合作，确保业务流程尽快恢复到正常状态。

  在整个过程中，我会遵循事先制定的灾难恢复流程，并记录所有操作以供后续审计和改进。

## 6 负责服务器的备份、数据备份、系统升级、日常维护、监控和安全维护检查，涉及到的Linux相关命令和数据库命令如下：

### 1） Linux相关命令

1. **备份相关命令**
   - `tar`：用于打包和压缩文件。
   - `cp`：用于复制文件或目录。
   - `rsync`：用于同步文件和目录，也可用于备份。
   - `dd`：用于低级备份，创建磁盘镜像。
   - `dump`：用于高级备份，需要root权限。

2. **系统升级相关命令**
   - `yum update`（CentOS/Red Hat）：更新所有可升级的软件包。
   - `apt-get upgrade`（Debian/Ubuntu）：更新所有可升级的软件包。
   - `zypper up`（openSUSE）：更新所有可升级的软件包。
   - `pacman -Syu`（Arch Linux）：同步软件包数据库并升级所有软件包。

3. **日常维护相关命令**
   - `df`：报告文件系统的磁盘空间使用情况。
   - `du`：估算文件或文件夹的磁盘空间使用。
   - `free`：显示内存和交换空间的使用情况。
   - `iostat`：监视系统输入/输出设备负载。
   - `netstat`：显示网络连接、路由表、接口统计等网络信息。
   - `top`：实时显示系统中各个进程的资源占用情况。
   - `htop`：类似于`top`，但提供更丰富的界面和信息。

4. **监控相关命令**
   - `uptime`：显示系统运行时间、用户登录信息和系统负载。
   - `vmstat`：报告虚拟内存统计信息。
   - `mpstat`：显示每个CPU的活动统计。
   - `sar`：收集、报告或保存系统活动信息。

5. **服务器安全维护检查相关命令**
   - `chkrootkit`：检查系统中的Rootkit。
   - `rkhunter`：Rootkit猎人，用于检测Rootkit和后门。
   - `fail2ban`：通过分析日志文件来阻止恶意访问。
   - `iptables`：配置Linux内核防火墙。
   - `firewalld`：管理防火墙的动态管理工具（CentOS 7及以上）。
   - `sestatus`：检查SELinux的状态。
   - `setenforce`：设置SELinux的强制模式。

### 2） 数据库命令

1. **MySQL/MariaDB**
   - `mysqldump`：用于导出MySQL数据库。
   - `mysqladmin`：管理MySQL服务器。
   - `mysqlcheck`：检查MySQL服务器的完整性。

2. **PostgreSQL**
   - `pg_dump`：用于导出PostgreSQL数据库。
   - `pg_ctl`：启动、停止或重启PostgreSQL服务。
   - `psql`：PostgreSQL的命令行接口。

3. **Oracle**
   - `rman`：Oracle Recovery Manager，用于备份和恢复Oracle数据库。
   - `sqlplus`：Oracle的命令行工具。
   - `exp/imp`：Oracle的数据导出和导入工具。

4. **MongoDB**
   - `mongodump`：用于导出MongoDB数据。
   - `mongorestore`：用于恢复MongoDB数据。
   - `mongo`：MongoDB的命令行工具。

请注意，具体的命令使用和参数可能会根据服务器的操作系统和数据库版本有所不同。在执行这些命令之前，建议查阅相关文档或手册以确保正确使用。

## 7 负责公司产品软件产品的后期运维服务，涉及到的Linux命令和可能的面试题及其答案如下：

### 1) 涉及的Linux命令

1. **文件和目录管理**
   - `cp`：复制文件或目录。
   - `mv`：移动或重命名文件或目录。
   - `rm`：删除文件或目录。
   - `mkdir`：创建新目录。
   - `rmdir`：删除空目录。
   - `ls`：列出目录内容。
   - `cat`、`more`、`less`、`head`、`tail`：查看文件内容。

2. **软件包管理**
   - `yum`（CentOS/RedHat）：安装、更新、删除软件包。
   - `apt`（Debian/Ubuntu）：安装、更新、删除软件包。
   - `zypper`（openSUSE）：安装、更新、删除软件包。
   - `pacman`（Arch Linux）：安装、更新、删除软件包。

3. **系统监控**
   - `top`：实时显示系统进程和资源使用情况。
   - `htop`：增强版的 `top` 命令。
   - `df`：检查文件系统的磁盘空间使用情况。
   - `du`：估算文件或文件夹的磁盘空间使用。
   - `iostat`：监视系统输入/输出设备负载。
   - `netstat`：显示网络连接、路由表、接口统计等网络信息。

4. **网络管理**
   - `ifconfig` 或 `ip`：配置或显示网络接口参数。
   - `ping`：测试网络连接。
   - `traceroute`：跟踪数据包到目的地的路径。
   - `ssh`：远程登录到另一台计算机。
   - `scp`：通过SSH复制文件。

5. **服务管理**
   - `systemctl`：控制systemd系统和服务管理器。
   - `service`：管理Debian/Ubuntu系统的服务。
   - `chkconfig`：在RedHat系统中设置服务的启动级别。

6. **备份与恢复**
   - `tar`：打包和解包文件。
   - `gzip`：压缩或解压文件。
   - `rsync`：文件同步和备份。

7. **日志管理**
   - `journalctl`：查看和操作systemd日志。
   - `grep`：搜索文件内容。
   - `logrotate`：日志文件的轮换、压缩、删除。

### 2) 可能的面试题及答案

1. **如何备份服务器上的特定目录？**
   - 答案：可以使用 `tar` 命令结合 `-r`（递归）选项来备份目录。例如，`tar -czvf backup.tar /path/to/directory` 会创建一个名为 `backup.tar` 的压缩归档文件，包含指定目录及其所有子目录和文件。

2. **如何更新系统上的所有软件包？**
   - 答案：在基于RedHat的系统上，可以使用 `yum update` 命令；在基于Debian的系统上，可以使用 `apt-get update && apt-get upgrade` 命令。

3. **如何查看特定服务的状态？**
   - 答案：可以使用 `systemctl status service_name` 命令（对于使用systemd的系统）或 `service --status-all` 命令（对于不使用systemd的系统）来查看服务的状态。

4. **如何重启网络服务？**
   - 答案：在大多数Linux发行版中，可以使用 `systemctl restart network` 或 `service network restart` 命令来重启网络服务。

5. **如何查看最近的系统日志？**
   - 答案：可以使用 `journalctl` 命令查看systemd日志，例如 `journalctl -xe`；或者使用 `tail` 命令查看日志文件的最后几行，例如 `tail /var/log/syslog`。

6. **如何远程复制文件到另一台服务器？**
   - 答案：可以使用 `scp` 命令，例如 `scp /path/to/local/file username@remote_host:/path/to/remote/directory`。

7. **如何监控服务器的磁盘使用情况？**
   - 答案：可以使用 `df -h` 命令来查看文件系统的磁盘使用情况，其中 `-h` 选项表示以易读的格式（如GB、MB）显示信息。

8. **如何查找并删除特定名称的文件？**
   - 答案：可以使用 `find` 命令结合 `-exec` 选项和 `rm` 命令来查找并删除特定名称的文件，例如 `find /path/to/search -type f -name "filename.txt" -exec rm {} \;`。

9. **如何查看当前系统的内存使用情况？**
   - 答案：可以使用 `free -m` 命令来查看内存使用情况，其中 `-m` 选项表示以MB为单位显示信息。

10. **如何监控特定进程的资源消耗？**
    - 答案：可以使用 `top` 或 `htop` 命令，然后通过进程ID或名称来过滤和监控特定进程。

在准备面试时，了解这些命令的基本用法和相关概念是非常重要的。同时，实际的工作经验和处理问题的能力也是面试官关注的重点。因此，除了理论知识，实际操作经验和解决问题的案例也会是面试中的重要内容。

## 8 针对日常运维文档编写和整理以及与用户交流培训的要求，面试官可能会提出以下问题，并期望应聘者能够给出相应的回答：

1. **问题：** 请描述您以往编写运维文档的经验，您通常如何组织和维护这些文档？【3】
   **回答：** 我在之前的工作中负责编写和维护多种运维文档，包括系统架构文档、操作手册、应急预案和常见问题处理手册。我通常会使用版本控制系统（如Git）来管理文档的版本和变更历史。此外，我会遵循团队制定的文档编写标准和模板，确保文档的一致性和可读性。我还会定期与团队成员进行交叉审核，确保文档的准确性和时效性。

2. **问题：** 您如何确保编写的运维文档对用户来说既准确又易于理解？【3】
   **回答：** 为了确保文档的准确性和易用性，我会在编写文档时与实际的系统操作和用户需求紧密对接。我会使用清晰的步骤说明、图表和示例来辅助解释。同时，我会邀请非技术背景的用户参与文档的测试和评审，以确保文档对所有用户都是友好和可访问的。

3. **问题：** 描述一次您与用户交流并培训他们进行系统操作的经历。【3】
   **回答：** 在我之前的工作中，我负责为一个新的内部工具编写操作手册，并培训用户如何使用该工具。我首先通过一对一的访谈了解用户的基础知识和需求，然后根据这些信息设计了一套分步骤的培训计划。培训过程中，我使用了实际操作演示和互动式教学，以确保用户能够跟上进度并理解关键概念。培训结束后，我还提供了一份详细的操作手册和FAQ文档，供用户在实际操作中参考。

4. **问题：** 您如何处理用户对系统操作的疑问或问题？【3】
   **回答：** 当用户遇到问题时，我会首先通过电话或电子邮件进行响应，了解问题的具体情况。如果问题可以通过简单的指导解决，我会提供步骤说明或截图辅助。对于更复杂的问题，我会安排一个面对面或远程的会议，进行更深入的故障排查和操作指导。此外，我还会定期更新和完善相关的文档和FAQ，以减少类似问题的发生。

5. **问题：** 您如何评估您的文档和培训材料的有效性？【3】
   **回答：** 我会通过用户反馈、培训后的测试和实际操作表现来评估文档和培训材料的有效性。此外，我会定期收集用户的使用数据和问题报告，以识别文档和培训材料中可能存在的不足。基于这些信息，我会不断调整和优化文档内容和培训方法，以提高其质量和效果。

通过这些问题和回答，面试官可以了解应聘者在编写和维护运维文档以及与用户交流培训方面的能力和经验。应聘者的回答应该体现出他们对这些任务的认真态度、专业知识和解决问题的能力。

## 9 国内外的服务器和网络设备厂商众多，它们提供的产品和服务覆盖了从个人使用到企业级的各种需求。

以下是一些知名的厂商及其产品的简要说明：

### 1) 国外厂商

1. **思科（Cisco）**【2】
   - 思科是全球领先的网络设备制造商，提供广泛的网络硬件产品，包括路由器、交换机、防火墙、无线接入点等。思科的产品被广泛应用于家庭、企业和服务提供商网络中。

2. **惠普企业（HPE）**【4】
   - 惠普企业是一家提供服务器、存储和网络设备的公司。其产品线涵盖了高性能计算、云计算、大数据分析等领域。

3. **戴尔（Dell）**【10】
   - 戴尔提供各种服务器和网络设备，包括数据中心服务器、存储解决方案和网络交换机等。戴尔的产品以其高性能和可靠性而闻名。

4. **IBM**【10】
   - IBM提供包括服务器、存储系统和网络设备在内的广泛IT产品。IBM的服务器产品线包括小型机、大型机和云计算解决方案。

5. **Juniper Networks**【2】
   - Juniper Networks专注于开发和制造网络设备，如路由器、交换机和网络安全设备。其产品适用于服务提供商和企业级网络。

### 2) 国内厂商

1. **华为（Huawei）**【2】【6】
   - 华为是全球领先的信息与通信技术（ICT）解决方案提供商，提供包括服务器、路由器、交换机和无线网络设备在内的广泛产品。华为的产品以其创新性和高性价比而受到市场欢迎。

2. **浪潮（Inspur）**【9】【10】
   - 浪潮是中国领先的云计算和大数据服务提供商，提供服务器、存储、云服务和大数据解决方案。浪潮的服务器产品在国内市场占有率较高。

3. **新华三（H3C）**【2】【6】
   - 新华三提供包括服务器、存储、网络设备和安全产品在内的综合IT解决方案。新华三的产品在企业网络市场中占有一席之地。

4. **中兴通讯（ZTE）**【6】【9】
   - 中兴通讯是一家全球领先的通信设备和网络解决方案提供商，其产品包括服务器、路由器、交换机和其他通信设备。

5. **烽火通信（FiberHome）**【6】
   - 烽火通信专注于光纤通信和数据通信设备的研发和制造，提供包括交换机、路由器和光纤传输设备在内的网络设备。

这些厂商的产品和服务在全球范围内都有广泛的应用，它们通过不断的技术创新和产品升级，满足了不同用户对网络设备和服务器的需求。

## 10 IT基本运维管理流程通常包括以下几个关键步骤：

1. **需求分析**：与业务部门沟通，了解业务需求和目标，以便为业务提供合适的IT支持和服务。

2. **资源规划**：根据需求分析的结果，规划所需的硬件、软件、网络资源和人力资源，确保有足够的资源来支持运维活动。

3. **系统部署**：安装和配置服务器、网络设备、应用程序等，确保它们按照既定的标准和流程进行部署。

4. **系统监控**：使用监控工具对IT基础设施的性能、可用性、安全性等关键指标进行实时监控，以便及时发现和解决问题。

5. **维护与支持**：定期对系统进行维护，包括软件更新、硬件升级、数据备份、性能优化等，同时提供用户支持服务，解决用户在使用过程中遇到的问题。

6. **故障响应与恢复**：在系统出现故障时，迅速响应并进行故障诊断，采取措施恢复系统正常运行，并分析故障原因，防止同类问题再次发生。

7. **安全管理**：确保IT系统的安全性，包括实施安全策略、配置防火墙、进行安全审计、管理用户权限等，以防止数据泄露和外部攻击。

8. **备份与恢复**：定期对关键数据进行备份，并确保在数据丢失或系统故障时能够迅速恢复数据和系统状态。

9. **性能优化**：根据监控数据和用户反馈，对系统进行性能分析和优化，提高系统的运行效率和用户体验。

10. **文档管理**：编写和维护相关的技术文档，包括系统架构、配置说明、操作手册、故障处理流程等，以便于知识的传承和团队间的协作。

11. **变更管理**：在对系统进行任何变更（如软件升级、硬件更换、配置调整等）之前，进行严格的变更控制流程，评估变更的影响，确保变更的顺利进行。

12. **容量规划**：根据业务增长趋势和历史数据，预测未来的资源需求，进行容量规划，确保系统能够适应未来的业务发展。

这些步骤构成了IT运维管理的基本流程，旨在确保IT系统的稳定运行，支持业务的连续性和发展。通过这些流程，IT运维团队能够高效地管理和维护企业的IT基础设施。

## 11 mysql、mongodb两者的区别与联系

| 异同点     | MySQL【2】【1】【11】                                        | MongoDB【2】【3】【1】                                       |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据模型   | 关系型数据库，使用行和列的表格来组织数据【1】。              | 非关系型数据库（NoSQL），面向文档的数据库，使用类似JSON的BSON格式存储数据【1】。 |
| 查询语言   | 使用结构化查询语言（SQL）进行数据查询和操作【11】。          | 使用MongoDB查询语言（MQL），类似于JSON的查询语法【11】。     |
| 数据模式   | 需要预先定义数据模式和表结构，对数据的变更需要使用ALTER TABLE语句【1】。 | 灵活的模式（Schema-less），不需要预先定义模式，文档结构可以动态变化【3】。 |
| 事务支持   | 支持多行事务操作，提供ACID事务特性，适合需要高事务处理率的应用【1】【2】。 | 早期版本仅支持单文档事务操作，弱一致性【1】【3】（最新版本已支持多文档事务【8】）。 |
| 性能       | 对于结构化数据和小到中等规模的数据库，MySQL提供了稳定的性能【2】。 | 对于大数据量和非结构化数据，MongoDB在写入和查询性能上有优势【3】【2】。 |
| 可扩展性   | 支持垂直扩展，通过增加硬件资源来提升性能【2】。              | 支持水平扩展，可以通过添加更多服务器来增加存储容量和处理能力【1】。 |
| 一致性     | 提供数据的强一致性，适合对数据一致性要求高的应用【2】。      | 在某些情况下可能牺牲一致性以换取高可用性和水平扩展能力【2】。 |
| 安全性     | 提供了成熟的安全特性，如角色和权限管理【11】。               | 也提供了安全特性，但在某些方面可能不如MySQL成熟【2】。       |
| 适用场景   | 适合需要固定数据模式和高事务性的应用，如金融、会计系统【1】【2】。 | 适合大数据和内容管理应用，以及需要快速迭代和变化的数据模型【1】【2】。 |
| 社区与支持 | 拥有广泛的社区支持和丰富的第三方工具【1】。                  | 作为较新的技术，社区活跃，不断发展中【1】。                  |

请注意，上述表格中的信息是基于提供的文档和通用知识整理而成。对于MongoDB的最新版本中可能已经支持的多文档事务，建议查阅官方文档以获取最准确的信息。

## 12 mysql、mongodb语法结构的区别与联系

| 异同点     | MySQL【5】【2】                                              | MongoDB【5】【1】【8】                                       |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据模型   | 关系型数据库，使用行和列的表格来组织数据【2】。              | 非关系型数据库（NoSQL），面向文档的数据库，使用BSON格式存储数据【5】【8】。 |
| 查询语言   | 使用结构化查询语言（SQL）进行数据查询和操作【5】。           | 使用MongoDB查询语言，基于JSON/BSON格式的操作语法【1】【8】。 |
| 数据定义   | 使用CREATE、ALTER、DROP等DDL语句进行数据库和表的结构定义【5】。 | 使用类似的DDL操作，但语法结构基于BSON格式【8】。             |
| 数据操作   | 通过INSERT、UPDATE、DELETE等DML语句进行数据的增删改操作【5】。 | 通过insert、update、remove等操作进行数据的增删改【1】。      |
| 数据查询   | 使用SELECT语句进行数据查询，支持WHERE、GROUP BY、HAVING等子句【5】。 | 使用find、aggregate等操作进行数据查询，支持类似SQL的查询语法【1】【8】。 |
| 索引       | 支持B+树索引，使用CREATE INDEX和DROP INDEX等语句管理索引【5】。 | 支持多种索引类型，包括单键、复合、全文等索引，使用ensureIndex等命令创建【1】【8】。 |
| 事务支持   | 支持事务处理，使用START TRANSACTION、COMMIT、ROLLBACK等语句控制事务【5】。 | 从4.0版本开始支持事务，使用类似SQL的事务控制语法【1】。      |
| 数据存储   | 以表格形式存储数据，每行代表一个记录，每列代表一个字段【2】。 | 文档型数据库，每个文档包含多个字段和值对，支持内嵌文档和数组【1】【8】。 |
| 集群和分片 | 通常通过垂直扩展提升性能，支持主从复制和读写分离【5】。      | 支持水平扩展，使用分片和副本集架构实现高可用和数据分散【1】。 |
| 数据一致性 | 遵循ACID事务原则，保证数据的一致性和完整性【5】。            | 通过副本集和日志（oplog）复制来保证数据的一致性和可用性【1】。 |
| 适用场景   | 适合结构化数据和复杂查询需求的场景【5】【2】。               | 适合半结构化或无结构数据，以及需要快速迭代和横向扩展的场景【5】【1】。 |

请注意，上述表格中的信息是基于提供的文档和通用知识整理而成。对于MongoDB的最新版本中可能已经支持的某些特性，建议查阅官方文档以获取最准确的信息。

## 13 以下是一个关于Docker常用命令及其简要说明的表格形式罗列：

| 命令                       | 功能描述                     | 使用格式/示例                                             |
| -------------------------- | ---------------------------- | --------------------------------------------------------- |
| **容器管理**               |                              |                                                           |
| `docker run`               | 创建并启动一个新的容器       | `docker run -d --name container_name image_name`          |
| `docker start`             | 启动已存在的停止状态容器     | `docker start container_id_or_name`                       |
| `docker stop`              | 停止正在运行的容器           | `docker stop container_id_or_name`                        |
| `docker restart`           | 重启指定容器                 | `docker restart container_id_or_name`                     |
| `docker rm`                | 删除已停止的容器             | `docker rm container_id_or_name`                          |
| `docker kill`              | 强制停止容器                 | `docker kill container_id_or_name`                        |
| `docker ps`                | 列出运行中的容器             | `docker ps`                                               |
| `docker ps -a`             | 列出所有容器（包括已停止的） | `docker ps -a`                                            |
| `docker exec`              | 在运行中的容器内执行命令     | `docker exec -it container_id_or_name /bin/bash`          |
| **镜像管理**               |                              |                                                           |
| `docker pull`              | 从仓库拉取镜像               | `docker pull nginx`                                       |
| `docker push`              | 将本地镜像推送到仓库         | `docker push username/repository:tag`                     |
| `docker images`            | 列出本地镜像                 | `docker images`                                           |
| `docker rmi`               | 删除本地镜像                 | `docker rmi image_id_or_name`                             |
| `docker build`             | 从Dockerfile构建镜像         | `docker build -t my_image .`                              |
| `docker tag`               | 给镜像添加标签               | `docker tag image_id new_username/new_repository:new_tag` |
| **Docker服务管理**         |                              |                                                           |
| `systemctl start docker`   | 启动Docker服务               | `systemctl start docker`                                  |
| `systemctl stop docker`    | 停止Docker服务               | `systemctl stop docker`                                   |
| `systemctl restart docker` | 重启Docker服务               | `systemctl restart docker`                                |
| `systemctl enable docker`  | 设置Docker服务开机自启       | `systemctl enable docker`                                 |
| `systemctl status docker`  | 查看Docker服务运行状态       | `systemctl status docker`                                 |
| `docker version`           | 显示Docker版本信息           | `docker version`                                          |
| `docker info`              | 显示Docker系统相关信息       | `docker info`                                             |
| **其他命令**               |                              |                                                           |
| `docker login`             | 登录Docker仓库               | `docker login registry.example.com`                       |
| `docker commit`            | 提交对容器的修改以创建新镜像 | `docker commit container_id new_image_name:new_tag`       |

以上表格仅列出了部分常用命令，Docker还有许多其他功能和选项，您可以根据实际需求查阅官方文档获取完整信息。

## 14kubernetes面试相关

###  1.简述什么是Kubernetes？

- Kubernetes是一个全新的基于容器技术的分布式系统支撑平台。是Google开源的容器集群管理系统（谷歌内部:Borg）。在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。并且具有完备的集群管理能力，多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。

Kubernetes（简称K8s）是一种用来管理容器化应用程序的工具，就像是一支能够自动化管理大量容器的舞台导演。想象一下，你有很多表演者（容器）在舞台上表演不同的节目（应用程序），Kubernetes就像是一个智能的导演，负责确保每个表演者都在正确的时间出场，舞台布景恰到好处，以及在演出过程中自动解决各种问题，确保表演顺利进行。这样，你就可以轻松地管理和部署你的应用程序，而不必担心复杂的细节。

容器化应用程序种类繁多，包括但不限于：

1. Web 服务器和应用程序：例如，使用容器化的Nginx、Apache或Node.js来托管网站和Web应用程序。
2. 数据库：例如，容器化的MySQL、PostgreSQL或MongoDB用于存储和管理数据。
3. 消息队列和中间件：例如，使用容器化的RabbitMQ、Kafka或Redis来处理消息传递和数据缓存。
4. 大数据处理应用程序：例如，容器化的Apache Spark、Hadoop或Flink用于大规模数据分析和处理。
5. 微服务应用程序：例如，将整个应用程序拆分为小型、独立的服务单元，每个服务单元都可以容器化部署，如容器化的Spring Boot应用。
6. 容器化的开发工具：例如，Docker本身就是一个用于容器化应用程序的工具，也可以容器化开发环境，如容器化的IDE或代码编辑器。

这些只是一小部分容器化应用程序的例子，实际上，几乎任何类型的应用程序都可以通过容器化来简化部署、提高可移植性和灵活性。

### 2.简述Kubernetes和Docker的关系？

Kubernetes和Docker是两个不同但相关的概念，它们通常被一起使用来构建和管理容器化应用程序的整个生命周期。

1. Docker是一种容器化技术，它允许开发人员将应用程序及其所有依赖项打包到一个称为容器的独立单元中。Docker提供了一种标准的打包格式和工具集，使应用程序在不同的环境中可以一致地运行。因此，Docker负责创建、管理和运行容器。

2. Kubernetes是一个容器编排平台，它用于自动化容器化应用程序的部署、扩展和管理。Kubernetes可以管理多个Docker容器，自动调度它们在集群中的运行位置，并提供弹性、高可用性和自我修复的能力。简而言之，Kubernetes负责管理整个容器化应用程序的生命周期。

因此，可以说，Docker提供了容器化技术，而Kubernetes提供了容器化应用程序的管理和编排能力。它们通常一起使用，使开发人员能够更轻松地构建、部署和管理复杂的分布式应用程序。

### 3.简述Kubernetes如何实现集群管理？

- 在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node。其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的。

Kubernetes实现集群管理的关键在于其架构和组件的设计。以下是Kubernetes如何实现集群管理的主要步骤：

1. **Master节点**：Kubernetes集群通常由多个节点组成，其中包括至少一个Master节点和多个Worker节点。Master节点是整个集群的控制中心，负责管理和协调集群中的所有工作。（管理）

2. **API服务器**：Kubernetes集群的Master节点上运行着一个API服务器，它充当着集群管理的主要接口。所有的管理命令和操作都通过API服务器来执行。

3. **控制器管理器**：控制器管理器是Kubernetes集群中的一个核心组件，负责监视集群状态，并根据用户定义的期望状态来进行调整。比如，它会确保所需的副本数量处于正确的状态，当发现状态不符合预期时，会主动进行调整。

4. **调度器**：调度器负责将新创建的Pod（容器集合）调度到集群中的合适节点上。它会考虑诸多因素，如资源利用率、节点负载、亲和性和反亲和性规则等，以确保最佳的运行效率和负载均衡。

5. **etcd**：etcd是一个分布式键值存储系统，用于保存集群的状态信息、配置数据以及所有关于集群的重要信息。Kubernetes中的所有组件都会使用etcd来存储和检索数据，以确保集群的一致性和可靠性。

6. **Worker节点**：Worker节点是运行容器的主机，它们负责实际运行容器化的应用程序。每个Worker节点上运行着一个称为kubelet的代理程序，它负责接收来自Master节点的指令，并根据指令来创建、启动、停止或删除容器。（干活）

通过这些组件的协作，Kubernetes实现了集群管理的各项功能，包括调度容器、自动扩展、负载均衡、故障恢复等。这使得用户能够轻松地部署和管理容器化应用程序，并确保它们能够以高效、稳定和可靠的方式运行在集群中。

### 4.kubernetes组件谈谈理解

一个kubernetes集群主要是由**控制节点(master)**、**工作节点(node)**构成，每个节点上都会安装不同的组件。

**master：集群的控制平面，负责集群的决策 ( 管理 )**

> **ApiServer** : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制
>
> **Scheduler** : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上
>
> **ControllerManager** : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等
>
> **Etcd** ：负责存储集群中各种资源对象的信息

**node：集群的数据平面，负责为容器提供运行环境 ( 干活 )**

> **Kubelet** : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器
>
> **KubeProxy** : 负责提供集群内部的服务发现和负载均衡
>
> **Docker** : 负责节点上容器的各种操作

![image-20200406184656917](https://gitee.com/yooome/golang/raw/main/21-k8s%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/images/image-20200406184656917.png)

下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：

1. 首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中

2. 一个nginx服务的安装请求会首先被发送到master节点的apiServer组件

3. apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上

   在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer

4. apiServer调用controller-manager去调度Node节点安装nginx服务

5. kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod

   pod是kubernetes的最小操作单元，容器必须跑在pod中至此，

6. 一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理

这样，外界用户就可以访问集群中的nginx服务了

### 5.kubernetes概念

**Master**：集群控制节点，每个集群需要至少一个master节点负责集群的管控

**Node**：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行

**Pod**：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器

**Controller**：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等

**Service**：pod对外服务的统一入口，下面可以维护者同一类的多个pod

**Label**：标签，用于对pod进行分类，同一类pod会拥有相同的标签

**NameSpace**：命名空间，用来隔离pod的运行环境

------

当涉及Kubernetes时，有几个基础概念非常重要。以下是其中一些：

1. **Pod（容器组）**：Pod是Kubernetes的最小部署单位，它可以包含一个或多个容器。这些容器共享网络和存储，并在同一个节点上运行。Pod是部署、扩展和管理的基本单位。

2. **服务（Service）**：服务是一种抽象，用于定义一组Pod的访问方式。它通过标签选择器将一组Pod组合成一个服务，并为其提供一个稳定的访问点，使其他应用程序可以通过服务名访问这些Pod，而无需关心底层Pod的具体位置。

3. **控制器（Controller）**：控制器是Kubernetes中用于管理Pod副本数量和状态的抽象。常见的控制器包括Deployment、ReplicaSet、StatefulSet等，它们负责确保所管理的Pod在集群中按照用户期望的状态运行。

4. **部署（Deployment）**：部署是一种控制器类型，用于管理Pod的部署和更新。它允许用户指定所需的Pod副本数量，并提供滚动更新、回滚和自动修复等功能。

5. **命名空间（Namespace）**：命名空间是Kubernetes中用于将集群资源划分为多个虚拟集群的一种方式。它允许用户在同一集群中创建多个逻辑分区，并将资源进行隔离和管理。

6. **节点（Node）**：节点是Kubernetes集群中的工作节点，它是运行Pod的实际主机。每个节点都有一个kubelet代理程序运行，负责与Master节点通信，并执行Pod的创建、管理和监控。

7. **容器（Container）**：容器是一种轻量级、独立的软件打包形式，其中包含应用程序及其所有依赖项。在Kubernetes中，容器通常是通过Docker等容器引擎创建的。

这些是Kubernetes的一些基础概念，理解它们对于有效地使用和管理Kubernetes集群至关重要。

### 6.简述kube-proxy作用？

kube-proxy是Kubernetes集群中的一个关键组件，其主要作用是实现服务的网络代理和负载均衡。具体来说，kube-proxy有以下几个主要功能：

1. **服务代理**：kube-proxy负责监视Kubernetes集群中的服务和端口映射的变化，并为这些服务创建网络代理。当有新的服务被创建时，kube-proxy会动态地更新代理规则，以确保可以通过服务名访问到后端Pod。

2. **负载均衡**：在服务代理的基础上，kube-proxy还负责实现服务的负载均衡。当服务有多个后端Pod时，kube-proxy会根据负载均衡策略将请求分发给这些Pod，以实现请求的均衡分配。

3. **服务发现**：通过为服务创建代理规则，kube-proxy允许其他Pod或外部用户通过服务名来访问服务，而无需了解服务后端Pod的具体IP地址和端口。这为服务发现提供了便利，使得应用程序可以更轻松地与其他服务通信。

总的来说，kube-proxy是Kubernetes中的一项重要组件，负责实现服务的网络代理、负载均衡和服务发现等功能，从而为集群中的应用程序提供稳定、可靠的网络访问。

### 7.简述Kubernetes常见的部署方式？

- kubeadm：也是推荐的一种部署方式

以下是使用 `kubeadm` 部署 Kubernetes 集群的一般步骤：

1. **准备环境**：
   - 确保所有节点满足 Kubernetes 的最低要求，如操作系统版本、内存和CPU要求等。
   - 确保节点之间能够相互通信，包括网络连通性和DNS解析。

2. **安装 Docker 或其他容器运行时**：
   - Kubernetes需要一个容器运行时来运行应用程序。通常情况下，会选择Docker或者Containerd。

3. **安装 kubeadm、kubelet 和 kubectl**：
   - 在所有节点上安装 Kubernetes 组件，可以使用包管理器或者直接下载二进制文件。

4. **初始化控制平面节点**：
   - 在其中一个节点上运行 `kubeadm init` 命令，这会初始化 Kubernetes 控制平面。你可以通过参数设置一些选项，比如指定 Pod 网络的插件。

5. **配置kubectl**：
   - 配置 `kubectl` 来连接到 Kubernetes 集群，`kubeadm init` 命令会输出相应的配置信息。

6. **部署网络插件**：
   - 部署网络插件，以便 Kubernetes 集群中的 Pod 可以相互通信。常用的网络插件包括 Calico、Flannel 和 Cilium。

7. **加入其他节点**：
   - 使用 `kubeadm join` 命令将其他节点加入到集群中。这个命令是在初始化控制平面节点时生成的。

8. **可选：配置容器运行时**：
   - 根据需要，配置容器运行时的参数，比如Cgroup驱动程序、镜像存储等。

9. **验证集群**：
   - 使用 `kubectl` 命令验证集群的状态，确保所有节点已成功加入，并且 Pod 能够正常运行。

10. **可选：添加负载均衡**：

   - 如果需要，可以添加负载均衡来分配流量到 Kubernetes 集群中的各个节点，以提高可用性和性能。

这些步骤提供了一个基本的部署流程，但具体的步骤和配置可能会因环境和需求而有所不同。在执行部署过程时，建议查阅 Kubernetes 官方文档以获取最新的指导和最佳实践。

- 二进制包部署：

以下是使用 Kubernetes 二进制包手动部署 Kubernetes 集群的一般步骤：

1. **准备环境**：
   - 确保所有节点满足 Kubernetes 的最低要求，包括操作系统版本、内存和CPU要求等。
   - 确保节点之间能够相互通信，包括网络连通性和DNS解析。

2. **安装和配置 Docker 或其他容器运行时**：
   - Kubernetes需要一个容器运行时来运行应用程序。通常情况下，你可以选择安装 Docker 或者其他容器运行时，如 Containerd。

3. **下载 Kubernetes 二进制文件**：
   - 下载所需版本的 Kubernetes 二进制文件，包括 kube-apiserver、kube-controller-manager、kube-scheduler、kubelet 和 kube-proxy 等组件。

4. **在所有节点上安装和配置 Kubernetes 组件**：
   - 将下载的 Kubernetes 二进制文件解压，并将它们放置在每个节点的合适目录中（例如 `/usr/local/bin/`）。
   - 配置每个组件的配置文件，通常位于 `/etc/kubernetes/` 目录下。这些配置文件包括 kube-apiserver、kube-controller-manager、kube-scheduler 和 kubelet 的配置。
   - 启动和配置 kubelet 服务。

5. **初始化控制平面节点**：
   - 在其中一个节点上运行 `kube-apiserver`、`kube-controller-manager` 和 `kube-scheduler`，并确保它们正确运行。
   - 运行 `kube-apiserver` 时，需要指定 API server 相关的参数，比如 `--service-cluster-ip-range`、`--etcd-servers` 等。
   - 运行 `kube-controller-manager` 时，需要指定 controller manager 相关的参数，比如 `--cluster-cidr` 等。
   - 运行 `kube-scheduler` 时，需要指定 scheduler 相关的参数，比如 `--address`、`--kubeconfig` 等。

6. **初始化工作节点**：
   - 在每个工作节点上运行 `kubelet` 和 `kube-proxy`。

7. **加入工作节点到集群**：
   - 在每个工作节点上运行 `kubelet` 和 `kube-proxy` 后，使用 `kubeadm join` 命令将其加入到 Kubernetes 集群中。该命令将在控制平面节点初始化时生成。

8. **部署网络插件**：
   - 部署网络插件，以便 Kubernetes 集群中的 Pod 可以相互通信。常用的网络插件包括 Calico、Flannel 和 Cilium。

9. **验证集群**：
   - 使用 `kubectl` 命令验证集群的状态，确保所有节点已成功加入，并且 Pod 能够正常运行。

这些步骤提供了手动部署 Kubernetes 集群的基本流程，但具体的步骤和配置可能会因环境和需求而有所不同。在执行部署过程时，建议查阅 Kubernetes 官方文档以获取最新的指导和最佳实践。

- minikube：在本地轻松运行一个单节点 Kubernetes 群集的工具。

Minikube 是一个用于在本地机器上运行单节点 Kubernetes 集群的工具，以下是使用 Minikube 部署 Kubernetes 集群的一般步骤：

1. **安装 Minikube**：
   - 根据你的操作系统，从 Minikube 的官方网站下载并安装 Minikube。通常你可以通过包管理器或者从二进制文件安装。

2. **安装 Hypervisor（可选）**：
   - 如果你打算在虚拟机中运行 Minikube，你需要在本地机器上安装一个支持的 Hypervisor，比如 VirtualBox、VMware Fusion、HyperKit 等。如果你使用 Docker Desktop，则无需安装额外的 Hypervisor。

3. **启动 Minikube**：
   - 在终端中运行 `minikube start` 命令来启动 Minikube 集群。根据你的配置和网络情况，Minikube 会下载和启动一个单节点 Kubernetes 集群。

4. **验证集群**：
   - 运行 `kubectl get nodes` 命令来验证 Minikube 集群是否已成功启动，并且节点处于 Ready 状态。

5. **管理 Minikube 集群**：
   - 你可以使用 `minikube stop`、`minikube delete` 等命令来停止或删除 Minikube 集群。另外，你还可以通过 `minikube dashboard` 命令启动 Kubernetes Dashboard 来管理集群中的资源。

6. **使用 Minikube**：
   - 一旦 Minikube 集群启动，你就可以使用 `kubectl` 命令或者 Kubernetes Dashboard 来部署和管理应用程序、服务和其他 Kubernetes 资源。你可以部署测试应用、调试容器等。

请注意，这些步骤提供了一个基本的部署流程。具体的步骤和配置可能会因环境和需求而有所不同。在执行部署过程时，建议查阅 Minikube 官方文档以获取最新的指导和最佳实践。

### 8.简述Kubernetes中什么是Minikube、Kubectl、Kubelet？

- Minikube 是一种可以在本地轻松运行一个单节点 Kubernetes 群集的工具。
- Kubectl 是一个命令行工具，可以使用该工具控制Kubernetes集群管理器，如检查群集资源，创建、删除和更新组件，查看应用程序。
- Kubelet 是一个代理服务，它在每个节点上运行，并使从服务器与主服务器通信。

### 9.简述Kubernetes的优势、适应场景及其特点？

- Kubernetes作为一个完备的分布式系统支撑平台，其主要优势：
- 容器编排
- 轻量级
- 开源
- 弹性伸缩
- 负载均衡
- Kubernetes常见场景：
- 快速部署应用
- 快速扩展应用
- 无缝对接新的应用功能
- 节省资源，优化硬件资源的使用
- Kubernetes相关特点：
- 可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）。
- 可扩展: 模块化,、插件化、可挂载、可组合。
- 自动化: 自动部署、自动重启、自动复制、自动伸缩/扩展。

### 10.简述Kubernetes的缺点或当前的不足之处？

- Kubernetes当前存在的缺点（不足）如下：
- 安装过程和配置相对困难复杂。
- 管理服务相对繁琐。
- 运行和编译需要很多时间。
- 它比其他替代品更昂贵。
- 对于简单的应用程序来说，可能不需要涉及Kubernetes即可满足。
